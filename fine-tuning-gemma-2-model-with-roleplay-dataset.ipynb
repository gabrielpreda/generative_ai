{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/gpreda/fine-tuning-gemma-2-model-with-roleplay-dataset?scriptVersionId=197770566\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"40f5e5ce","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.013063,"end_time":"2024-09-22T10:25:17.84611","exception":false,"start_time":"2024-09-22T10:25:17.833047","status":"completed"},"tags":[]},"source":["<center><h1>Fine-tuning Gemma 2 model using LoRA and Keras</h1></center>\n","\n","<center><img src=\"https://res.infoq.com/news/2024/02/google-gemma-open-model/en/headerimage/generatedHeaderImage-1708977571481.jpg\" width=\"400\"></center>\n","\n","\n","# Introduction\n","\n","This notebook will demonstrate three things:\n","\n","1. How to fine-tune Gemma model using LoRA\n","2. Creation of a specialised class to query about Kaggle features\n","3. Some results of querying about various topics while instructing the model to adopt a certain persona, from the ones included in the data used for fine tuning.\n","\n"]},{"cell_type":"markdown","id":"cf50aa6d","metadata":{"papermill":{"duration":0.011494,"end_time":"2024-09-22T10:25:17.869661","exception":false,"start_time":"2024-09-22T10:25:17.858167","status":"completed"},"tags":[]},"source":["# What is Gemma 2?\n","\n","Gemma is a collection of lightweight, advanced open models developed by Google, leveraging the same research and technology behind the Gemini models. These models are text-to-text, decoder-only large language models available in English, with open weights provided for both pre-trained and instruction-tuned versions. Gemma models excel in a range of text generation tasks, such as question answering, summarization, and reasoning. Their compact size allows for deployment in resource-constrained environments like laptops, desktops, or personal cloud infrastructure, making state-of-the-art AI models more accessible and encouraging innovation for all. \n","\n","Gemma 2 represent the 2nd generation of Gemma models. These models were trained on a dataset of text data that includes a wide variety of sources. The **27B** model was trained with **13 trillion** tokens, the **9B** model was trained with **8 trillion tokens**, and **2B** model was trained with **2 trillion** tokens. Here is a summary of their key components: \n","* **Web Documents**: A diverse collection of web text ensures the model is exposed to a broad range of linguistic styles, topics, and vocabulary. Primarily English-language content.\n","* **Code**: Exposing the model to code helps it to learn the syntax and patterns of programming languages, which improves its ability to generate code or understand code-related questions.\n","* **Mathematics**: Training on mathematical text helps the model learn logical reasoning, symbolic representation, and to address mathematical queries.\n","\n","To learn more about Gemma 2, follow this link: [Gemma 2 Model Card](https://www.kaggle.com/models/google/gemma-2).\n","\n","\n"]},{"cell_type":"markdown","id":"a54cbfaf","metadata":{"papermill":{"duration":0.011481,"end_time":"2024-09-22T10:25:17.89297","exception":false,"start_time":"2024-09-22T10:25:17.881489","status":"completed"},"tags":[]},"source":["# What is LoRA?  \n","\n","**LoRA** stands for **Low-Rank Adaptation**. It is a method used to fine-tune large language models (LLMs) by freezing the weights of the LLM and injecting trainable rank-decomposition matrices. The number of trainable parameters during fine-tunning will decrease therefore considerably. According to **LoRA** paper, this number decreases **10,000 times**, and the computational resources size decreases 3 times. "]},{"cell_type":"markdown","id":"a425e7ee","metadata":{"papermill":{"duration":0.0115,"end_time":"2024-09-22T10:25:17.916476","exception":false,"start_time":"2024-09-22T10:25:17.904976","status":"completed"},"tags":[]},"source":["# How we proceed?\n","\n","For fine-tunning with LoRA, we will follow the steps:\n","\n","1. Install prerequisites\n","2. Load and process the data for fine-tuning\n","3. Initialize the code for Gemma causal language model (Gemma Causal LM)\n","4. Perform fine-tuning so that the model will learn the various persona and be able to perform in each role.\n","5. Test the fine-tunned model with questions from the data used for fine-tuning and with aditional questions"]},{"cell_type":"markdown","id":"1b8f6a6e","metadata":{"papermill":{"duration":0.011372,"end_time":"2024-09-22T10:25:17.939556","exception":false,"start_time":"2024-09-22T10:25:17.928184","status":"completed"},"tags":[]},"source":["# Prerequisites\n","\n","\n","## Install packages\n","\n","We start by installing `keras-nlp` and `keras` packages."]},{"cell_type":"code","execution_count":1,"id":"76349425","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-09-22T10:25:17.964653Z","iopub.status.busy":"2024-09-22T10:25:17.964255Z","iopub.status.idle":"2024-09-22T10:26:01.340966Z","shell.execute_reply":"2024-09-22T10:26:01.339674Z"},"papermill":{"duration":43.39232,"end_time":"2024-09-22T10:26:01.343667","exception":false,"start_time":"2024-09-22T10:25:17.951347","status":"completed"},"tags":[]},"outputs":[],"source":["# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n","!pip install -q -U keras-nlp\n","!pip install -q -U keras>=3\n","!pip install -q -U kagglehub --upgrade"]},{"cell_type":"markdown","id":"bb868259","metadata":{"papermill":{"duration":0.011649,"end_time":"2024-09-22T10:26:01.368459","exception":false,"start_time":"2024-09-22T10:26:01.35681","status":"completed"},"tags":[]},"source":["## Import packages\n","\n","Now we can import the packages we just installed. We will also install `os`, so that we can set the environment variables needed for keras backend. We will use `jax` as `KERAS_BACKEND`.\n","\n","Because we want to publish the Model from the Notebook, we also include `kagglehub` and import secrets from `Kaggle App`."]},{"cell_type":"code","execution_count":2,"id":"fc2b965f","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-09-22T10:26:01.394692Z","iopub.status.busy":"2024-09-22T10:26:01.393931Z","iopub.status.idle":"2024-09-22T10:26:15.393513Z","shell.execute_reply":"2024-09-22T10:26:15.392786Z"},"papermill":{"duration":14.015152,"end_time":"2024-09-22T10:26:15.39578","exception":false,"start_time":"2024-09-22T10:26:01.380628","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","os.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n","os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\" # avoid memory fragmentation on JAX backend.\n","os.environ[\"JAX_PLATFORMS\"] = \"\"\n","import keras\n","import keras_nlp\n","import kagglehub\n","\n","\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","tqdm.pandas() # progress bar for pandas\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from IPython.display import display, Markdown"]},{"cell_type":"markdown","id":"54751426","metadata":{"papermill":{"duration":0.011695,"end_time":"2024-09-22T10:26:15.419622","exception":false,"start_time":"2024-09-22T10:26:15.407927","status":"completed"},"tags":[]},"source":["## Initialize user secrets\n","\n","We initialize user secrets, so that we can publish the model using `kagglehub`."]},{"cell_type":"code","execution_count":3,"id":"97b3074b","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:26:15.444915Z","iopub.status.busy":"2024-09-22T10:26:15.444267Z","iopub.status.idle":"2024-09-22T10:26:15.730898Z","shell.execute_reply":"2024-09-22T10:26:15.730108Z"},"papermill":{"duration":0.301804,"end_time":"2024-09-22T10:26:15.733087","exception":false,"start_time":"2024-09-22T10:26:15.431283","status":"completed"},"tags":[]},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","os.environ[\"KAGGLE_USERNAME\"] = user_secrets.get_secret(\"kaggle_username\")\n","os.environ[\"KAGGLE_KEY\"] = user_secrets.get_secret(\"kaggle_key\")"]},{"cell_type":"markdown","id":"8e94adcd","metadata":{"papermill":{"duration":0.011252,"end_time":"2024-09-22T10:26:15.756136","exception":false,"start_time":"2024-09-22T10:26:15.744884","status":"completed"},"tags":[]},"source":["## Configurations\n","\n","\n","We use a `Config` class to group the information needed to control the fine-tuning process:\n","* random seed \n","* dataset path\n","* preset - name of pretrained Gemma 2\n","* sequence length - this is the maximum size of input sequence for training\n","* batch size - size of the input batch in training, x 2 as two GPUs\n","* lora rank - rank for LoRA, higher means more trainable parameters \n","* learning rate used in the train\n","* epochs - number of epochs for train"]},{"cell_type":"code","execution_count":4,"id":"26866d58","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:26:15.780866Z","iopub.status.busy":"2024-09-22T10:26:15.780098Z","iopub.status.idle":"2024-09-22T10:26:15.785085Z","shell.execute_reply":"2024-09-22T10:26:15.784214Z"},"papermill":{"duration":0.019167,"end_time":"2024-09-22T10:26:15.786996","exception":false,"start_time":"2024-09-22T10:26:15.767829","status":"completed"},"tags":[]},"outputs":[],"source":["class Config:\n","    seed = 42\n","    dataset_path = \"/kaggle/input/roleplay-snapshot/roleplay.csv\"\n","    preset = \"/kaggle/input/gemma2/keras/gemma2_2b_en/1\" # name of pretrained Gemma 2\n","    sequence_length = 512 # max size of input sequence for training\n","    batch_size = 1 # size of the input batch in training\n","    lora_rank = 4 # rank for LoRA, higher means more trainable parameters\n","    learning_rate=8e-5 # learning rate used in train\n","    epochs = 15 # number of epochs to train"]},{"cell_type":"markdown","id":"aacc55f7","metadata":{"papermill":{"duration":0.011343,"end_time":"2024-09-22T10:26:15.810039","exception":false,"start_time":"2024-09-22T10:26:15.798696","status":"completed"},"tags":[]},"source":["Set a random seed for results reproducibility."]},{"cell_type":"code","execution_count":5,"id":"1f22e70b","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:26:15.834176Z","iopub.status.busy":"2024-09-22T10:26:15.833627Z","iopub.status.idle":"2024-09-22T10:26:15.838012Z","shell.execute_reply":"2024-09-22T10:26:15.837145Z"},"papermill":{"duration":0.018525,"end_time":"2024-09-22T10:26:15.839918","exception":false,"start_time":"2024-09-22T10:26:15.821393","status":"completed"},"tags":[]},"outputs":[],"source":["keras.utils.set_random_seed(Config.seed)"]},{"cell_type":"markdown","id":"1281ca00","metadata":{"papermill":{"duration":0.01111,"end_time":"2024-09-22T10:26:15.862377","exception":false,"start_time":"2024-09-22T10:26:15.851267","status":"completed"},"tags":[]},"source":["# Load the data\n","\n","\n","We load the data we will use for fine-tunining."]},{"cell_type":"code","execution_count":6,"id":"879f86aa","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:26:15.887538Z","iopub.status.busy":"2024-09-22T10:26:15.886507Z","iopub.status.idle":"2024-09-22T10:26:15.926888Z","shell.execute_reply":"2024-09-22T10:26:15.925952Z"},"papermill":{"duration":0.054978,"end_time":"2024-09-22T10:26:15.92898","exception":false,"start_time":"2024-09-22T10:26:15.874002","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>description</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sherlock</td>\n","      <td>Sherlock the renowned detective from Baker Str...</td>\n","      <td>&lt;|system|&gt;In the bustling streets of Victorian...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Serena Williams</td>\n","      <td>Serena is a professional tennis legend known f...</td>\n","      <td>&lt;|system|&gt;Serena Williams is a professional te...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Beethoven</td>\n","      <td>Beethoven is a classical composer and pianist ...</td>\n","      <td>&lt;|system|&gt;Ludwig van Beethoven was a German co...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Katniss Everdeen</td>\n","      <td>Katniss is a resourceful and tough heroine fro...</td>\n","      <td>&lt;|system|&gt;Welcome to the world of Panem, where...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tony Stark</td>\n","      <td>Tony Stark also known as Iron Man is a genius ...</td>\n","      <td>&lt;|system|&gt;Meet Tony Stark, also known as Iron ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               name                                        description  \\\n","0          Sherlock  Sherlock the renowned detective from Baker Str...   \n","1   Serena Williams  Serena is a professional tennis legend known f...   \n","2         Beethoven  Beethoven is a classical composer and pianist ...   \n","3  Katniss Everdeen  Katniss is a resourceful and tough heroine fro...   \n","4        Tony Stark  Tony Stark also known as Iron Man is a genius ...   \n","\n","                                                text  \n","0  <|system|>In the bustling streets of Victorian...  \n","1  <|system|>Serena Williams is a professional te...  \n","2  <|system|>Ludwig van Beethoven was a German co...  \n","3  <|system|>Welcome to the world of Panem, where...  \n","4  <|system|>Meet Tony Stark, also known as Iron ...  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(f\"{Config.dataset_path}\", sep=\";\")\n","df.head()"]},{"cell_type":"markdown","id":"8d09a637","metadata":{"papermill":{"duration":0.011405,"end_time":"2024-09-22T10:26:15.952306","exception":false,"start_time":"2024-09-22T10:26:15.940901","status":"completed"},"tags":[]},"source":["Let's check the total number of rows in this dataset."]},{"cell_type":"code","execution_count":7,"id":"a683ad41","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:26:15.976659Z","iopub.status.busy":"2024-09-22T10:26:15.976374Z","iopub.status.idle":"2024-09-22T10:26:15.982077Z","shell.execute_reply":"2024-09-22T10:26:15.981193Z"},"papermill":{"duration":0.020127,"end_time":"2024-09-22T10:26:15.984028","exception":false,"start_time":"2024-09-22T10:26:15.963901","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["((25, 3), Index(['name', 'description', 'text'], dtype='object'))"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.shape, df.columns"]},{"cell_type":"markdown","id":"5ac760ee","metadata":{"papermill":{"duration":0.011646,"end_time":"2024-09-22T10:26:16.007958","exception":false,"start_time":"2024-09-22T10:26:15.996312","status":"completed"},"tags":[]},"source":["# Preprocess the data\n","\n","We will preprocess the data so that, from the sequences in the `text` column, we extract the `<|system|>` prompt and the pairs of {`<|user|>`, `<|assistant|>`} to form triplets of {`<|system|>`, `<|user|>`, `<|assistant|>`}  for each entry in the data for fine-tuning."]},{"cell_type":"code","execution_count":8,"id":"0896f5ec","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:26:16.03272Z","iopub.status.busy":"2024-09-22T10:26:16.032423Z","iopub.status.idle":"2024-09-22T10:26:16.037201Z","shell.execute_reply":"2024-09-22T10:26:16.036413Z"},"papermill":{"duration":0.019165,"end_time":"2024-09-22T10:26:16.039051","exception":false,"start_time":"2024-09-22T10:26:16.019886","status":"completed"},"tags":[]},"outputs":[],"source":["import re\n","def extract_dialogue_components(text):\n","    # Extract the system prompt\n","    system_prompt = re.search(r\"<\\|system\\|>.*?</s>\", text, re.DOTALL).group(0)\n","    \n","    # Extract user and assistant dialogues\n","    dialogue_pairs = re.findall(r\"(<\\|user\\|>.*?</s>\\s*<\\|assistant\\|>.*?</s>)\", text, re.DOTALL)\n","    \n","    return system_prompt, dialogue_pairs"]},{"cell_type":"markdown","id":"9d7a1317","metadata":{"papermill":{"duration":0.011503,"end_time":"2024-09-22T10:26:16.062356","exception":false,"start_time":"2024-09-22T10:26:16.050853","status":"completed"},"tags":[]},"source":["We process the data. We will only include in the data for fine-tuning the model the rows that fits in the max length as configured."]},{"cell_type":"code","execution_count":9,"id":"c525a9c5","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:26:16.086981Z","iopub.status.busy":"2024-09-22T10:26:16.08666Z","iopub.status.idle":"2024-09-22T10:26:16.095805Z","shell.execute_reply":"2024-09-22T10:26:16.094906Z"},"papermill":{"duration":0.023637,"end_time":"2024-09-22T10:26:16.097729","exception":false,"start_time":"2024-09-22T10:26:16.074092","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["expected string or bytes-like object 24\n"]}],"source":["data = []\n","for row in df.iterrows():\n","    text = row[1][\"text\"]\n","    try:\n","        system_prompt, dialogue_pairs = extract_dialogue_components(text)\n","        for pair in dialogue_pairs:\n","            prompt_sample = f\"{system_prompt}\\n\\n{pair}\"\n","            data.append(prompt_sample)\n","    except Exception as ex:\n","        print(ex, row[0])"]},{"cell_type":"markdown","id":"383a4777","metadata":{"papermill":{"duration":0.011556,"end_time":"2024-09-22T10:26:16.121075","exception":false,"start_time":"2024-09-22T10:26:16.109519","status":"completed"},"tags":[]},"source":["## Template utility function\n","\n","\n","We use this function to reformat the output of our queries, so that it is more user friendly.\n","\n","We replace and highlight the initial special tokens with more human-readable text (Instruction, Question, Answer)."]},{"cell_type":"code","execution_count":10,"id":"a34b1fdb","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:26:16.145906Z","iopub.status.busy":"2024-09-22T10:26:16.145604Z","iopub.status.idle":"2024-09-22T10:26:16.150547Z","shell.execute_reply":"2024-09-22T10:26:16.149761Z"},"papermill":{"duration":0.019401,"end_time":"2024-09-22T10:26:16.152388","exception":false,"start_time":"2024-09-22T10:26:16.132987","status":"completed"},"tags":[]},"outputs":[],"source":["def colorize_text(text):\n","    for word, formatted_word, color in zip([\"<|system|>:\", \"<|user|>:\", \"<|assistant|>:\"], \n","                                           [\"Instruction:\", \"Question:\", \"Answer:\"],\n","                                           [\"blue\", \"red\", \"green\"]):\n","        text = text.replace(f\"\\n\\n{word}\", f\"\\n\\n**<font color='{color}'>{formatted_word}</font>**\")\n","    return text"]},{"cell_type":"markdown","id":"7b0ebf02","metadata":{"papermill":{"duration":0.011676,"end_time":"2024-09-22T10:26:16.175808","exception":false,"start_time":"2024-09-22T10:26:16.164132","status":"completed"},"tags":[]},"source":["# Specialized class to query Gemma\n","\n","\n","We define a specialized class to query Gemma. But first, we need to initialize an object of GemmaCausalLM class."]},{"cell_type":"markdown","id":"715f96eb","metadata":{"papermill":{"duration":0.011621,"end_time":"2024-09-22T10:26:16.19974","exception":false,"start_time":"2024-09-22T10:26:16.188119","status":"completed"},"tags":[]},"source":["## Initialize the code for Gemma Causal LM"]},{"cell_type":"code","execution_count":11,"id":"eeb1f9d3","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:26:16.224683Z","iopub.status.busy":"2024-09-22T10:26:16.224387Z","iopub.status.idle":"2024-09-22T10:27:28.891656Z","shell.execute_reply":"2024-09-22T10:27:28.890792Z"},"papermill":{"duration":72.682109,"end_time":"2024-09-22T10:27:28.893681","exception":false,"start_time":"2024-09-22T10:26:16.211572","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n","└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n","└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n","└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n","│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n","│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n","└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["gemma_causal_lm = keras_nlp.models.GemmaCausalLM.from_preset(Config.preset)\n","gemma_causal_lm.summary()"]},{"cell_type":"markdown","id":"2346fd84","metadata":{"papermill":{"duration":0.012967,"end_time":"2024-09-22T10:27:28.920125","exception":false,"start_time":"2024-09-22T10:27:28.907158","status":"completed"},"tags":[]},"source":["## Define the specialized class\n","\n","Here we define the special class `GemmaQA`. \n","in the `__init__` we pass the `GemmaCausalLM` object created before.\n","The `query` member function uses `GemmaCausalLM` member function `generate` to generate the answer, based on a prompt that includes the category and the question."]},{"cell_type":"code","execution_count":12,"id":"faa48543","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:27:28.948372Z","iopub.status.busy":"2024-09-22T10:27:28.947564Z","iopub.status.idle":"2024-09-22T10:27:28.953866Z","shell.execute_reply":"2024-09-22T10:27:28.952971Z"},"papermill":{"duration":0.022576,"end_time":"2024-09-22T10:27:28.9558","exception":false,"start_time":"2024-09-22T10:27:28.933224","status":"completed"},"tags":[]},"outputs":[],"source":["template = \"\\n\\n<|system|>:\\n{instruct}\\n\\n<|user|>:\\n{question}\\n\\n<|assistant|>:\\n{answer}\"\n","class GemmaQA:\n","    def __init__(self, max_length=512):\n","        self.max_length = max_length\n","        self.prompt = template\n","        self.gemma_causal_lm = gemma_causal_lm\n","        \n","    def query(self, instruct, question):\n","        response = self.gemma_causal_lm.generate(\n","            self.prompt.format(\n","                instruct=instruct,\n","                question=question,\n","                answer=\"\"), \n","            max_length=self.max_length)\n","        display(Markdown(colorize_text(response)))\n","        "]},{"cell_type":"markdown","id":"c4a9ed69","metadata":{"papermill":{"duration":0.012948,"end_time":"2024-09-22T10:27:28.981813","exception":false,"start_time":"2024-09-22T10:27:28.968865","status":"completed"},"tags":[]},"source":["## Gemma preprocessor\n","\n","\n","This preprocessing layer will take in batches of strings, and return outputs in a ```(x, y, sample_weight)``` format, where the y label is the next token id in the x sequence.\n","\n","From the code below, we can see that, after the preprocessor, the data shape is ```(num_samples, sequence_length)```."]},{"cell_type":"code","execution_count":13,"id":"e13e1033","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:27:29.009919Z","iopub.status.busy":"2024-09-22T10:27:29.009563Z","iopub.status.idle":"2024-09-22T10:27:29.106828Z","shell.execute_reply":"2024-09-22T10:27:29.106016Z"},"papermill":{"duration":0.113928,"end_time":"2024-09-22T10:27:29.109079","exception":false,"start_time":"2024-09-22T10:27:28.995151","status":"completed"},"tags":[]},"outputs":[],"source":["x, y, sample_weight = gemma_causal_lm.preprocessor(data[0:2])"]},{"cell_type":"code","execution_count":14,"id":"0fc0016d","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:27:29.137932Z","iopub.status.busy":"2024-09-22T10:27:29.137281Z","iopub.status.idle":"2024-09-22T10:27:29.205279Z","shell.execute_reply":"2024-09-22T10:27:29.204279Z"},"papermill":{"duration":0.084751,"end_time":"2024-09-22T10:27:29.20736","exception":false,"start_time":"2024-09-22T10:27:29.122609","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["{'token_ids': Array([[     2, 235322, 235371, ...,      0,      0,      0],\n","       [     2, 235322, 235371, ...,      0,      0,      0]],      dtype=int32), 'padding_mask': Array([[ True,  True,  True, ..., False, False, False],\n","       [ True,  True,  True, ..., False, False, False]], dtype=bool)} [[235322 235371   9020 ...      0      0      0]\n"," [235322 235371   9020 ...      0      0      0]]\n"]}],"source":["print(x, y)"]},{"cell_type":"markdown","id":"5f357792","metadata":{"papermill":{"duration":0.013271,"end_time":"2024-09-22T10:27:29.233974","exception":false,"start_time":"2024-09-22T10:27:29.220703","status":"completed"},"tags":[]},"source":["# Perform fine-tuning with LoRA"]},{"cell_type":"markdown","id":"be99776c","metadata":{"papermill":{"duration":0.012909,"end_time":"2024-09-22T10:27:29.260044","exception":false,"start_time":"2024-09-22T10:27:29.247135","status":"completed"},"tags":[]},"source":["## Enable LoRA for the model\n","\n","LoRA rank is setting the number of trainable parameters. A larger rank will result in a larger number of parameters to train."]},{"cell_type":"code","execution_count":15,"id":"12a1454e","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:27:29.287797Z","iopub.status.busy":"2024-09-22T10:27:29.28742Z","iopub.status.idle":"2024-09-22T10:27:29.572012Z","shell.execute_reply":"2024-09-22T10:27:29.571108Z"},"papermill":{"duration":0.300894,"end_time":"2024-09-22T10:27:29.573988","exception":false,"start_time":"2024-09-22T10:27:29.273094","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n","└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n","└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n","└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n","│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n","│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n","└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["# Enable LoRA for the model and set the LoRA rank to the lora_rank as set in Config (4).\n","gemma_causal_lm.backbone.enable_lora(rank=Config.lora_rank)\n","gemma_causal_lm.summary()"]},{"cell_type":"markdown","id":"2010a53a","metadata":{"papermill":{"duration":0.014331,"end_time":"2024-09-22T10:27:29.640249","exception":false,"start_time":"2024-09-22T10:27:29.625918","status":"completed"},"tags":[]},"source":["We see that only a small part of the parameters are trainable. 2.6 billions parameters total, and only 2.9 Millions parameters trainable."]},{"cell_type":"markdown","id":"af55aeb3","metadata":{"papermill":{"duration":0.014204,"end_time":"2024-09-22T10:27:29.669192","exception":false,"start_time":"2024-09-22T10:27:29.654988","status":"completed"},"tags":[]},"source":["## Run the training sequence\n","\n","We set the `sequence_length` for the `GemmaCausalLM` (from configuration, will be 512).\n","We compile the model, with the loss, optimizer and metric.\n","For the metric, it is used `SparseCategoricalAccuracy`. This metric calculates how often predictions match integer labels."]},{"cell_type":"code","execution_count":16,"id":"9408ef59","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:27:29.700903Z","iopub.status.busy":"2024-09-22T10:27:29.700494Z","iopub.status.idle":"2024-09-22T10:48:31.211194Z","shell.execute_reply":"2024-09-22T10:48:31.210095Z"},"papermill":{"duration":1261.528477,"end_time":"2024-09-22T10:48:31.213394","exception":false,"start_time":"2024-09-22T10:27:29.684917","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6000\n","Epoch 2/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 822ms/step - loss: 0.4543 - sparse_categorical_accuracy: 0.6731\n","Epoch 3/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 862ms/step - loss: 0.4119 - sparse_categorical_accuracy: 0.6953\n","Epoch 4/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.3609 - sparse_categorical_accuracy: 0.7244\n","Epoch 5/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.3017 - sparse_categorical_accuracy: 0.7671\n","Epoch 6/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.2397 - sparse_categorical_accuracy: 0.8144\n","Epoch 7/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.1915 - sparse_categorical_accuracy: 0.8576\n","Epoch 8/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.1580 - sparse_categorical_accuracy: 0.8815\n","Epoch 9/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.1303 - sparse_categorical_accuracy: 0.9035\n","Epoch 10/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.1049 - sparse_categorical_accuracy: 0.9223\n","Epoch 11/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.0843 - sparse_categorical_accuracy: 0.9414\n","Epoch 12/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.0669 - sparse_categorical_accuracy: 0.9533\n","Epoch 13/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9614\n","Epoch 14/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9660\n","Epoch 15/15\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 822ms/step - loss: 0.0417 - sparse_categorical_accuracy: 0.9711\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x7b529c5b8df0>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["#set sequence length cf. config (896)\n","gemma_causal_lm.preprocessor.sequence_length = Config.sequence_length \n","\n","# Compile the model with loss, optimizer, and metric\n","gemma_causal_lm.compile(\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=keras.optimizers.Adam(learning_rate=Config.learning_rate),\n","    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",")\n","\n","# Train model\n","gemma_causal_lm.fit(data, epochs=Config.epochs, batch_size=Config.batch_size)"]},{"cell_type":"markdown","id":"06548bf6","metadata":{"papermill":{"duration":0.134379,"end_time":"2024-09-22T10:48:31.482065","exception":false,"start_time":"2024-09-22T10:48:31.347686","status":"completed"},"tags":[]},"source":["We obtained a rather good accuracy after the 15 steps of fine-tuning."]},{"cell_type":"markdown","id":"b21b57a0","metadata":{"papermill":{"duration":0.133352,"end_time":"2024-09-22T10:48:31.749187","exception":false,"start_time":"2024-09-22T10:48:31.615835","status":"completed"},"tags":[]},"source":["# Test the fine-tuned model\n","\n","We instantiate an object of class GemmaQA. Because `gemma_causal_lm` was fine-tuned using LoRA, `gemma_qa` defined here will use the fine-tuned model."]},{"cell_type":"code","execution_count":17,"id":"f8df2289","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:48:32.047018Z","iopub.status.busy":"2024-09-22T10:48:32.046115Z","iopub.status.idle":"2024-09-22T10:48:32.053405Z","shell.execute_reply":"2024-09-22T10:48:32.052304Z"},"papermill":{"duration":0.155741,"end_time":"2024-09-22T10:48:32.055724","exception":false,"start_time":"2024-09-22T10:48:31.899983","status":"completed"},"tags":[]},"outputs":[],"source":["gemma_qa = GemmaQA()"]},{"cell_type":"markdown","id":"52da2e73","metadata":{"papermill":{"duration":0.14767,"end_time":"2024-09-22T10:48:32.359847","exception":false,"start_time":"2024-09-22T10:48:32.212177","status":"completed"},"tags":[]},"source":["For start, we are testing the model with some of the data from the training set itself."]},{"cell_type":"markdown","id":"da4d9a32","metadata":{"papermill":{"duration":0.130243,"end_time":"2024-09-22T10:48:32.672882","exception":false,"start_time":"2024-09-22T10:48:32.542639","status":"completed"},"tags":[]},"source":["## Sample 1"]},{"cell_type":"code","execution_count":18,"id":"1d805101","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:48:32.937084Z","iopub.status.busy":"2024-09-22T10:48:32.936658Z","iopub.status.idle":"2024-09-22T10:48:49.223176Z","shell.execute_reply":"2024-09-22T10:48:49.222089Z"},"papermill":{"duration":16.420925,"end_time":"2024-09-22T10:48:49.225195","exception":false,"start_time":"2024-09-22T10:48:32.80427","status":"completed"},"tags":[]},"outputs":[{"data":{"text/markdown":["\n","\n","**<font color='blue'>Instruction:</font>**\n","Sherlock the renowned detective from Baker Street is known for his astute logical reasoning disguise ability and use of forensic science to solve perplexing crimes\n","\n","**<font color='red'>Question:</font>**\n","What's Sherlock secret to solving crimes?\n","\n","**<font color='green'>Answer:</font>**\n","Ah, method and madness! I am driven by a relentless pursuit of truth and order my observations are meticulously recorded and analyzed resulting in paradigm-shifting revelations"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["gemma_qa = GemmaQA(max_length=96)\n","instruct = \"Sherlock the renowned detective from Baker Street is known for his astute logical reasoning disguise ability and use of forensic science to solve perplexing crimes\"\n","question = \"What's Sherlock secret to solving crimes?\"\n","gemma_qa.query(instruct, question)"]},{"cell_type":"markdown","id":"2af8692f","metadata":{"papermill":{"duration":0.13487,"end_time":"2024-09-22T10:48:49.494386","exception":false,"start_time":"2024-09-22T10:48:49.359516","status":"completed"},"tags":[]},"source":["## Not seen question(s)"]},{"cell_type":"code","execution_count":19,"id":"8d19c17c","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:48:49.762262Z","iopub.status.busy":"2024-09-22T10:48:49.761865Z","iopub.status.idle":"2024-09-22T10:49:07.63568Z","shell.execute_reply":"2024-09-22T10:49:07.634706Z"},"papermill":{"duration":18.010627,"end_time":"2024-09-22T10:49:07.637819","exception":false,"start_time":"2024-09-22T10:48:49.627192","status":"completed"},"tags":[]},"outputs":[{"data":{"text/markdown":["\n","\n","**<font color='blue'>Instruction:</font>**\n","Sherlock the renowned detective from Baker Street is known for his astute logical reasoning disguise ability and use of forensic science to solve perplexing crimes\n","\n","**<font color='red'>Question:</font>**\n","How is able Sherlock to be so succesfull in solving crimes?\n","\n","**<font color='green'>Answer:</font>**\n","Well, its due to his keen eye for detail and his unyielding abiliy to think critiacally. He uses forensc science and his own observational abilitie to piecel togther the clues and uncovr the truth\n","\n","**<font color='red'>Question:</font>**\n","Can you give an example of one of your cricical"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["gemma_qa = GemmaQA(max_length=128)\n","instruct = \"Sherlock the renowned detective from Baker Street is known for his astute logical reasoning disguise ability and use of forensic science to solve perplexing crimes\"\n","question = \"How is able Sherlock to be so succesfull in solving crimes?\"\n","gemma_qa.query(instruct, question)"]},{"cell_type":"code","execution_count":20,"id":"f775f267","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:49:07.905654Z","iopub.status.busy":"2024-09-22T10:49:07.904721Z","iopub.status.idle":"2024-09-22T10:49:09.533118Z","shell.execute_reply":"2024-09-22T10:49:09.532155Z"},"papermill":{"duration":1.763904,"end_time":"2024-09-22T10:49:09.535337","exception":false,"start_time":"2024-09-22T10:49:07.771433","status":"completed"},"tags":[]},"outputs":[{"data":{"text/markdown":["\n","\n","**<font color='blue'>Instruction:</font>**\n","Serena is a professional tennis legend known for her powerful game and unparalleled record of Grand Slam victories dominating womens tennis with her skill and strength\n","\n","**<font color='red'>Question:</font>**\n","How is Serena Williams play against Simona Halep?\n","\n","**<font color='green'>Answer:</font>**\n","Simona Halep is a formidable opponent with her own blend of skill and speed but Serena's dominance in Grand Slam matches remains unparalleled her precision and power often proving too much for her rivals.</blockquote>"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["instruct = df.description.values[1]\n","question = \"How is Serena Williams play against Simona Halep?\"\n","\n","gemma_qa.query(instruct,question)"]},{"cell_type":"code","execution_count":21,"id":"22619f4b","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:49:09.80487Z","iopub.status.busy":"2024-09-22T10:49:09.803687Z","iopub.status.idle":"2024-09-22T10:49:29.000192Z","shell.execute_reply":"2024-09-22T10:49:28.999219Z"},"papermill":{"duration":19.333229,"end_time":"2024-09-22T10:49:29.00224","exception":false,"start_time":"2024-09-22T10:49:09.669011","status":"completed"},"tags":[]},"outputs":[{"data":{"text/markdown":["\n","\n","**<font color='blue'>Instruction:</font>**\n","Beethoven is a classical composer and pianist a crucial figure in the transition between the classical and romantic eras in Western music known for his symphonies and sonatas\n","\n","**<font color='red'>Question:</font>**\n","How will Beethoven solve the equation system x + 1 = 2?\n","\n","**<font color='green'>Answer:</font>**\n","Ah, the solution is x = 1, my friend. Quite simple, isn't it?</s>\n","\n","**<font color='red'>Question:</font>**\n","Can you improvise a melody to match the mood of a passionate love sonata?</s>\n","\n","**<font color='green'>Answer:</font>**\n","Certainly! Let's see... Ah, the melody should soar with the expressiveness of the love-filled notes, wouldn't you say? Try this: Allegro, ma non troppo, con passione.</s>"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["gemma_qa = GemmaQA(max_length=256)\n","instruct = df.description.values[2]\n","question = \"How will Beethoven solve the equation system x + 1 = 2?\"\n","\n","gemma_qa.query(instruct,question)"]},{"cell_type":"code","execution_count":22,"id":"a93ca188","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:49:29.272238Z","iopub.status.busy":"2024-09-22T10:49:29.271814Z","iopub.status.idle":"2024-09-22T10:49:45.509476Z","shell.execute_reply":"2024-09-22T10:49:45.508593Z"},"papermill":{"duration":16.375055,"end_time":"2024-09-22T10:49:45.511605","exception":false,"start_time":"2024-09-22T10:49:29.13655","status":"completed"},"tags":[]},"outputs":[{"data":{"text/markdown":["\n","\n","**<font color='blue'>Instruction:</font>**\n","Michael Jordan an NBA legend known for his competitive drive six championship wins with the Chicago Bulls and global influence on the sport of basketball\n","\n","**<font color='red'>Question:</font>**\n","How will Michael Jordan knitt a sweater?\n","\n","**<font color='green'>Answer:</font>**\n","Michael Jordan knitt sweaters as a hobby a testament to his precision and attention to detail he knits intricate and stylish sweaters often incorporating his own brand or team logos into the"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["gemma_qa = GemmaQA(max_length=90)\n","instruct = df.description.values[10]\n","question = \"How will Michael Jordan knitt a sweater?\"\n","\n","gemma_qa.query(instruct,question)"]},{"cell_type":"markdown","id":"c5aa6525","metadata":{"papermill":{"duration":0.131814,"end_time":"2024-09-22T10:49:45.776683","exception":false,"start_time":"2024-09-22T10:49:45.644869","status":"completed"},"tags":[]},"source":["# Save the model"]},{"cell_type":"code","execution_count":23,"id":"8d657af6","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:49:46.043341Z","iopub.status.busy":"2024-09-22T10:49:46.042952Z","iopub.status.idle":"2024-09-22T10:50:17.390641Z","shell.execute_reply":"2024-09-22T10:50:17.389464Z"},"papermill":{"duration":31.483643,"end_time":"2024-09-22T10:50:17.39304","exception":false,"start_time":"2024-09-22T10:49:45.909397","status":"completed"},"tags":[]},"outputs":[],"source":["preset_dir = \".\\gemma2_2b_en_roleplay\"\n","gemma_causal_lm.save_to_preset(preset_dir)"]},{"cell_type":"markdown","id":"85ac6df1","metadata":{"papermill":{"duration":0.23225,"end_time":"2024-09-22T10:50:28.963187","exception":false,"start_time":"2024-09-22T10:50:28.730937","status":"completed"},"tags":[]},"source":["# Publish Model on Kaggle as a Kaggle Model\n","\n","We are publishing now the saved model as a Kaggle Model."]},{"cell_type":"code","execution_count":24,"id":"ad2c6a46","metadata":{"execution":{"iopub.execute_input":"2024-09-22T10:50:29.282418Z","iopub.status.busy":"2024-09-22T10:50:29.281685Z","iopub.status.idle":"2024-09-22T10:53:25.927875Z","shell.execute_reply":"2024-09-22T10:53:25.92693Z"},"papermill":{"duration":176.800681,"end_time":"2024-09-22T10:53:25.930349","exception":false,"start_time":"2024-09-22T10:50:29.129668","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Uploading Model https://www.kaggle.com/models/gpreda/gemma2_2b_en_roleplay/keras/gemma2_2b_en_roleplay ...\n","Model 'gemma2_2b_en_roleplay' does not exist or access is forbidden for user 'gpreda'. Creating or handling Model...\n","Model 'gemma2_2b_en_roleplay' Created.\n","Starting upload for file .\\gemma2_2b_en_roleplay/metadata.json\n"]},{"name":"stderr","output_type":"stream","text":["Uploading: 100%|██████████| 143/143 [00:00<00:00, 220B/s]"]},{"name":"stdout","output_type":"stream","text":["Upload successful: .\\gemma2_2b_en_roleplay/metadata.json (143B)\n","Starting upload for file .\\gemma2_2b_en_roleplay/config.json\n"]},{"name":"stderr","output_type":"stream","text":["\n","Uploading: 100%|██████████| 782/782 [00:00<00:00, 1.30kB/s]"]},{"name":"stdout","output_type":"stream","text":["Upload successful: .\\gemma2_2b_en_roleplay/config.json (782B)\n","Starting upload for file .\\gemma2_2b_en_roleplay/preprocessor.json\n"]},{"name":"stderr","output_type":"stream","text":["\n","Uploading: 100%|██████████| 1.32k/1.32k [00:00<00:00, 2.08kB/s]"]},{"name":"stdout","output_type":"stream","text":["Upload successful: .\\gemma2_2b_en_roleplay/preprocessor.json (1KB)\n","Starting upload for file .\\gemma2_2b_en_roleplay/task.json\n"]},{"name":"stderr","output_type":"stream","text":["\n","Uploading: 100%|██████████| 2.87k/2.87k [00:00<00:00, 4.68kB/s]"]},{"name":"stdout","output_type":"stream","text":["Upload successful: .\\gemma2_2b_en_roleplay/task.json (3KB)\n","Starting upload for file .\\gemma2_2b_en_roleplay/tokenizer.json\n"]},{"name":"stderr","output_type":"stream","text":["\n","Uploading: 100%|██████████| 550/550 [00:00<00:00, 892B/s]"]},{"name":"stdout","output_type":"stream","text":["Upload successful: .\\gemma2_2b_en_roleplay/tokenizer.json (550B)\n","Starting upload for file .\\gemma2_2b_en_roleplay/model.weights.h5\n"]},{"name":"stderr","output_type":"stream","text":["\n","Uploading: 100%|██████████| 10.5G/10.5G [02:47<00:00, 62.3MB/s]"]},{"name":"stdout","output_type":"stream","text":["Upload successful: .\\gemma2_2b_en_roleplay/model.weights.h5 (10GB)\n","Starting upload for file .\\gemma2_2b_en_roleplay/assets/tokenizer/vocabulary.spm\n"]},{"name":"stderr","output_type":"stream","text":["\n","Uploading: 100%|██████████| 4.24M/4.24M [00:00<00:00, 5.52MB/s]"]},{"name":"stdout","output_type":"stream","text":["Upload successful: .\\gemma2_2b_en_roleplay/assets/tokenizer/vocabulary.spm (4MB)\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Your model instance has been created.\n","Files are being processed...\n","See at: https://www.kaggle.com/models/gpreda/gemma2_2b_en_roleplay/keras/gemma2_2b_en_roleplay\n"]}],"source":["kaggle_username = os.environ[\"KAGGLE_USERNAME\"]\n","\n","kaggle_uri = f\"kaggle://{kaggle_username}/gemma2_2b_en_roleplay/keras/gemma2_2b_en_roleplay\"\n","keras_nlp.upload_preset(kaggle_uri, preset_dir)\n"]},{"cell_type":"markdown","id":"5f552e59","metadata":{"papermill":{"duration":0.231223,"end_time":"2024-09-22T10:53:26.386342","exception":false,"start_time":"2024-09-22T10:53:26.155119","status":"completed"},"tags":[]},"source":["# Conclusions\n","\n"]},{"cell_type":"markdown","id":"3fc66fb5","metadata":{"papermill":{"duration":0.218912,"end_time":"2024-09-22T10:53:26.827266","exception":false,"start_time":"2024-09-22T10:53:26.608354","status":"completed"},"tags":[]},"source":["We demonstated how to fine-tune a **Gemma 2** model using LoRA.  \n","\n","We also created a class to run queries to the **Gemma 2** model and tested it with some examples from the existing training data but also with some new, not seen questions.   \n","\n","At the end, we published the model as a Kaggle Model using `kagglehub`."]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5729234,"sourceId":9430417,"sourceType":"datasetVersion"},{"modelId":78150,"modelInstanceId":72244,"sourceId":85984,"sourceType":"modelInstanceVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":1695.56607,"end_time":"2024-09-22T10:53:30.608447","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-22T10:25:15.042377","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}