{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0493822",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.007157,
     "end_time": "2024-03-31T11:37:37.051644",
     "exception": false,
     "start_time": "2024-03-31T11:37:37.044487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><h1>Gemma, please teach me Data Science!</h1></center>\n",
    "\n",
    "<center><img src=\"https://res.infoq.com/news/2024/02/google-gemma-open-model/en/headerimage/generatedHeaderImage-1708977571481.jpg\" width=\"400\"></center>\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This notebook aims to show how we can, with a very simple approach, to exploit the rich information that Gemma already acquired through training and answer questions about Data Science. \n",
    "\n",
    "**Let's go**!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405771e2",
   "metadata": {
    "papermill": {
     "duration": 0.006346,
     "end_time": "2024-03-31T11:37:37.064580",
     "exception": false,
     "start_time": "2024-03-31T11:37:37.058234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install resources\n",
    "\n",
    "We start with few logistic steps, installing the needed resources and preparing our tools.\n",
    "\n",
    "We will use Gemma through Keras interface.\n",
    "\n",
    "## Install Keras NLP and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d2420e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:37:37.078793Z",
     "iopub.status.busy": "2024-03-31T11:37:37.078469Z",
     "iopub.status.idle": "2024-03-31T11:38:08.364400Z",
     "shell.execute_reply": "2024-03-31T11:38:08.363493Z"
    },
    "papermill": {
     "duration": 31.295867,
     "end_time": "2024-03-31T11:38:08.366835",
     "exception": false,
     "start_time": "2024-03-31T11:37:37.070968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.1.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f457c",
   "metadata": {
    "papermill": {
     "duration": 0.006597,
     "end_time": "2024-03-31T11:38:08.380469",
     "exception": false,
     "start_time": "2024-03-31T11:38:08.373872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01dffdf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:38:08.395356Z",
     "iopub.status.busy": "2024-03-31T11:38:08.395056Z",
     "iopub.status.idle": "2024-03-31T11:38:22.024174Z",
     "shell.execute_reply": "2024-03-31T11:38:22.023359Z"
    },
    "papermill": {
     "duration": 13.639327,
     "end_time": "2024-03-31T11:38:22.026584",
     "exception": false,
     "start_time": "2024-03-31T11:38:08.387257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 11:38:10.223282: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-31 11:38:10.223400: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-31 11:38:10.354866: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e2bd0",
   "metadata": {
    "papermill": {
     "duration": 0.006809,
     "end_time": "2024-03-31T11:38:22.040795",
     "exception": false,
     "start_time": "2024-03-31T11:38:22.033986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup some environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2025e72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:38:22.058048Z",
     "iopub.status.busy": "2024-03-31T11:38:22.057390Z",
     "iopub.status.idle": "2024-03-31T11:38:22.062507Z",
     "shell.execute_reply": "2024-03-31T11:38:22.061621Z"
    },
    "papermill": {
     "duration": 0.016688,
     "end_time": "2024-03-31T11:38:22.064646",
     "exception": false,
     "start_time": "2024-03-31T11:38:22.047958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the desired backend for Keras. Options: \"jax\", \"tensorflow\", or \"torch\".\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Adjust as needed.\n",
    "\n",
    "# Specific to the JAX backend, this setting helps avoid memory fragmentation, ensuring more efficient resource use.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016aff1",
   "metadata": {
    "papermill": {
     "duration": 0.007209,
     "end_time": "2024-03-31T11:38:22.079418",
     "exception": false,
     "start_time": "2024-03-31T11:38:22.072209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utility for formatting the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d888e713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:38:22.095591Z",
     "iopub.status.busy": "2024-03-31T11:38:22.095283Z",
     "iopub.status.idle": "2024-03-31T11:38:22.100318Z",
     "shell.execute_reply": "2024-03-31T11:38:22.099528Z"
    },
    "papermill": {
     "duration": 0.015536,
     "end_time": "2024-03-31T11:38:22.102469",
     "exception": false,
     "start_time": "2024-03-31T11:38:22.086933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Reasoning\", \"Question\", \"Answer\"], [\"blue\", \"red\", \"green\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b26cc7",
   "metadata": {
    "papermill": {
     "duration": 0.007433,
     "end_time": "2024-03-31T11:38:22.117080",
     "exception": false,
     "start_time": "2024-03-31T11:38:22.109647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Gemma Causal LM\n",
    "\n",
    "We will try for this application `gemma_instruct_2b_en`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468b1b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:38:22.132997Z",
     "iopub.status.busy": "2024-03-31T11:38:22.132500Z",
     "iopub.status.idle": "2024-03-31T11:39:20.584930Z",
     "shell.execute_reply": "2024-03-31T11:39:20.584027Z"
    },
    "papermill": {
     "duration": 58.462877,
     "end_time": "2024-03-31T11:39:20.587253",
     "exception": false,
     "start_time": "2024-03-31T11:38:22.124376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122b918c",
   "metadata": {
    "papermill": {
     "duration": 0.007519,
     "end_time": "2024-03-31T11:39:20.602613",
     "exception": false,
     "start_time": "2024-03-31T11:39:20.595094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup the Q&A class\n",
    "\n",
    "\n",
    "We will setup a class for querying directly the Gemma model about Data Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f83d5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:39:20.619385Z",
     "iopub.status.busy": "2024-03-31T11:39:20.618619Z",
     "iopub.status.idle": "2024-03-31T11:39:20.625022Z",
     "shell.execute_reply": "2024-03-31T11:39:20.624177Z"
    },
    "papermill": {
     "duration": 0.016703,
     "end_time": "2024-03-31T11:39:20.626846",
     "exception": false,
     "start_time": "2024-03-31T11:39:20.610143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GemmaQA:\n",
    "    def __init__(self, max_length=512):\n",
    "        self.max_length = max_length\n",
    "        self.prompt = \"\"\"\n",
    "            You are an AI assistant designed to answer questions about Data Science.\n",
    "            Reasoning: If the question is not related to Data Science, simply state politely this.\n",
    "            If it is a complex question, think step by step. If needed, include your reasoning process.\n",
    "            Question: {question}\n",
    "            Answer:\n",
    "        \"\"\"\n",
    "        self.gemma_lm = gemma_lm\n",
    "        \n",
    "    def query(self, question):\n",
    "        response = self.gemma_lm.generate(\n",
    "            self.prompt.format(\n",
    "                question=question), \n",
    "            max_length=self.max_length)\n",
    "        display(Markdown(colorize_text(response)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7396ff",
   "metadata": {
    "papermill": {
     "duration": 0.007295,
     "end_time": "2024-03-31T11:39:20.641418",
     "exception": false,
     "start_time": "2024-03-31T11:39:20.634123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's initialize the class. \n",
    "\n",
    "If we are not giving any parameters, the default initialization with `max_length` = 512 will be used.\n",
    "\n",
    "Let's use instead initialization with `max_length` = 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a92805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:39:20.658649Z",
     "iopub.status.busy": "2024-03-31T11:39:20.657179Z",
     "iopub.status.idle": "2024-03-31T11:39:20.662246Z",
     "shell.execute_reply": "2024-03-31T11:39:20.661420Z"
    },
    "papermill": {
     "duration": 0.015363,
     "end_time": "2024-03-31T11:39:20.664063",
     "exception": false,
     "start_time": "2024-03-31T11:39:20.648700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma_qanda = GemmaQA(max_length=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943be5e",
   "metadata": {
    "papermill": {
     "duration": 0.007012,
     "end_time": "2024-03-31T11:39:20.678469",
     "exception": false,
     "start_time": "2024-03-31T11:39:20.671457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test the model - ask few questions on Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56ecbef",
   "metadata": {
    "papermill": {
     "duration": 0.007175,
     "end_time": "2024-03-31T11:39:20.692884",
     "exception": false,
     "start_time": "2024-03-31T11:39:20.685709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Question 1: Ask about sklearn\n",
    "\n",
    "Let's test first with a simple question about `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f6b7da5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:39:20.708839Z",
     "iopub.status.busy": "2024-03-31T11:39:20.708545Z",
     "iopub.status.idle": "2024-03-31T11:39:44.817678Z",
     "shell.execute_reply": "2024-03-31T11:39:44.816760Z"
    },
    "papermill": {
     "duration": 24.119815,
     "end_time": "2024-03-31T11:39:44.819871",
     "exception": false,
     "start_time": "2024-03-31T11:39:20.700056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711885180.506119      27 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1711885180.573985      27 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
      "W0000 00:00:1711885180.720592      27 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "            You are an AI assistant designed to answer questions about Data Science.\n",
       "            \n",
       "\n",
       "**<font color='blue'>Reasoning:</font>** If the question is not related to Data Science, simply state politely this.\n",
       "            If it is a complex question, think step by step. If needed, include your reasoning process.\n",
       "            \n",
       "\n",
       "**<font color='red'>Question:</font>** Please teach me how to do a train test split using sklearn\n",
       "            \n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "        Sure, here's a step-by-step explanation of how to perform a train-test split using the scikit-learn library in Python:\n",
       "\n",
       "**Step 1: Import the necessary libraries**\n",
       "\n",
       "```python\n",
       "import sklearn.model_selection as train_test_split\n",
       "```\n",
       "\n",
       "**Step 2: Load your data**\n",
       "\n",
       "```python\n",
       "X_train, X_test, y_train, y_test = train_test_split.train_test_split(X, y, test_size=0.2)\n",
       "```\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "* `train_test_split` is a function from the `sklearn.model_selection` module that performs the train-test split.\n",
       "* `X` is the feature data.\n",
       "* `y` is the target data.\n",
       "* `test_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_qanda.query(\"Please teach me how to do a train test split using sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d28482",
   "metadata": {
    "papermill": {
     "duration": 0.007438,
     "end_time": "2024-03-31T11:39:44.835332",
     "exception": false,
     "start_time": "2024-03-31T11:39:44.827894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Doesn't look fine, isn't it? Let's get back to the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13638e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:39:44.852187Z",
     "iopub.status.busy": "2024-03-31T11:39:44.851871Z",
     "iopub.status.idle": "2024-03-31T11:39:44.855996Z",
     "shell.execute_reply": "2024-03-31T11:39:44.855133Z"
    },
    "papermill": {
     "duration": 0.014788,
     "end_time": "2024-03-31T11:39:44.857949",
     "exception": false,
     "start_time": "2024-03-31T11:39:44.843161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma_qanda = GemmaQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d4ee9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:39:44.874506Z",
     "iopub.status.busy": "2024-03-31T11:39:44.874219Z",
     "iopub.status.idle": "2024-03-31T11:40:13.923247Z",
     "shell.execute_reply": "2024-03-31T11:40:13.922259Z"
    },
    "papermill": {
     "duration": 29.059351,
     "end_time": "2024-03-31T11:40:13.925297",
     "exception": false,
     "start_time": "2024-03-31T11:39:44.865946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1711885203.887906      27 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "            You are an AI assistant designed to answer questions about Data Science.\n",
       "            \n",
       "\n",
       "**<font color='blue'>Reasoning:</font>** If the question is not related to Data Science, simply state politely this.\n",
       "            If it is a complex question, think step by step. If needed, include your reasoning process.\n",
       "            \n",
       "\n",
       "**<font color='red'>Question:</font>** Please teach me how to do a train test split using sklearn\n",
       "            \n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "        Sure, here's a step-by-step explanation of how to perform a train-test split using the scikit-learn library in Python:\n",
       "\n",
       "**Step 1: Import the necessary libraries**\n",
       "\n",
       "```python\n",
       "import sklearn.model_selection as train_test_split\n",
       "```\n",
       "\n",
       "**Step 2: Load your data**\n",
       "\n",
       "```python\n",
       "X_train, X_test, y_train, y_test = train_test_split.train_test_split(X, y, test_size=0.2)\n",
       "```\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "* `train_test_split` is a function from the `sklearn.model_selection` module that performs the train-test split.\n",
       "* `X` is the feature data.\n",
       "* `y` is the target data.\n",
       "* `test_size` is the size of the test set. In this case, we set it to 20% of the data.\n",
       "\n",
       "**Step 3: Split the data into training and testing sets**\n",
       "\n",
       "The `train_test_split` function returns a tuple containing the training and testing sets.\n",
       "\n",
       "* `X_train` contains the training data.\n",
       "* `y_train` contains the corresponding target data for the training set.\n",
       "* `X_test` contains the testing data.\n",
       "* `y_test` contains the corresponding target data for the testing set.\n",
       "\n",
       "**Step 4: Check the split**\n",
       "\n",
       "You can check the split by printing the shape of the training and testing sets:\n",
       "\n",
       "```python\n",
       "print(f\"Number of training samples: {len(X_train)}\")\n",
       "print(f\"Number of testing samples: {len(X_test)}\")\n",
       "```\n",
       "\n",
       "**Step 5: Use the split data for training and testing**\n",
       "\n",
       "You can now use the split data for training your model and testing its performance on the held-out test set.\n",
       "\n",
       "**Additional Notes:**\n",
       "\n",
       "* You can adjust the `test_size` parameter to control the size of the test set.\n",
       "* You can"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_qanda.query(\"Please teach me how to do a train test split using sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf16a7",
   "metadata": {
    "papermill": {
     "duration": 0.007597,
     "end_time": "2024-03-31T11:40:13.941516",
     "exception": false,
     "start_time": "2024-03-31T11:40:13.933919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Question 2: Ask about bias and variance\n",
    "\n",
    "Now, let's ask something different. Will ask Gemma about bias and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "421c1642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:40:13.958222Z",
     "iopub.status.busy": "2024-03-31T11:40:13.957909Z",
     "iopub.status.idle": "2024-03-31T11:40:21.337351Z",
     "shell.execute_reply": "2024-03-31T11:40:21.336187Z"
    },
    "papermill": {
     "duration": 7.390844,
     "end_time": "2024-03-31T11:40:21.340157",
     "exception": false,
     "start_time": "2024-03-31T11:40:13.949313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "            You are an AI assistant designed to answer questions about Data Science.\n",
       "            \n",
       "\n",
       "**<font color='blue'>Reasoning:</font>** If the question is not related to Data Science, simply state politely this.\n",
       "            If it is a complex question, think step by step. If needed, include your reasoning process.\n",
       "            \n",
       "\n",
       "**<font color='red'>Question:</font>** Please explain to me the concepts of bias and variance\n",
       "            \n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "        Sure, here's a breakdown of the concepts of bias and variance:\n",
       "\n",
       "**Bias:**\n",
       "\n",
       "* Bias is a systematic error in a model that results from the training data.\n",
       "* It can be caused by factors such as:\n",
       "    * Choosing an inappropriate learning algorithm\n",
       "    * Using biased data\n",
       "    * Failing to account for important features\n",
       "* Bias can lead to unfair or inaccurate predictions.\n",
       "\n",
       "**Variance:**\n",
       "\n",
       "* Variance is a measure of how much the predicted value of a data point varies from one sample to another.\n",
       "* It can be calculated by looking at the spread of the data points in a distribution.\n",
       "* Higher variance indicates that the predicted value is more sensitive to changes in the data.\n",
       "\n",
       "**Relationship between bias and variance:**\n",
       "\n",
       "* Bias and variance are closely related. High bias can lead to high variance, while high variance can lead to high bias.\n",
       "* This is because bias can cause the model to make systematic errors, which can then be amplified by variance.\n",
       "\n",
       "**Example:**\n",
       "\n",
       "* A model that is biased towards a particular group of people may have high bias but low variance.\n",
       "* This is because the model is only making errors on a subset of the data, which is relatively consistent.\n",
       "\n",
       "**In summary:**\n",
       "\n",
       "* Bias is a systematic error in a model that results from the training data.\n",
       "* Variance is a measure of how much the predicted value of a data point varies from one sample to another.\n",
       "* Bias and variance are closely related, and high bias can lead to high variance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_qanda.query(\"Please explain to me the concepts of bias and variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf649d5",
   "metadata": {
    "papermill": {
     "duration": 0.011107,
     "end_time": "2024-03-31T11:40:21.366914",
     "exception": false,
     "start_time": "2024-03-31T11:40:21.355807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Question 3: Ask about Dropout\n",
    "\n",
    "Let's ask something from Deep Learning, more specific, about Dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d2dbe6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:40:21.390872Z",
     "iopub.status.busy": "2024-03-31T11:40:21.389751Z",
     "iopub.status.idle": "2024-03-31T11:40:29.828165Z",
     "shell.execute_reply": "2024-03-31T11:40:29.827147Z"
    },
    "papermill": {
     "duration": 8.45362,
     "end_time": "2024-03-31T11:40:29.830283",
     "exception": false,
     "start_time": "2024-03-31T11:40:21.376663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "            You are an AI assistant designed to answer questions about Data Science.\n",
       "            \n",
       "\n",
       "**<font color='blue'>Reasoning:</font>** If the question is not related to Data Science, simply state politely this.\n",
       "            If it is a complex question, think step by step. If needed, include your reasoning process.\n",
       "            \n",
       "\n",
       "**<font color='red'>Question:</font>** What is the role of Dropout layer added to a Deep Learning architecture?\n",
       "            \n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "        Sure, here's the answer to your question:\n",
       "\n",
       "**Role of Dropout Layer in Deep Learning Architecture:**\n",
       "\n",
       "The Dropout layer is a technique used in deep learning models to address overfitting and improve generalization performance. It involves randomly dropping out neurons or groups of neurons during training.\n",
       "\n",
       "**Step 1: Initialization:**\n",
       "- Before the model is trained, the dropout rate is set, which is a probability determined by the user.\n",
       "- The dropout layer randomly selects neurons to keep during each training iteration.\n",
       "- The number of neurons dropped out is equal to the dropout rate multiplied by the total number of neurons in the layer.\n",
       "\n",
       "**Step 2: Training:**\n",
       "- During training, the model randomly drops out neurons during each iteration.\n",
       "- This means that some neurons are not used for calculation during each step.\n",
       "- The model is essentially training a smaller subset of neurons, which can help to prevent overfitting.\n",
       "\n",
       "**Step 3: Backpropagation:**\n",
       "- Dropout is applied during backpropagation, the process by which the model updates its weights and biases to minimize the error between the model's predictions and the actual target values.\n",
       "- During backpropagation, the dropout layer helps to ensure that the model updates weights that are most relevant to the task at hand.\n",
       "\n",
       "**Benefits of Dropout:**\n",
       "\n",
       "- Reduces overfitting by preventing the model from memorizing specific training patterns.\n",
       "- Improves generalization performance by exposing the model to a wider range of data.\n",
       "- Reduces computational cost by reducing the number of computations required for backpropagation.\n",
       "\n",
       "**Conclusion:**\n",
       "\n",
       "The Dropout layer is an important technique in deep learning that helps to address overfitting and improve generalization performance. By randomly dropping out neurons during training, it forces the model to learn more robust representations of the data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_qanda.query(\"What is the role of Dropout layer added to a Deep Learning architecture?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7218b",
   "metadata": {
    "papermill": {
     "duration": 0.008417,
     "end_time": "2024-03-31T11:40:29.847686",
     "exception": false,
     "start_time": "2024-03-31T11:40:29.839269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Question 4: Ask about model calibration\n",
    "\n",
    "Now, let's ask a more advanced question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade7496e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T11:40:29.866401Z",
     "iopub.status.busy": "2024-03-31T11:40:29.866087Z",
     "iopub.status.idle": "2024-03-31T11:40:39.412533Z",
     "shell.execute_reply": "2024-03-31T11:40:39.411567Z"
    },
    "papermill": {
     "duration": 9.558719,
     "end_time": "2024-03-31T11:40:39.414778",
     "exception": false,
     "start_time": "2024-03-31T11:40:29.856059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "            You are an AI assistant designed to answer questions about Data Science.\n",
       "            \n",
       "\n",
       "**<font color='blue'>Reasoning:</font>** If the question is not related to Data Science, simply state politely this.\n",
       "            If it is a complex question, think step by step. If needed, include your reasoning process.\n",
       "            \n",
       "\n",
       "**<font color='red'>Question:</font>** Could you explain, in the context of Data Science, what is model calibration?\n",
       "            \n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "        Sure, here's a comprehensive explanation of model calibration in the context of Data Science:\n",
       "\n",
       "**Model Calibration**\n",
       "\n",
       "Model calibration is the process of adjusting the parameters of a machine learning model to improve its performance on unseen data. This is a crucial step in the data science workflow, as it ensures that the model is accurate and reliable.\n",
       "\n",
       "**Key Concepts:**\n",
       "\n",
       "* **Model Parameters:** These are the internal settings of the model that determine its behavior. For example, in linear regression, the model parameters are the slope and intercept.\n",
       "* **Calibration Data:** This is a set of data that is specifically designed to be difficult for the model to learn from. It is often used to fine-tune the model's parameters.\n",
       "* **Calibration Algorithm:** This is a set of instructions that guide the model to learn from the calibration data. There are various calibration algorithms available, each with its own strengths and weaknesses.\n",
       "* **Model Performance:** After calibration, the model is evaluated on a separate test dataset. This allows us to measure its accuracy and performance.\n",
       "\n",
       "**Steps in Model Calibration:**\n",
       "\n",
       "1. **Data Preparation:** Clean and prepare the calibration data for modeling.\n",
       "2. **Model Selection:** Choose an appropriate model for calibration.\n",
       "3. **Parameter Initialization:** Set the initial values of the model parameters.\n",
       "4. **Calibration Loop:**\n",
       "   a. Train the model on the calibration data.\n",
       "   b. Evaluate the model's performance on the validation data.\n",
       "   c. Adjust the model parameters based on the validation data.\n",
       "5. **Final Model:** After the calibration process is complete, the model is saved and used for prediction.\n",
       "\n",
       "**Benefits of Model Calibration:**\n",
       "\n",
       "* Improves model accuracy and performance.\n",
       "* Reduces overfitting and improvesgeneralizability.\n",
       "* Helps to identify and address model biases.\n",
       "\n",
       "**Note:** Model calibration can be a complex and iterative process, especially for complex models. The specific steps and algorithms used will vary depending on the model and the data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_qanda.query(\"Could you explain, in the context of Data Science, what is model calibration?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e3046",
   "metadata": {
    "papermill": {
     "duration": 0.008339,
     "end_time": "2024-03-31T11:40:39.432116",
     "exception": false,
     "start_time": "2024-03-31T11:40:39.423777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "In this first attempt to create a simple tool to answer to our questions about Data Science, we tested the capability of Gemma model to answer to few questions related to Data Science directly, without prompting it with some special documentation.\n",
    "\n",
    "The results were quite good, actually unexpected good, considering that we were just using a system prompt adapted to the task. Maybe the last question could have been answered better, but, well, how many of us have actually used Platt calibrations curves or other method for model calibration? Btw., here is a good article describing the concepts related to model calibration: [A Comprehensive Guide on Model Calibration: What, When, and How](https://towardsdatascience.com/a-comprehensive-guide-on-model-calibration-part-1-of-4-73466eb5e09a)\n",
    "\n",
    "The results shows that Gemma was trained well with data about Data Science domain. To further extend and maybe take it up-to-date, we can ingest recent information about Data Science in a vector database and create a Retrieval Augmented Generation system.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7669720,
     "sourceId": 64148,
     "sourceType": "competition"
    },
    {
     "modelInstanceId": 5388,
     "sourceId": 11372,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 188.258795,
   "end_time": "2024-03-31T11:40:42.487690",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-31T11:37:34.228895",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
