{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076bce8e",
   "metadata": {
    "papermill": {
     "duration": 0.006145,
     "end_time": "2023-10-27T22:21:34.015303",
     "exception": false,
     "start_time": "2023-10-27T22:21:34.009158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction   \n",
    "\n",
    "\n",
    "We will experiment now with the Mistral model.\n",
    "\n",
    "\n",
    "## Model specification  \n",
    "\n",
    "The model details are:\n",
    "\n",
    "* **Model**: Mistral\n",
    "* **Variation**: 7b-v0.1-hf (7b: 7B dimm. hf: HuggingFace build)\n",
    "* **Version**: V1\n",
    "* **Framework**: PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7bcdc8",
   "metadata": {
    "papermill": {
     "duration": 0.005114,
     "end_time": "2023-10-27T22:21:34.026016",
     "exception": false,
     "start_time": "2023-10-27T22:21:34.020902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install and import packages  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a3b0dd",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-10-27T22:21:34.038462Z",
     "iopub.status.busy": "2023-10-27T22:21:34.038046Z",
     "iopub.status.idle": "2023-10-27T22:22:26.771790Z",
     "shell.execute_reply": "2023-10-27T22:22:26.770227Z"
    },
    "papermill": {
     "duration": 52.743038,
     "end_time": "2023-10-27T22:22:26.774534",
     "exception": false,
     "start_time": "2023-10-27T22:21:34.031496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U transformers\n",
    "!pip install -q -U accelerate\n",
    "!pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3543c9",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-27T22:22:26.787608Z",
     "iopub.status.busy": "2023-10-27T22:22:26.787277Z",
     "iopub.status.idle": "2023-10-27T22:22:50.802198Z",
     "shell.execute_reply": "2023-10-27T22:22:50.801039Z"
    },
    "papermill": {
     "duration": 24.024185,
     "end_time": "2023-10-27T22:22:50.804794",
     "exception": false,
     "start_time": "2023-10-27T22:22:26.780609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b798aab",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-27T22:22:50.818285Z",
     "iopub.status.busy": "2023-10-27T22:22:50.817956Z",
     "iopub.status.idle": "2023-10-27T22:23:09.234153Z",
     "shell.execute_reply": "2023-10-27T22:23:09.233376Z"
    },
    "papermill": {
     "duration": 18.425732,
     "end_time": "2023-10-27T22:23:09.236595",
     "exception": false,
     "start_time": "2023-10-27T22:22:50.810863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from time import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d690ecd4",
   "metadata": {
    "papermill": {
     "duration": 0.005696,
     "end_time": "2023-10-27T22:23:09.248508",
     "exception": false,
     "start_time": "2023-10-27T22:23:09.242812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f80d71",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-27T22:23:09.261132Z",
     "iopub.status.busy": "2023-10-27T22:23:09.260545Z",
     "iopub.status.idle": "2023-10-27T22:25:24.597254Z",
     "shell.execute_reply": "2023-10-27T22:25:24.596160Z"
    },
    "papermill": {
     "duration": 135.345389,
     "end_time": "2023-10-27T22:25:24.599418",
     "exception": false,
     "start_time": "2023-10-27T22:23:09.254029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2628a8ff58654d148dbaf5408553d832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer & pipeline: 135 sec.\n"
     ]
    }
   ],
   "source": [
    "model_id = '/kaggle/input/mistral/pytorch/7b-v0.1-hf/1'\n",
    "time_1 = time()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model_name = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "print(f\"Tokenizer & pipeline: {round(time() - time_1)} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e78f26",
   "metadata": {
    "papermill": {
     "duration": 0.005406,
     "end_time": "2023-10-27T22:25:24.610631",
     "exception": false,
     "start_time": "2023-10-27T22:25:24.605225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test model  \n",
    "\n",
    "Let's test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c961bff",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-27T22:25:24.622825Z",
     "iopub.status.busy": "2023-10-27T22:25:24.622551Z",
     "iopub.status.idle": "2023-10-27T22:25:24.629157Z",
     "shell.execute_reply": "2023-10-27T22:25:24.628172Z"
    },
    "papermill": {
     "duration": 0.015394,
     "end_time": "2023-10-27T22:25:24.631460",
     "exception": false,
     "start_time": "2023-10-27T22:25:24.616066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare pipeline: 0.0 sec.\n"
     ]
    }
   ],
   "source": [
    "time_1 = time()\n",
    "query_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_name,\n",
    "        tokenizer=tokenizer,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.1,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        max_length=200,)\n",
    "time_2 = time()\n",
    "print(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee92fed",
   "metadata": {
    "papermill": {
     "duration": 0.005706,
     "end_time": "2023-10-27T22:25:24.644170",
     "exception": false,
     "start_time": "2023-10-27T22:25:24.638464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Let's define a function to test the query pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a935eaa",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-27T22:25:24.657249Z",
     "iopub.status.busy": "2023-10-27T22:25:24.656937Z",
     "iopub.status.idle": "2023-10-27T22:25:24.663338Z",
     "shell.execute_reply": "2023-10-27T22:25:24.662401Z"
    },
    "papermill": {
     "duration": 0.015257,
     "end_time": "2023-10-27T22:25:24.665381",
     "exception": false,
     "start_time": "2023-10-27T22:25:24.650124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(tokenizer, pipeline, prompt_to_test):\n",
    "    \"\"\"\n",
    "    Perform a query\n",
    "    print the result\n",
    "    Args:\n",
    "        tokenizer: the tokenizer\n",
    "        pipeline: the pipeline\n",
    "        prompt_to_test: the prompt\n",
    "    Returns\n",
    "        None\n",
    "    \"\"\"\n",
    "    # adapted from https://huggingface.co/blog/llama2#using-transformers\n",
    "    time_1 = time()\n",
    "    sequences = pipeline(\n",
    "        prompt_to_test,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.1,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=200,)\n",
    "    time_2 = time()\n",
    "    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n",
    "    for seq in sequences:\n",
    "        print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9ce9bdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T22:25:24.678792Z",
     "iopub.status.busy": "2023-10-27T22:25:24.678002Z",
     "iopub.status.idle": "2023-10-27T22:25:41.531459Z",
     "shell.execute_reply": "2023-10-27T22:25:41.530430Z"
    },
    "papermill": {
     "duration": 16.862527,
     "end_time": "2023-10-27T22:25:41.533742",
     "exception": false,
     "start_time": "2023-10-27T22:25:24.671215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inference: 16.848 sec.\n",
      "Result: Please list the three most visited cities in France.\n",
      "\n",
      "Answer: Paris, Marseille, Lyon\n",
      "\n",
      "Question 2: Which is the most visited city in France?\n",
      "\n",
      "Answer: Paris\n",
      "\n",
      "Question 3: Which is the second most visited city in France?\n",
      "\n",
      "Answer: Marseille\n",
      "\n",
      "Question 4: Which is the third most visited city in France?\n",
      "\n",
      "Answer: Lyon\n",
      "\n",
      "Question 5: Which is the fourth most visited city in France?\n",
      "\n",
      "Answer: Nice\n",
      "\n",
      "Question 6: Which is the fifth most visited city in France?\n",
      "\n",
      "Answer: Toulouse\n",
      "\n",
      "Question 7: Which is the sixth most visited city in France?\n",
      "\n",
      "Answer: Lille\n",
      "\n",
      "Question 8: Which is the seventh most visited city in France?\n",
      "\n",
      "Answer: Bordeaux\n",
      "\n",
      "Question 9: Which is the eighth most visited city in France\n"
     ]
    }
   ],
   "source": [
    "test_model(tokenizer,\n",
    "           query_pipeline,\n",
    "           \"Please list the three most visited cities in France.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8dd96b",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-27T22:25:41.547114Z",
     "iopub.status.busy": "2023-10-27T22:25:41.546817Z",
     "iopub.status.idle": "2023-10-27T22:25:53.838189Z",
     "shell.execute_reply": "2023-10-27T22:25:53.837292Z"
    },
    "papermill": {
     "duration": 12.300594,
     "end_time": "2023-10-27T22:25:53.840367",
     "exception": false,
     "start_time": "2023-10-27T22:25:41.539773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inference: 12.287 sec.\n",
      "Result: What tourist attractions I can see in Paris?\n",
      "\n",
      "Paris is a city of art, culture, and history. There are many tourist attractions in Paris that you can visit. Some of the most popular tourist attractions in Paris include the Eiffel Tower, the Louvre Museum, the Notre Dame Cathedral, and the Arc de Triomphe.\n",
      "\n",
      "### What are the best things to do in Paris?\n",
      "\n",
      "There are many things to do in Paris, but some of the best things to do include visiting the Eiffel Tower, the Louvre Museum, and the Notre Dame Cathedral.\n",
      "\n",
      "### What are the best places to eat in Paris?\n",
      "\n",
      "There are many great places to eat in Paris, but some of the best places to eat include the Eiffel Tower, the Louvre Museum, and the Notre Dame Cathedral.\n",
      "\n",
      "### What are the best places to stay in Paris?\n",
      "\n",
      "There\n"
     ]
    }
   ],
   "source": [
    "test_model(tokenizer,\n",
    "           query_pipeline,\n",
    "           \"What tourist attractions I can see in Paris?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123db923",
   "metadata": {
    "papermill": {
     "duration": 0.006109,
     "end_time": "2023-10-27T22:25:53.852634",
     "exception": false,
     "start_time": "2023-10-27T22:25:53.846525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define and execute the sequential chain  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25101ada",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-27T22:25:53.865804Z",
     "iopub.status.busy": "2023-10-27T22:25:53.865499Z",
     "iopub.status.idle": "2023-10-27T22:25:53.870202Z",
     "shell.execute_reply": "2023-10-27T22:25:53.869325Z"
    },
    "papermill": {
     "duration": 0.013375,
     "end_time": "2023-10-27T22:25:53.872102",
     "exception": false,
     "start_time": "2023-10-27T22:25:53.858727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=query_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b4c4449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T22:25:53.884957Z",
     "iopub.status.busy": "2023-10-27T22:25:53.884707Z",
     "iopub.status.idle": "2023-10-27T22:26:06.160594Z",
     "shell.execute_reply": "2023-10-27T22:26:06.159624Z"
    },
    "papermill": {
     "duration": 12.284798,
     "end_time": "2023-10-27T22:26:06.162884",
     "exception": false,
     "start_time": "2023-10-27T22:25:53.878086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAnswer: Paris, Marseille, Lyon\\n\\nQuestion 2: What is the name of the famous French painter who painted the Mona Lisa?\\n\\nAnswer: Leonardo da Vinci\\n\\nQuestion 3: What is the name of the famous French painter who painted the Mona Lisa?\\n\\nAnswer: Leonardo da Vinci\\n\\nQuestion 4: What is the name of the famous French painter who painted the Mona Lisa?\\n\\nAnswer: Leonardo da Vinci\\n\\nQuestion 5: What is the name of the famous French painter who painted the Mona Lisa?\\n\\nAnswer: Leonardo da Vinci\\n\\nQuestion 6: What is the name of the famous French painter who painted the Mona Lisa?\\n\\nAnswer: Leonardo da Vinci\\n\\nQuestion 7: What is the name of the famous French painter who painted'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Please list the three most visited cities in France.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37c8e365",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-27T22:26:06.177248Z",
     "iopub.status.busy": "2023-10-27T22:26:06.176934Z",
     "iopub.status.idle": "2023-10-27T22:26:06.184089Z",
     "shell.execute_reply": "2023-10-27T22:26:06.183252Z"
    },
    "papermill": {
     "duration": 0.016356,
     "end_time": "2023-10-27T22:26:06.186070",
     "exception": false,
     "start_time": "2023-10-27T22:26:06.169714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sequential_chain(country, llm):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        country: country selected\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    time_1 = time()\n",
    "    template = \"What is the most popular city in {country} for tourists?\"\n",
    "\n",
    "    #  first task in chain\n",
    "    first_prompt = PromptTemplate(\n",
    "\n",
    "    input_variables=[\"country\"],\n",
    "\n",
    "    template=template)\n",
    "\n",
    "    chain_one = LLMChain(llm = llm, prompt = first_prompt)\n",
    "\n",
    "    # second step in chain\n",
    "    second_prompt = PromptTemplate(\n",
    "\n",
    "    input_variables=[\"city\"],\n",
    "\n",
    "    template=\"What are the top three things to do in this: {city} for tourists\",)\n",
    "\n",
    "    chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "\n",
    "    # combine the two steps and run the chain sequence\n",
    "    overall_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)\n",
    "    overall_chain.run(country)\n",
    "    time_2 = time()\n",
    "    print(f\"Run sequential chain: {round(time_2-time_1, 3)} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b30981a0",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-27T22:26:06.199987Z",
     "iopub.status.busy": "2023-10-27T22:26:06.199697Z",
     "iopub.status.idle": "2023-10-27T22:26:19.773610Z",
     "shell.execute_reply": "2023-10-27T22:26:19.772593Z"
    },
    "papermill": {
     "duration": 13.584054,
     "end_time": "2023-10-27T22:26:19.776150",
     "exception": false,
     "start_time": "2023-10-27T22:26:06.192096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "Paris is the most popular city in France for tourists. It is the capital city of France and is known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Notre Dame Cathedral. Paris is also known for its fashion, cuisine, and art scene.\n",
      "\n",
      "## What is the most popular city in France for tourists?\n",
      "\n",
      "The most popular city in France for tourists is Paris. Paris is the capital city of France and is known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Notre Dame Cathedral. Paris is also known for its fashion, cuisine, and art scene.\n",
      "\n",
      "## What is the most popular city in France for tourists?\n",
      "\n",
      "The most popular city in France for tourists is Paris. Paris is the capital city of France and is known for its iconic land\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 203, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m is\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Run sequential chain: 13.57 sec.\n"
     ]
    }
   ],
   "source": [
    "final_answer = sequential_chain(\"France\", llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20a5cd1d",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-27T22:26:19.791757Z",
     "iopub.status.busy": "2023-10-27T22:26:19.791012Z",
     "iopub.status.idle": "2023-10-27T22:26:19.795930Z",
     "shell.execute_reply": "2023-10-27T22:26:19.795001Z"
    },
    "papermill": {
     "duration": 0.014692,
     "end_time": "2023-10-27T22:26:19.798084",
     "exception": false,
     "start_time": "2023-10-27T22:26:19.783392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c909e2",
   "metadata": {
    "papermill": {
     "duration": 0.006932,
     "end_time": "2023-10-27T22:26:19.811646",
     "exception": false,
     "start_time": "2023-10-27T22:26:19.804714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusions   \n",
    "\n",
    "\n",
    "Mistral 7b-hf seems to be inferior to Llama 7b-chat-hf for question answering.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 292.801014,
   "end_time": "2023-10-27T22:26:23.152146",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-27T22:21:30.351132",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "17d977562f304d4d8c31dcbe6468832b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d9f4c72539a4c2da91ede859cfa9f00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2251f6e5705d446dafd4796bf0e82873": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2628a8ff58654d148dbaf5408553d832": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b1e008fa1a2e44a2a74195a53bd0845f",
        "IPY_MODEL_dcb0b4d1b862455189e0c0a7260393d7",
        "IPY_MODEL_9ea48521e69b4b18a94d3c96a416ca9b"
       ],
       "layout": "IPY_MODEL_17d977562f304d4d8c31dcbe6468832b"
      }
     },
     "6938c8fe93a0469394095051141b3ffd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7b85d944f073441aa448b058273392dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f9114cf86d54d0891edc4109e362d12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9c22103ec453491c9218ce6a471c87c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ea48521e69b4b18a94d3c96a416ca9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7b85d944f073441aa448b058273392dd",
       "placeholder": "​",
       "style": "IPY_MODEL_8f9114cf86d54d0891edc4109e362d12",
       "value": " 2/2 [02:05&lt;00:00, 58.98s/it]"
      }
     },
     "b1e008fa1a2e44a2a74195a53bd0845f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9c22103ec453491c9218ce6a471c87c5",
       "placeholder": "​",
       "style": "IPY_MODEL_6938c8fe93a0469394095051141b3ffd",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "dcb0b4d1b862455189e0c0a7260393d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2251f6e5705d446dafd4796bf0e82873",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1d9f4c72539a4c2da91ede859cfa9f00",
       "value": 2.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
