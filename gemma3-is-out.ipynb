{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed9ac92",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.002568,
     "end_time": "2025-03-12T10:02:25.565527",
     "exception": false,
     "start_time": "2025-03-12T10:02:25.562959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Gemma 3 is out!\n",
    "\n",
    "In this Notebook I will show how to use it.\n",
    "\n",
    "The version of Gemma 3 we are using here is the 1B it model, the most compact model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9038048",
   "metadata": {
    "papermill": {
     "duration": 0.001646,
     "end_time": "2025-03-12T10:02:25.569465",
     "exception": false,
     "start_time": "2025-03-12T10:02:25.567819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Instalations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80167ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T10:02:25.573851Z",
     "iopub.status.busy": "2025-03-12T10:02:25.573647Z",
     "iopub.status.idle": "2025-03-12T10:03:19.252652Z",
     "shell.execute_reply": "2025-03-12T10:03:19.251701Z"
    },
    "papermill": {
     "duration": 53.682999,
     "end_time": "2025-03-12T10:03:19.254324",
     "exception": false,
     "start_time": "2025-03-12T10:02:25.571325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\r\n",
      "  Cloning https://github.com/huggingface/transformers (to revision v4.49.0-Gemma-3) to /tmp/pip-req-build-lfxmilae\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-lfxmilae\r\n",
      "  Running command git checkout -q 3edb3aa5b71a35d86a8f951d876c3910732eccaf\r\n",
      "  Resolved https://github.com/huggingface/transformers to commit 3edb3aa5b71a35d86a8f951d876c3910732eccaf\r\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (3.17.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (0.29.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (0.4.5)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2024.12.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.12.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (2025.1.31)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.50.0.dev0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.50.0.dev0) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.50.0.dev0) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.50.0.dev0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers==4.50.0.dev0) (2024.2.0)\r\n",
      "Building wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for transformers: filename=transformers-4.50.0.dev0-py3-none-any.whl size=10936386 sha256=f25ca5a2ece1ae84f0690e07db533ac9b969efeb618e74e893690eae6353862c\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rnlqz7xt/wheels/c1/95/d1/7d800368ab25942bf88f88fe1716597fcc8d757043c9b48a2f\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.47.0\r\n",
      "    Uninstalling transformers-4.47.0:\r\n",
      "      Successfully uninstalled transformers-4.47.0\r\n",
      "Successfully installed transformers-4.50.0.dev0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3 \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.models.gemma3 import Gemma3ForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb245a",
   "metadata": {
    "papermill": {
     "duration": 0.002642,
     "end_time": "2025-03-12T10:03:19.260124",
     "exception": false,
     "start_time": "2025-03-12T10:03:19.257482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Intialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f946088c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T10:03:19.266912Z",
     "iopub.status.busy": "2025-03-12T10:03:19.266386Z",
     "iopub.status.idle": "2025-03-12T10:03:31.229082Z",
     "shell.execute_reply": "2025-03-12T10:03:31.227994Z"
    },
    "papermill": {
     "duration": 11.967685,
     "end_time": "2025-03-12T10:03:31.230582",
     "exception": false,
     "start_time": "2025-03-12T10:03:19.262897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma3ForCausalLM(\n",
      "  (model): Gemma3TextModel(\n",
      "    (embed_tokens): Gemma3TextScaledWordEmbedding(262144, 1152, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-25): 26 x Gemma3DecoderLayer(\n",
      "        (self_attn): Gemma3Attention(\n",
      "          (q_proj): Linear(in_features=1152, out_features=1024, bias=False)\n",
      "          (k_proj): Linear(in_features=1152, out_features=256, bias=False)\n",
      "          (v_proj): Linear(in_features=1152, out_features=256, bias=False)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1152, bias=False)\n",
      "          (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
      "          (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
      "        )\n",
      "        (mlp): Gemma3MLP(\n",
      "          (gate_proj): Linear(in_features=1152, out_features=6912, bias=False)\n",
      "          (up_proj): Linear(in_features=1152, out_features=6912, bias=False)\n",
      "          (down_proj): Linear(in_features=6912, out_features=1152, bias=False)\n",
      "          (act_fn): PytorchGELUTanh()\n",
      "        )\n",
      "        (input_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "        (post_attention_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "        (pre_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "        (post_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "    (rotary_emb): Gemma3RotaryEmbedding()\n",
      "    (rotary_emb_local): Gemma3RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1152, out_features=262144, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "GEMMA_PATH = \"/kaggle/input/gemma-3/transformers/gemma-3-1b-it/1\"\n",
    "processor = AutoTokenizer.from_pretrained(GEMMA_PATH)\n",
    "model = Gemma3ForCausalLM.from_pretrained(GEMMA_PATH)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642e09b",
   "metadata": {
    "papermill": {
     "duration": 0.002584,
     "end_time": "2025-03-12T10:03:31.236210",
     "exception": false,
     "start_time": "2025-03-12T10:03:31.233626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prompting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22def672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T10:03:31.242515Z",
     "iopub.status.busy": "2025-03-12T10:03:31.242267Z",
     "iopub.status.idle": "2025-03-12T10:04:28.291252Z",
     "shell.execute_reply": "2025-03-12T10:04:28.290502Z"
    },
    "papermill": {
     "duration": 57.053984,
     "end_time": "2025-03-12T10:04:28.292965",
     "exception": false,
     "start_time": "2025-03-12T10:03:31.238981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"<start_of_turn>user:\n",
    "What is Gemini model?<end_of_turn>\n",
    "<start_of_turn>model\"\"\"\n",
    "input_ids = processor(text=prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**input_ids, max_new_tokens=256)\n",
    "text = processor.batch_decode(\n",
    "    outputs,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3efd26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T10:04:28.301477Z",
     "iopub.status.busy": "2025-03-12T10:04:28.301255Z",
     "iopub.status.idle": "2025-03-12T10:04:28.306792Z",
     "shell.execute_reply": "2025-03-12T10:04:28.306071Z"
    },
    "papermill": {
     "duration": 0.010869,
     "end_time": "2025-03-12T10:04:28.308093",
     "exception": false,
     "start_time": "2025-03-12T10:04:28.297224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "user:\n",
       "What is Gemini model?\n",
       "model1. The Gemini model is a family of large language models (LLMs) developed by Google AI. It's the successor to PaLM 2 and is designed to be multimodal, meaning it can process and generate different types of information, like text, images, audio, and video.\n",
       "\n",
       "Here's a breakdown of key aspects:\n",
       "\n",
       "* **Multimodal:** This is the defining feature. Gemini can understand and respond to information across multiple modalities.\n",
       "* **PaLM 2 Foundation:** It's built upon the PaLM 2 architecture, which was known for its strong language understanding and reasoning capabilities.\n",
       "* **Different Sizes:** Gemini comes in different sizes, with Gemini Ultra being the most powerful and capable, followed by Gemini Pro and Gemini Nano.\n",
       "* **Capabilities:** Gemini is designed to excel at a wide range of tasks, including:\n",
       "    * **Reasoning:**  Stronger reasoning abilities than previous models.\n",
       "    * **Coding:**  Improved coding capabilities.\n",
       "    * **Creative Writing:**  More creative and nuanced text generation.\n",
       "    * **Multilingual:**  Better performance in multiple languages.\n",
       "    * **Image Understanding:**  Can analyze and understand images.\n",
       "\n",
       "\n",
       "**Where to Learn More:**\n",
       "\n",
       "* **Google AI"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(text[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920efb12",
   "metadata": {
    "papermill": {
     "duration": 0.002588,
     "end_time": "2025-03-12T10:04:28.313862",
     "exception": false,
     "start_time": "2025-03-12T10:04:28.311274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "That was all for now.\n",
    "\n",
    "Get Gemma 3 from Kaggle Model Garden and start using it, in all sizes and versions, and make sure to use its multilingual and multi-modality capabilities."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 222398,
     "modelInstanceId": 239467,
     "sourceId": 282742,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 128.813276,
   "end_time": "2025-03-12T10:04:31.841961",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-12T10:02:23.028685",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
