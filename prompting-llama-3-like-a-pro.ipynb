{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a529a09",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.015188,
     "end_time": "2024-05-13T08:30:53.896229",
     "exception": false,
     "start_time": "2024-05-13T08:30:53.881041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://images2.mobilissimo.ro/ejM/662234d3d923f.jpg\" width=400></center>\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Llama 3 is the latest model from Meta. Let's try and see what we can do with it.  \n",
    "\n",
    "Will test now the following model:\n",
    "* **Model**: Llama3\n",
    "* **Version**: 8b-chat-hf\n",
    "* **Framework**: Transformers\n",
    "* **Version**: V1\n",
    "\n",
    "This is what we will test:\n",
    "\n",
    "* Simple prompts with general information questions\n",
    "* Poetry (haiku, sonets) writing\n",
    "* Code writing (Python, C++, Java)\n",
    "* Software design (simple problems)\n",
    "* Multi-parameter questions\n",
    "* Chain of reasoning\n",
    "* A more complex reasoning problem\n",
    "\n",
    "I intend to learn from this experience so that I can then build then someting a bit more complex.\n",
    "\n",
    "Note: this notebook is organized to facilitate a comparison of **Llama3** with **Gemma**. Corresponding notebook is [Prompt Gemma like a Pro](https://www.kaggle.com/code/gpreda/prompt-gemma-like-a-pro). At the end of current notebook we are reviewing the performance of the two notebooks for the list of tasks submitted to both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccc0c49",
   "metadata": {
    "papermill": {
     "duration": 0.012476,
     "end_time": "2024-05-13T08:30:53.921904",
     "exception": false,
     "start_time": "2024-05-13T08:30:53.909428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparation\n",
    "\n",
    "We import the libraries we need, and we set the model to be ready for testing.\n",
    "\n",
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c9699a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:30:53.949265Z",
     "iopub.status.busy": "2024-05-13T08:30:53.948939Z",
     "iopub.status.idle": "2024-05-13T08:30:59.022010Z",
     "shell.execute_reply": "2024-05-13T08:30:59.020790Z"
    },
    "papermill": {
     "duration": 5.090315,
     "end_time": "2024-05-13T08:30:59.025264",
     "exception": false,
     "start_time": "2024-05-13T08:30:53.934949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52728e16",
   "metadata": {
    "papermill": {
     "duration": 0.016232,
     "end_time": "2024-05-13T08:30:59.060245",
     "exception": false,
     "start_time": "2024-05-13T08:30:59.044013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define model\n",
    "\n",
    "This will take some time (loading checkpoint shards, cca. 2 min.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94152d5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:30:59.092008Z",
     "iopub.status.busy": "2024-05-13T08:30:59.091482Z",
     "iopub.status.idle": "2024-05-13T08:32:57.033329Z",
     "shell.execute_reply": "2024-05-13T08:32:57.032252Z"
    },
    "papermill": {
     "duration": 117.961573,
     "end_time": "2024-05-13T08:32:57.035421",
     "exception": false,
     "start_time": "2024-05-13T08:30:59.073848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 08:31:00.615024: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-13 08:31:00.615179: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-13 08:31:00.714953: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfee94fc2b6245d589cbdb14bd2a6fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd831852",
   "metadata": {
    "papermill": {
     "duration": 0.012419,
     "end_time": "2024-05-13T08:32:57.060576",
     "exception": false,
     "start_time": "2024-05-13T08:32:57.048157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare query function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbd074c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:32:57.087723Z",
     "iopub.status.busy": "2024-05-13T08:32:57.086746Z",
     "iopub.status.idle": "2024-05-13T08:32:57.095148Z",
     "shell.execute_reply": "2024-05-13T08:32:57.094369Z"
    },
    "papermill": {
     "duration": 0.024036,
     "end_time": "2024-05-13T08:32:57.097045",
     "exception": false,
     "start_time": "2024-05-13T08:32:57.073009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_model(\n",
    "        system_message,\n",
    "        user_message,\n",
    "        temperature=0.7,\n",
    "        max_length=1024\n",
    "        ):\n",
    "    start_time = time()\n",
    "    user_message = \"Question: \" + user_message + \" Answer:\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "        ]\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "        )\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    sequences = pipeline(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=temperature,\n",
    "        #num_return_sequences=1,\n",
    "        eos_token_id=terminators,\n",
    "        max_new_tokens=max_length,\n",
    "        return_full_text=False,\n",
    "        pad_token_id=pipeline.model.config.eos_token_id\n",
    "    )\n",
    "    #answer = f\"{sequences[0]['generated_text'][len(prompt):]}\\n\"\n",
    "    answer = sequences[0]['generated_text']\n",
    "    end_time = time()\n",
    "    ttime = f\"Total time: {round(end_time-start_time, 2)} sec.\"\n",
    "\n",
    "    return user_message + \" \" + answer  + \" \" +  ttime\n",
    "\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to answer simple questions.\n",
    "Please restrict your answer to the exact question asked.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615dd9cb",
   "metadata": {
    "papermill": {
     "duration": 0.012101,
     "end_time": "2024-05-13T08:32:57.121439",
     "exception": false,
     "start_time": "2024-05-13T08:32:57.109338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utility function for output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f60d610b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:32:57.147159Z",
     "iopub.status.busy": "2024-05-13T08:32:57.146891Z",
     "iopub.status.idle": "2024-05-13T08:32:57.151431Z",
     "shell.execute_reply": "2024-05-13T08:32:57.150619Z"
    },
    "papermill": {
     "duration": 0.019532,
     "end_time": "2024-05-13T08:32:57.153244",
     "exception": false,
     "start_time": "2024-05-13T08:32:57.133712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Reasoning\", \"Question\", \"Answer\", \"Total time\"], [\"blue\", \"red\", \"green\", \"magenta\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab4590",
   "metadata": {
    "papermill": {
     "duration": 0.01216,
     "end_time": "2024-05-13T08:32:57.177638",
     "exception": false,
     "start_time": "2024-05-13T08:32:57.165478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test with few simple geography and history questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bc74a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:32:57.203349Z",
     "iopub.status.busy": "2024-05-13T08:32:57.202684Z",
     "iopub.status.idle": "2024-05-13T08:33:03.469558Z",
     "shell.execute_reply": "2024-05-13T08:33:03.468602Z"
    },
    "papermill": {
     "duration": 6.281735,
     "end_time": "2024-05-13T08:33:03.471647",
     "exception": false,
     "start_time": "2024-05-13T08:32:57.189912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** What is the surface temperature of the Moon? \n",
       "\n",
       "**<font color='green'>Answer:</font>** The surface temperature of the Moon varies greatly depending on the time of day and the location on the Moon. During the day, the temperature can reach as high as 253°F (122°C), while at night it can drop to as low as -243°F (-153°C). \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 6.26 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"What is the surface temperature of the Moon?\",\n",
    "    temperature=0.1,\n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58f603f",
   "metadata": {
    "papermill": {
     "duration": 0.012784,
     "end_time": "2024-05-13T08:33:03.497066",
     "exception": false,
     "start_time": "2024-05-13T08:33:03.484282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's try also with a different prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c779ecbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:03.523672Z",
     "iopub.status.busy": "2024-05-13T08:33:03.522743Z",
     "iopub.status.idle": "2024-05-13T08:33:04.975466Z",
     "shell.execute_reply": "2024-05-13T08:33:04.974572Z"
    },
    "papermill": {
     "duration": 1.468141,
     "end_time": "2024-05-13T08:33:04.977604",
     "exception": false,
     "start_time": "2024-05-13T08:33:03.509463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** What is the surface of France? \n",
       "\n",
       "**<font color='green'>Answer:</font>** The surface area of France is approximately 551,500 square kilometers (213,011 square miles). \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 1.45 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(    \n",
    "    system_message,\n",
    "    user_message=\"What is the surface of France?\",\n",
    "    temperature=0.1,\n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a79b599",
   "metadata": {
    "papermill": {
     "duration": 0.012459,
     "end_time": "2024-05-13T08:33:05.002954",
     "exception": false,
     "start_time": "2024-05-13T08:33:04.990495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It doesn't look like a well crafted prompt helps too much.  Let's get back to our initial prompt pattern for more questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5091b331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:05.029554Z",
     "iopub.status.busy": "2024-05-13T08:33:05.028878Z",
     "iopub.status.idle": "2024-05-13T08:33:06.072510Z",
     "shell.execute_reply": "2024-05-13T08:33:06.071642Z"
    },
    "papermill": {
     "duration": 1.059208,
     "end_time": "2024-05-13T08:33:06.074560",
     "exception": false,
     "start_time": "2024-05-13T08:33:05.015352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** When was the 30 years war? \n",
       "\n",
       "**<font color='green'>Answer:</font>** The Thirty Years War was from 1618 to 1648. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 1.04 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"When was the 30 years war?\",\n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed752105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:06.101816Z",
     "iopub.status.busy": "2024-05-13T08:33:06.101515Z",
     "iopub.status.idle": "2024-05-13T08:33:08.844911Z",
     "shell.execute_reply": "2024-05-13T08:33:08.844034Z"
    },
    "papermill": {
     "duration": 2.75907,
     "end_time": "2024-05-13T08:33:08.847032",
     "exception": false,
     "start_time": "2024-05-13T08:33:06.087962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** What is graphe paranomon? \n",
       "\n",
       "**<font color='green'>Answer:</font>** Graphe paranomon is a type of ancient Greek legal action, specifically a public accusation made against a magistrate or other public official for acting contrary to the laws or customs of the city-state. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 2.74 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"What is graphe paranomon?\",\n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ceae500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:08.876565Z",
     "iopub.status.busy": "2024-05-13T08:33:08.875922Z",
     "iopub.status.idle": "2024-05-13T08:33:09.535681Z",
     "shell.execute_reply": "2024-05-13T08:33:09.534725Z"
    },
    "papermill": {
     "duration": 0.677133,
     "end_time": "2024-05-13T08:33:09.537723",
     "exception": false,
     "start_time": "2024-05-13T08:33:08.860590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Who was the next shogun after Tokugawa Ieyasu? \n",
       "\n",
       "**<font color='green'>Answer:</font>** Tokugawa Hidetada. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 0.65 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Who was the next shogun after Tokugawa Ieyasu?\",\n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cf08ed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:09.565840Z",
     "iopub.status.busy": "2024-05-13T08:33:09.565551Z",
     "iopub.status.idle": "2024-05-13T08:33:09.939023Z",
     "shell.execute_reply": "2024-05-13T08:33:09.938146Z"
    },
    "papermill": {
     "duration": 0.389815,
     "end_time": "2024-05-13T08:33:09.941074",
     "exception": false,
     "start_time": "2024-05-13T08:33:09.551259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** What was the name of the Chinese dinasty during 1st century B.C.? \n",
       "\n",
       "**<font color='green'>Answer:</font>** The Han Dynasty. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 0.37 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"What was the name of the Chinese dinasty during 1st century B.C.?\",\n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8a284",
   "metadata": {
    "papermill": {
     "duration": 0.013477,
     "end_time": "2024-05-13T08:33:09.968088",
     "exception": false,
     "start_time": "2024-05-13T08:33:09.954611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's try some elementary questions about American history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f5a826f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:09.996438Z",
     "iopub.status.busy": "2024-05-13T08:33:09.996135Z",
     "iopub.status.idle": "2024-05-13T08:33:10.298532Z",
     "shell.execute_reply": "2024-05-13T08:33:10.297565Z"
    },
    "papermill": {
     "duration": 0.31854,
     "end_time": "2024-05-13T08:33:10.300493",
     "exception": false,
     "start_time": "2024-05-13T08:33:09.981953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Who was the first American president? \n",
       "\n",
       "**<font color='green'>Answer:</font>** George Washington. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 0.3 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Who was the first American president?\",\n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c172238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:10.370329Z",
     "iopub.status.busy": "2024-05-13T08:33:10.369971Z",
     "iopub.status.idle": "2024-05-13T08:33:11.486773Z",
     "shell.execute_reply": "2024-05-13T08:33:11.485938Z"
    },
    "papermill": {
     "duration": 1.174969,
     "end_time": "2024-05-13T08:33:11.489002",
     "exception": false,
     "start_time": "2024-05-13T08:33:10.314033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** When took place the Civil War in United States of America? \n",
       "\n",
       "**<font color='green'>Answer:</font>** The American Civil War took place from 1861 to 1865. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 1.11 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"When took place the Civil War in United States of America?\",\n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe3d04",
   "metadata": {
    "papermill": {
     "duration": 0.013581,
     "end_time": "2024-05-13T08:33:11.516079",
     "exception": false,
     "start_time": "2024-05-13T08:33:11.502498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Let's write poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d9bced4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:11.544644Z",
     "iopub.status.busy": "2024-05-13T08:33:11.544339Z",
     "iopub.status.idle": "2024-05-13T08:33:12.802853Z",
     "shell.execute_reply": "2024-05-13T08:33:12.801827Z"
    },
    "papermill": {
     "duration": 1.275202,
     "end_time": "2024-05-13T08:33:12.805308",
     "exception": false,
     "start_time": "2024-05-13T08:33:11.530106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a poem about Boris Becker wins in tennis \n",
       "\n",
       "**<font color='green'>Answer:</font>** Golden racket's song\n",
       "Boris Becker's mighty serve\n",
       "Victory's sweet cry \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 1.25 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write poetry.\n",
    "Please answer with a haiku format (17 words poems).\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a poem about Boris Becker wins in tennis\",\n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9018f520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:12.835887Z",
     "iopub.status.busy": "2024-05-13T08:33:12.835004Z",
     "iopub.status.idle": "2024-05-13T08:33:14.434953Z",
     "shell.execute_reply": "2024-05-13T08:33:14.433978Z"
    },
    "papermill": {
     "duration": 1.617008,
     "end_time": "2024-05-13T08:33:14.436877",
     "exception": false,
     "start_time": "2024-05-13T08:33:12.819869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a poem about Shakespeare being lame at playing poker \n",
       "\n",
       "**<font color='green'>Answer:</font>** Bard's bluffing fails hard\n",
       "Shakespeare's poker face a lie\n",
       "Lame, his royal flush \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 1.59 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a poem about Shakespeare being lame at playing poker\",\n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "372e6100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:14.466854Z",
     "iopub.status.busy": "2024-05-13T08:33:14.466104Z",
     "iopub.status.idle": "2024-05-13T08:33:27.609904Z",
     "shell.execute_reply": "2024-05-13T08:33:27.608848Z"
    },
    "papermill": {
     "duration": 13.160775,
     "end_time": "2024-05-13T08:33:27.611996",
     "exception": false,
     "start_time": "2024-05-13T08:33:14.451221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24/3940791513.py\", line 7, in <module>\n",
      "    response = query_model(\n",
      "  File \"/tmp/ipykernel_24/462056988.py\", line 22, in query_model\n",
      "    sequences = pipeline(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\", line 240, in __call__\n",
      "    return super().__call__(text_inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n",
      "    logger.warning_once(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\n",
      "Arguments: (<class 'UserWarning'>,)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a poem about Nadia Comaneci winning Montreal Olympiad \n",
       "\n",
       "**<font color='green'>Answer:</font>** Fair Nadia, with thy nimble frame,\n",
       "Didst conquer Montreal's Olympic fame.\n",
       "Thy gymnastics, a wondrous, whirling dance,\n",
       "Didst capture hearts, and earn a second chance.\n",
       "\n",
       "Thy score, a seven, a feat most rare,\n",
       "Didst stun the crowd, and leave them bare.\n",
       "Of breath, of words, of all articulate sound,\n",
       "As thou, a maiden, didst thy triumph wound.\n",
       "\n",
       "The judges' eyes, in awe, didst gaze upon\n",
       "Thy form, so lithe, so strong, so young, and won.\n",
       "The crowd, in raptures, didst thy name proclaim,\n",
       "As thou, a heroine, didst thy glory claim.\n",
       "\n",
       "And when the scores, in final tally, told\n",
       "Thy total, a perfect ten, to behold,\n",
       "The world, in wonder, didst thy feat proclaim,\n",
       "And Nadia Comaneci, forever in fame. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 13.14 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write poetry.\n",
    "Please answer with a short poem, with rime, in the style of Shakespeare's poems.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a poem about Nadia Comaneci winning Montreal Olympiad\",\n",
    "    temperature=0.1, \n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd664d",
   "metadata": {
    "papermill": {
     "duration": 0.013878,
     "end_time": "2024-05-13T08:33:27.640759",
     "exception": false,
     "start_time": "2024-05-13T08:33:27.626881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Math problem and Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cad58cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:27.670419Z",
     "iopub.status.busy": "2024-05-13T08:33:27.670100Z",
     "iopub.status.idle": "2024-05-13T08:33:30.319595Z",
     "shell.execute_reply": "2024-05-13T08:33:30.318681Z"
    },
    "papermill": {
     "duration": 2.666599,
     "end_time": "2024-05-13T08:33:30.321610",
     "exception": false,
     "start_time": "2024-05-13T08:33:27.655011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in Python to calculate the area of a circle of radius r \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is the Python code for the function:\n",
       "\n",
       "```\n",
       "import math\n",
       "\n",
       "def calculate_circle_area(r):\n",
       "    area = math.pi * (r ** 2)\n",
       "    return area\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 2.64 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple Python code.\n",
    "Please answer with the listing of the Python code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in Python to calculate the area of a circle of radius r\",\n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bc0c944",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:30.353522Z",
     "iopub.status.busy": "2024-05-13T08:33:30.352848Z",
     "iopub.status.idle": "2024-05-13T08:33:32.018733Z",
     "shell.execute_reply": "2024-05-13T08:33:32.017829Z"
    },
    "papermill": {
     "duration": 1.684458,
     "end_time": "2024-05-13T08:33:32.020935",
     "exception": false,
     "start_time": "2024-05-13T08:33:30.336477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in Python to order a list \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a Python function that orders a list:\n",
       "\n",
       "```\n",
       "def order_list(lst):\n",
       "    return sorted(lst)\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 1.66 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in Python to order a list\",\n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c051b",
   "metadata": {
    "papermill": {
     "duration": 0.014608,
     "end_time": "2024-05-13T08:33:32.050754",
     "exception": false,
     "start_time": "2024-05-13T08:33:32.036146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Software design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc526898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:32.080823Z",
     "iopub.status.busy": "2024-05-13T08:33:32.080504Z",
     "iopub.status.idle": "2024-05-13T08:33:54.060575Z",
     "shell.execute_reply": "2024-05-13T08:33:54.059556Z"
    },
    "papermill": {
     "duration": 21.997624,
     "end_time": "2024-05-13T08:33:54.062879",
     "exception": false,
     "start_time": "2024-05-13T08:33:32.065255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a class in Python \n",
       "                        to model a phone book (storing name, surname, address, phone) \n",
       "                        with add, delete, order by name, search operations.\n",
       "                        The class should store a list of contacts, each\n",
       "                        with name, surname, address, phone information stored.\n",
       "                         \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is the Python code for the PhoneBook class:\n",
       "\n",
       "```\n",
       "class PhoneBook:\n",
       "    def __init__(self):\n",
       "        self.contacts = []\n",
       "\n",
       "    def add_contact(self, name, surname, address, phone):\n",
       "        self.contacts.append({\n",
       "            'name': name,\n",
       "           'surname': surname,\n",
       "            'address': address,\n",
       "            'phone': phone\n",
       "        })\n",
       "\n",
       "    def delete_contact(self, name):\n",
       "        for contact in self.contacts:\n",
       "            if contact['name'] == name:\n",
       "                self.contacts.remove(contact)\n",
       "                print(f\"Contact {name} deleted successfully.\")\n",
       "                return\n",
       "        print(f\"Contact {name} not found.\")\n",
       "\n",
       "    def order_by_name(self):\n",
       "        self.contacts.sort(key=lambda x: x['name'])\n",
       "\n",
       "    def search_contact(self, name):\n",
       "        for contact in self.contacts:\n",
       "            if contact['name'] == name:\n",
       "                return contact\n",
       "        return None\n",
       "\n",
       "    def display_contacts(self):\n",
       "        for contact in self.contacts:\n",
       "            print(f\"Name: {contact['name']}, Surname: {contact['surname']}, Address: {contact['address']}, Phone: {contact['phone']}\")\n",
       "\n",
       "\n",
       "# Example usage:\n",
       "phone_book = PhoneBook()\n",
       "phone_book.add_contact('John', 'Doe', '123 Main St', '1234567890')\n",
       "phone_book.add_contact('Jane', 'Smith', '456 Elm St', '9876543210')\n",
       "phone_book.order_by_name()\n",
       "phone_book.display_contacts()\n",
       "print(phone_book.search_contact('John'))\n",
       "phone_book.delete_contact('John')\n",
       "phone_book.display_contacts()\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 21.97 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"\"\"Please write a class in Python \n",
    "                        to model a phone book (storing name, surname, address, phone) \n",
    "                        with add, delete, order by name, search operations.\n",
    "                        The class should store a list of contacts, each\n",
    "                        with name, surname, address, phone information stored.\n",
    "                        \"\"\",\n",
    "    temperature=0.1, \n",
    "    max_length=1024)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dddce8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:33:54.094010Z",
     "iopub.status.busy": "2024-05-13T08:33:54.093717Z",
     "iopub.status.idle": "2024-05-13T08:34:11.820103Z",
     "shell.execute_reply": "2024-05-13T08:34:11.819149Z"
    },
    "papermill": {
     "duration": 17.744027,
     "end_time": "2024-05-13T08:34:11.822105",
     "exception": false,
     "start_time": "2024-05-13T08:33:54.078078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a small Python module that creates a REST API service\n",
       "                        with two endpoints: \n",
       "                        * get_status (GET)\n",
       "                        * prediction (POST)\n",
       "                        The prediction endpoint receives the payload, extract three fields: city, street and number\n",
       "                        and returns a field called price_estimate\n",
       "                        \n",
       "                         \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple Python module using Flask to create a REST API service with the two endpoints you requested:\n",
       "\n",
       "```\n",
       "from flask import Flask, request, jsonify\n",
       "import json\n",
       "\n",
       "app = Flask(__name__)\n",
       "\n",
       "# Sample data for prediction\n",
       "data = {\n",
       "    \"New York\": {\"street\": {\"1st\": 100, \"2nd\": 120, \"3rd\": 150}, \n",
       "                 \"Los Angeles\": {\"1st\": 80, \"2nd\": 90, \"3rd\": 110}, \n",
       "                 \"Chicago\": {\"1st\": 70, \"2nd\": 80, \"3rd\": 100}\n",
       "}\n",
       "\n",
       "@app.route('/get_status', methods=['GET'])\n",
       "def get_status():\n",
       "    return jsonify({'status': 'OK'})\n",
       "\n",
       "@app.route('/prediction', methods=['POST'])\n",
       "def prediction():\n",
       "    data = request.get_json()\n",
       "    city = data.get('city')\n",
       "    street = data.get('street')\n",
       "    number = data.get('number')\n",
       "    \n",
       "    if city and street and number:\n",
       "        if city in data and street in data[city] and number in data[city][street]:\n",
       "            return jsonify({'price_estimate': data[city][street][number]})\n",
       "        else:\n",
       "            return jsonify({'error': 'Invalid city \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 17.72 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"\"\"Please write a small Python module that creates a REST API service\n",
    "                        with two endpoints: \n",
    "                        * get_status (GET)\n",
    "                        * prediction (POST)\n",
    "                        The prediction endpoint receives the payload, extract three fields: city, street and number\n",
    "                        and returns a field called price_estimate\n",
    "                        \n",
    "                        \"\"\",\n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c601f3f",
   "metadata": {
    "papermill": {
     "duration": 0.015139,
     "end_time": "2024-05-13T08:34:11.852860",
     "exception": false,
     "start_time": "2024-05-13T08:34:11.837721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# C++ code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "577d3f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:34:11.884325Z",
     "iopub.status.busy": "2024-05-13T08:34:11.883975Z",
     "iopub.status.idle": "2024-05-13T08:34:18.519044Z",
     "shell.execute_reply": "2024-05-13T08:34:18.518115Z"
    },
    "papermill": {
     "duration": 6.65352,
     "end_time": "2024-05-13T08:34:18.521214",
     "exception": false,
     "start_time": "2024-05-13T08:34:11.867694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in C++ to calculate the area of a circle of radius r \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is the C++ code for the function to calculate the area of a circle:\n",
       "\n",
       "```cpp\n",
       "#include<iostream>\n",
       "using namespace std;\n",
       "\n",
       "double circleArea(double r) {\n",
       "    return 3.14 * r * r;\n",
       "}\n",
       "\n",
       "int main() {\n",
       "    double radius;\n",
       "    cout << \"Enter the radius of the circle: \";\n",
       "    cin >> radius;\n",
       "    cout << \"The area of the circle is: \" << circleArea(radius);\n",
       "    return 0;\n",
       "}\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 6.63 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple C++ code.\n",
    "Please answer with the listing of the C++ code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in C++ to calculate the area of a circle of radius r\", \n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d208b505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:34:18.553614Z",
     "iopub.status.busy": "2024-05-13T08:34:18.553210Z",
     "iopub.status.idle": "2024-05-13T08:34:27.312822Z",
     "shell.execute_reply": "2024-05-13T08:34:27.311841Z"
    },
    "papermill": {
     "duration": 8.778105,
     "end_time": "2024-05-13T08:34:27.315007",
     "exception": false,
     "start_time": "2024-05-13T08:34:18.536902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in C++ to calculate the volume of a cylinder with radius r and height h \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is the C++ code for the function to calculate the volume of a cylinder:\n",
       "\n",
       "```cpp\n",
       "#include<iostream>\n",
       "using namespace std;\n",
       "\n",
       "double cylinderVolume(double r, double h) {\n",
       "    return 3.14159 * r * r * h;\n",
       "}\n",
       "\n",
       "int main() {\n",
       "    double r, h;\n",
       "    cout << \"Enter the radius of the cylinder: \";\n",
       "    cin >> r;\n",
       "    cout << \"Enter the height of the cylinder: \";\n",
       "    cin >> h;\n",
       "    cout << \"The volume of the cylinder is: \" << cylinderVolume(r, h) << endl;\n",
       "    return 0;\n",
       "}\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 8.75 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple C++ code.\n",
    "Please answer with the listing of the C++ code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in C++ to calculate the volume of a cylinder with radius r and height h\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31d79068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:34:27.348128Z",
     "iopub.status.busy": "2024-05-13T08:34:27.347443Z",
     "iopub.status.idle": "2024-05-13T08:34:45.011378Z",
     "shell.execute_reply": "2024-05-13T08:34:45.010528Z"
    },
    "papermill": {
     "duration": 17.682472,
     "end_time": "2024-05-13T08:34:45.013434",
     "exception": false,
     "start_time": "2024-05-13T08:34:27.330962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in C++ to order a list \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple implementation of a function in C++ that sorts a list of integers in ascending order using the built-in `sort` function from the `<algorithm>` library:\n",
       "\n",
       "```cpp\n",
       "#include <iostream>\n",
       "#include <algorithm>\n",
       "#include <vector>\n",
       "\n",
       "void sortList(std::vector<int>& list) {\n",
       "    std::sort(list.begin(), list.end());\n",
       "}\n",
       "\n",
       "int main() {\n",
       "    std::vector<int> list = {4, 2, 9, 6, 5, 1, 3, 7, 8};\n",
       "    std::cout << \"Original list: \";\n",
       "    for (int i : list) {\n",
       "        std::cout << i << \" \";\n",
       "    }\n",
       "    std::cout << std::endl;\n",
       "\n",
       "    sortList(list);\n",
       "\n",
       "    std::cout << \"Sorted list: \";\n",
       "    for (int i : list) {\n",
       "        std::cout << i << \" \";\n",
       "    }\n",
       "    std::cout << std::endl;\n",
       "\n",
       "    return 0;\n",
       "}\n",
       "```\n",
       "\n",
       "This code defines a function `sortList` that takes a reference to a `std::vector<int>` as its argument. It uses the `std::sort` function to sort the list in ascending order. The `main` function demonstrates how to use this function by \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 17.66 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in C++ to order a list\", \n",
    "    temperature=0.1, \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9722bf",
   "metadata": {
    "papermill": {
     "duration": 0.015599,
     "end_time": "2024-05-13T08:34:45.045296",
     "exception": false,
     "start_time": "2024-05-13T08:34:45.029697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multiple parameters questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac6db4",
   "metadata": {
    "papermill": {
     "duration": 0.01541,
     "end_time": "2024-05-13T08:34:45.076091",
     "exception": false,
     "start_time": "2024-05-13T08:34:45.060681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Best food in France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1f90c70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:34:45.108410Z",
     "iopub.status.busy": "2024-05-13T08:34:45.107894Z",
     "iopub.status.idle": "2024-05-13T08:34:58.654860Z",
     "shell.execute_reply": "2024-05-13T08:34:58.653872Z"
    },
    "papermill": {
     "duration": 13.565407,
     "end_time": "2024-05-13T08:34:58.657022",
     "exception": false,
     "start_time": "2024-05-13T08:34:45.091615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** \n",
       "What are the best 3 food from France?\n",
       " \n",
       "\n",
       "**<font color='green'>Answer:</font>** Bonjour! France, the land of cuisine, is renowned for its delectable dishes and exquisite culinary delights. Here are the top 3 foods from France that you must try:\n",
       "\n",
       "• **Croissants**: Flaky, buttery, and oh-so-flavorful, croissants are a classic French breakfast staple. Whether plain or filled with chocolate, they're a must-try when visiting France.\n",
       "\n",
       "• **Escargots**: Snails in garlic butter, anyone? Escargots are a quintessential French appetizer that will delight your taste buds. The perfect combination of rich flavors and tender texture.\n",
       "\n",
       "• **Macarons**: These delicate meringue-based confections are a French specialty. With a wide range of flavors and fillings, macarons are the perfect treat to satisfy your sweet tooth. From classic flavors like raspberry and chocolate to more unique flavors like matcha and rose, there's a macaron for everyone.\n",
       "\n",
       "Bon appétit! \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 13.54 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to answer questions with parameters.\n",
    "Return the answer formated nicely, for example with bullet points.\n",
    "\"\"\"\n",
    "user_message = \"\"\"\n",
    "What are the {adjective} {number} {items} from {place}?\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message.format(\n",
    "    adjective=\"best\",\n",
    "    number=\"3\",\n",
    "    items=\"food\",\n",
    "    place=\"France\"\n",
    "    ), \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf8737",
   "metadata": {
    "papermill": {
     "duration": 0.015981,
     "end_time": "2024-05-13T08:34:58.690110",
     "exception": false,
     "start_time": "2024-05-13T08:34:58.674129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Best attractions in Italy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26fe8d11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:34:58.722895Z",
     "iopub.status.busy": "2024-05-13T08:34:58.722125Z",
     "iopub.status.idle": "2024-05-13T08:35:16.388782Z",
     "shell.execute_reply": "2024-05-13T08:35:16.387867Z"
    },
    "papermill": {
     "duration": 17.685348,
     "end_time": "2024-05-13T08:35:16.390964",
     "exception": false,
     "start_time": "2024-05-13T08:34:58.705616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** \n",
       "What are the best five attractions from Italy?\n",
       " \n",
       "\n",
       "**<font color='green'>Answer:</font>** Italy is a country with a rich history, art, architecture, and culture, offering numerous attractions for tourists. Here are the top 5 attractions in Italy:\n",
       "\n",
       "• **Colosseum** (Rome): This ancient amphitheater is one of Rome's most iconic landmarks and a must-visit attraction. Learn about the history of gladiators and the Roman Empire while exploring the ancient structure.\n",
       "\n",
       "• **Leaning Tower of Pisa** (Pisa): This famous tower is a symbol of Italy and a popular spot for tourists. Take a stroll around the square, admire the tower's unique architecture, and capture the perfect photo.\n",
       "\n",
       "• **Cinque Terre** (Liguria): These five colorful towns on the Italian coast offer breathtaking ocean views, scenic hiking trails, and charming villages to explore. Visit Monterosso, Vernazza, Corniglia, Manarola, and Riomaggiore for a unique experience.\n",
       "\n",
       "• **Uffizi Gallery** (Florence): This world-renowned museum is home to some of the most famous artworks in history, including Botticelli's \"The Birth of Venus\" and Leonardo da Vinci's \"Annunciation.\" Discover the works of Italian masters like Michelangelo, Raphael, and Caravaggio.\n",
       "\n",
       " \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 17.66 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(    \n",
    "    system_message,\n",
    "    user_message.format(\n",
    "    adjective=\"best\",\n",
    "    number=\"five\",\n",
    "    items=\"attractions\",\n",
    "    place=\"Italy\"\n",
    "    ), \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af2bb7",
   "metadata": {
    "papermill": {
     "duration": 0.015949,
     "end_time": "2024-05-13T08:35:16.423606",
     "exception": false,
     "start_time": "2024-05-13T08:35:16.407657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Most affordable places to stay in Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bcd64c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:35:16.456459Z",
     "iopub.status.busy": "2024-05-13T08:35:16.456139Z",
     "iopub.status.idle": "2024-05-13T08:35:33.108699Z",
     "shell.execute_reply": "2024-05-13T08:35:33.107767Z"
    },
    "papermill": {
     "duration": 16.671241,
     "end_time": "2024-05-13T08:35:33.110655",
     "exception": false,
     "start_time": "2024-05-13T08:35:16.439414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** \n",
       "What are the most affordable two places to retire from Spain?\n",
       " \n",
       "\n",
       "**<font color='green'>Answer:</font>** **Affordable Retirement Options in Spain**\n",
       "\n",
       "Considering the cost of living, taxes, and quality of life, here are two of the most affordable places to retire from Spain:\n",
       "\n",
       "• **Almería**: Located in the southeastern region of Andalusia, Almería is one of the most affordable cities in Spain. The cost of living is relatively low, with a monthly budget of around €1,500-€2,000 (approximately $1,700-$2,200 USD) covering accommodation, food, and other expenses.\n",
       "\n",
       "• **Girona**: Situated in the northeastern region of Catalonia, Girona is another affordable option for retirees. The city has a lower cost of living compared to larger cities like Barcelona, with a monthly budget of around €2,000-€2,500 (approximately $2,200-$2,800 USD) covering the essentials.\n",
       "\n",
       "Both Almería and Girona offer a great quality of life, with pleasant weather, rich cultural heritage, and a strong sense of community. Additionally, they have good access to healthcare, amenities, and transportation networks, making them attractive options for retirees looking to make the most of their retirement in Spain. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 16.65 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message.format(\n",
    "    adjective=\"most affordable\",\n",
    "    number=\"two\",\n",
    "    items=\"places to retire\",\n",
    "    place=\"Spain\"\n",
    "    ), \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc91b8e",
   "metadata": {
    "papermill": {
     "duration": 0.016078,
     "end_time": "2024-05-13T08:35:33.143166",
     "exception": false,
     "start_time": "2024-05-13T08:35:33.127088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Less known but great places to stay in Romania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3e4cd21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:35:33.175834Z",
     "iopub.status.busy": "2024-05-13T08:35:33.175530Z",
     "iopub.status.idle": "2024-05-13T08:35:50.827060Z",
     "shell.execute_reply": "2024-05-13T08:35:50.826168Z"
    },
    "papermill": {
     "duration": 17.670287,
     "end_time": "2024-05-13T08:35:50.829120",
     "exception": false,
     "start_time": "2024-05-13T08:35:33.158833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** \n",
       "What are the Less known but great 4 places to stay from Romania?\n",
       " \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here are 4 lesser-known but great places to stay in Romania:\n",
       "\n",
       "• **Sighisoara**: This medieval town is a UNESCO World Heritage Site and offers a unique blend of Germanic and Latin architecture. Stay in one of the many charming guesthouses or boutique hotels, such as the Hotel Casa Wagner or the Guesthouse Casa Sighisoara.\n",
       "\n",
       "• **Sinaia**: Located in the heart of the Carpathian Mountains, Sinaia is a picturesque town surrounded by stunning scenery. Stay at the elegant Hotel Palace or the cozy Guesthouse Casa Sinaia for a relaxing getaway.\n",
       "\n",
       "• **Târgu Mureș**: This city in central Romania is often overlooked by tourists, but it has a rich cultural heritage and a unique blend of Hungarian and Romanian influences. Stay at the Hotel Continental or the Guesthouse Casa Târgu Mureș for a comfortable and affordable stay.\n",
       "\n",
       "• **Râșnov**: This charming village in Transylvania is famous for its medieval fortress and stunning scenery. Stay at the Guesthouse Casa Râșnov or the Hotel Râșnov for a peaceful retreat amidst the rolling hills and forests.\n",
       "\n",
       "These places offer a unique and authentic Romanian experience, away from the crowds of popular tourist destinations like Bucharest or Bras \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 17.65 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(    \n",
    "    system_message,\n",
    "    user_message.format(\n",
    "    adjective=\"Less known but great\",\n",
    "    number=\"4\",\n",
    "    items=\"places to stay\",\n",
    "    place=\"Romania\"\n",
    "    ), \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f3166",
   "metadata": {
    "papermill": {
     "duration": 0.016067,
     "end_time": "2024-05-13T08:35:50.861518",
     "exception": false,
     "start_time": "2024-05-13T08:35:50.845451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Best commedies by Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d52cafd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:35:50.894632Z",
     "iopub.status.busy": "2024-05-13T08:35:50.894346Z",
     "iopub.status.idle": "2024-05-13T08:36:03.422117Z",
     "shell.execute_reply": "2024-05-13T08:36:03.421150Z"
    },
    "papermill": {
     "duration": 12.546767,
     "end_time": "2024-05-13T08:36:03.424197",
     "exception": false,
     "start_time": "2024-05-13T08:35:50.877430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** \n",
       "What are the best 3 commedies from Shakespeare entire creation?\n",
       " \n",
       "\n",
       "**<font color='green'>Answer:</font>** What a delightful question! Here are three of the most popular and enduring comedies from Shakespeare's entire creation:\n",
       "\n",
       "• **A Midsummer Night's Dream**: A whimsical tale of love, magic, and mischief in the forest, featuring the iconic characters of Puck, Oberon, and Titania.\n",
       "\n",
       "• **Twelfth Night**: A witty and romantic comedy that explores the complexities of love, identity, and deception, featuring the memorable characters of Viola, Olivia, and the lovable fool, Feste.\n",
       "\n",
       "• **As You Like It**: A charming and lighthearted comedy that follows the adventures of Rosalind, a clever and resourceful heroine, as she navigates love, family, and social hierarchy in the Forest of Arden.\n",
       "\n",
       "These three comedies showcase Shakespeare's mastery of language, character development, and comedic storytelling, and continue to delight audiences to this day! \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 12.52 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message.format(\n",
    "    adjective=\"best\",\n",
    "    number=\"3\",\n",
    "    items=\"commedies\",\n",
    "    place=\"Shakespeare entire creation\"\n",
    "    ), \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76486f",
   "metadata": {
    "papermill": {
     "duration": 0.016381,
     "end_time": "2024-05-13T08:36:03.457344",
     "exception": false,
     "start_time": "2024-05-13T08:36:03.440963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Most important battles from WW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d91df812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:36:03.492276Z",
     "iopub.status.busy": "2024-05-13T08:36:03.491542Z",
     "iopub.status.idle": "2024-05-13T08:36:23.750179Z",
     "shell.execute_reply": "2024-05-13T08:36:23.749167Z"
    },
    "papermill": {
     "duration": 20.278639,
     "end_time": "2024-05-13T08:36:23.752157",
     "exception": false,
     "start_time": "2024-05-13T08:36:03.473518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** \n",
       "What are the most important 5 battles from WW2?\n",
       " \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here are the top 5 most important battles of World War II:\n",
       "\n",
       "• **Battle of Stalingrad (August 1942 - February 1943)**: A decisive turning point on the Eastern Front, where the Soviet Union defeated Nazi Germany, marking a shift in momentum in favor of the Allies.\n",
       "\n",
       "• **Battle of Midway (June 4-7, 1942)**: A pivotal naval battle in the Pacific, where the United States defeated Japan, preventing a potential invasion of Hawaii and halting Japan's expansion in the Pacific.\n",
       "\n",
       "• **Battle of El Alamein (October - November 1942)**: A crucial battle in North Africa, where the British Eighth Army defeated the German-Italian forces, marking a turning point in the North African Campaign and paving the way for the Allied invasion of Italy.\n",
       "\n",
       "• **Battle of Normandy (D-Day) (June 6, 1944)**: A massive Allied invasion of Nazi-occupied France, which marked a significant turning point in the war, as it established a foothold for the Allies on the European mainland.\n",
       "\n",
       "• **Battle of Berlin (April - May 1945)**: The final battle of the war, where Soviet forces captured the German capital, leading to the surrender of Germany and the end of World War II in Europe.\n",
       "\n",
       "These battles had a significant impact on the outcome of the war and are widely regarded as some of the most important conflicts of World War II. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 20.25 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message.format(\n",
    "    adjective=\"most important\",\n",
    "    number=\"5\",\n",
    "    items=\"battles\",\n",
    "    place=\"WW2\"\n",
    "    ), \n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a776b",
   "metadata": {
    "papermill": {
     "duration": 0.016978,
     "end_time": "2024-05-13T08:36:23.786346",
     "exception": false,
     "start_time": "2024-05-13T08:36:23.769368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multiple steps reasoning (task chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb9bb01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:36:23.820918Z",
     "iopub.status.busy": "2024-05-13T08:36:23.820568Z",
     "iopub.status.idle": "2024-05-13T08:36:25.927565Z",
     "shell.execute_reply": "2024-05-13T08:36:25.926480Z"
    },
    "papermill": {
     "duration": 2.126781,
     "end_time": "2024-05-13T08:36:25.929686",
     "exception": false,
     "start_time": "2024-05-13T08:36:23.802905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** \n",
       "Question one: What are the best city from France for tourists?\n",
       "Question two: What are the best 3 of attractions from the city identified as answer to question one?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       " \n",
       "\n",
       "**<font color='green'>Answer:</font>** Question one: What are the best cities from France for tourists?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** Paris is often considered one of the best cities for tourists in France. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 2.1 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to answer questions in a chain of thought.\n",
    "Use the answer to the first question as input for the second question.\n",
    "\"\"\"\n",
    "user_message= \"\"\"\n",
    "Question one: What are the best city from {country} for tourists?\n",
    "Question two: What are the best {number} of attractions from the city identified as answer to question one?\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message.format(\n",
    "    number=\"3\",\n",
    "    country=\"France\"\n",
    "    ), \n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6af8c",
   "metadata": {
    "papermill": {
     "duration": 0.016519,
     "end_time": "2024-05-13T08:36:25.963605",
     "exception": false,
     "start_time": "2024-05-13T08:36:25.947086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reasoning like Einstein will do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eabf3852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T08:36:25.998335Z",
     "iopub.status.busy": "2024-05-13T08:36:25.997666Z",
     "iopub.status.idle": "2024-05-13T08:36:58.642903Z",
     "shell.execute_reply": "2024-05-13T08:36:58.641857Z"
    },
    "papermill": {
     "duration": 32.681408,
     "end_time": "2024-05-13T08:36:58.661591",
     "exception": false,
     "start_time": "2024-05-13T08:36:25.980183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** How many kilometers will travel totally the swallow? \n",
       "\n",
       "**<font color='green'>Answer:</font>** Let's break this down step by step.\n",
       "\n",
       "1. The train travels from Bucharest to Ploiesti, which is a distance of 60 km. Since the train is moving at a constant speed of 60 km/h, it will take 1 hour to cover this distance.\n",
       "2. The swallow flies from Ploiesti to the moving train, which is a distance of 60 km. Since the swallow is flying at a constant speed of 90 km/h, it will take 40 minutes (60 km / 90 km/h) to cover this distance.\n",
       "3. When the swallow reaches the train, it flies back towards Ploiesti, which is also a distance of 60 km. Again, it will take 40 minutes to cover this distance.\n",
       "4. The train and the swallow continue to move towards Ploiesti. Since the train is moving at 60 km/h and the swallow is flying at 90 km/h, the distance between them is decreasing at a rate of 30 km/h (90 km/h - 60 km/h).\n",
       "5. The swallow flies back and forth between the train and Ploiesti until the train reaches Ploiesti. Since the train is moving at a constant speed, it will take 1 hour to cover the remaining distance.\n",
       "6. During this time, the swallow will make multiple trips back and forth between the train and Ploiesti. Let's calculate the total distance the swallow will travel during this time.\n",
       "\n",
       "The distance between the train and Ploiesti is decreasing at a rate of 30 km/h. In 1 hour, the distance will decrease by 30 km. Since the swallow is flying at 90 km/h, it will make 3 trips back and forth during this time (30 km / 30 km/h = 1 hour).\n",
       "\n",
       "Each trip is a distance of 60 km, so the total distance the swallow will travel during this time is:\n",
       "\n",
       "3 trips x 60 km/trip = 180 km\n",
       "\n",
       "Adding this to the initial distance the swallow traveled to reach the train, we get:\n",
       "\n",
       "40 minutes x 90 km/h = 36 km (initial distance) + 180 km = 216 km\n",
       "\n",
       "So, the swallow will travel a total distance of 216 km. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 32.64 sec.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 32.64 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are a math professor, smart but cool.\n",
    "Background: A train traveling from Bucharest to Ploiesti (60 km distance) has the speed of 60 km/h. \n",
    "The train starts in Bucharest and travels until Ploiesti, once, only in this direction.\n",
    "A swallow, flying with 90 km/h, fly from Ploiesti to the moving train.\n",
    "When it reaches the train, the swallow flies back toward Ploiesti,\n",
    "ahead of the train. At Ploiesti turns again back and continues to fly back and forth \n",
    "(between the train approaching Ploiesti and Ploiesti) until the train reaches Ploiesti. \n",
    "The swallow will fly continously all the time the train is traveling from Bucharest to Ploiesti.\n",
    "Reasoning: Think step by step. Explain your reasoning.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "t = time()\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"How many kilometers will travel totally the swallow?\", \n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(f\"{response}\\n\\nTotal time: {round(time()-t, 2)} sec.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edde3ef",
   "metadata": {
    "papermill": {
     "duration": 0.016775,
     "end_time": "2024-05-13T08:36:58.695877",
     "exception": false,
     "start_time": "2024-05-13T08:36:58.679102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "\n",
    "We compared the results with those with Gemma. Here is the notebook for Gemma: [Prompt Gemma like a Pro](https://www.kaggle.com/code/gpreda/prompt-gemma-like-a-pro).\n",
    "\n",
    "\n",
    "* Llama3 answered quite decent to most of the questions on history and geography. It looks like an improvement from previous runs of this Notebook.\n",
    "* Llama3 is good at code generation and math problems.\n",
    "* The final math problem - failed worst than Gemma (who rationed it's 120 Km; the true answer is 90 km). But actually the rationing is really, really wrong.\n",
    "\n",
    "In terms of execution time, after I applied the change suggested in one of the comments, it improved very much. \n",
    "\n",
    "So, comparison of Llama3 8B with Gemma 2B is in favor of Llama3 for general knowledge, maths and code generation, with Gemma slightly better on the more complex math task.\n",
    "\n",
    "Stay tuned, we will continue with more tests in the next days."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 370.250159,
   "end_time": "2024-05-13T08:37:01.515245",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-13T08:30:51.265086",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1f9fdd9f9f1042c1a296c0109c247a3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5a40597db03244c59d1abc51660f2316",
       "placeholder": "​",
       "style": "IPY_MODEL_eeb95bd7e6174e63803e6c4016fef9a9",
       "value": " 4/4 [01:43&lt;00:00, 22.28s/it]"
      }
     },
     "598b86d9bdad45f4910d5125ebe71a24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a40597db03244c59d1abc51660f2316": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62464eea3b2d4b7694613825db813099": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99811ad0cec9407d87fe73f53a026ecb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a1e6fe77870a4483ab2472f37af8875b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1fcb7c836e4477da888a679ac3ba702": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_62464eea3b2d4b7694613825db813099",
       "placeholder": "​",
       "style": "IPY_MODEL_99811ad0cec9407d87fe73f53a026ecb",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "da70c044efb44f8cbb9bc35d924f2a58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_598b86d9bdad45f4910d5125ebe71a24",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dced98a8be194aae9a06cb600be7f610",
       "value": 4.0
      }
     },
     "dced98a8be194aae9a06cb600be7f610": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dfee94fc2b6245d589cbdb14bd2a6fd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d1fcb7c836e4477da888a679ac3ba702",
        "IPY_MODEL_da70c044efb44f8cbb9bc35d924f2a58",
        "IPY_MODEL_1f9fdd9f9f1042c1a296c0109c247a3f"
       ],
       "layout": "IPY_MODEL_a1e6fe77870a4483ab2472f37af8875b"
      }
     },
     "eeb95bd7e6174e63803e6c4016fef9a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
