{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64756eea",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.008109,
     "end_time": "2024-06-09T08:28:52.758911",
     "exception": false,
     "start_time": "2024-06-09T08:28:52.750802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "We are using LLama3 to write code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a61c25",
   "metadata": {
    "papermill": {
     "duration": 0.007094,
     "end_time": "2024-06-09T08:28:52.773871",
     "exception": false,
     "start_time": "2024-06-09T08:28:52.766777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2bbede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:28:52.790041Z",
     "iopub.status.busy": "2024-06-09T08:28:52.789369Z",
     "iopub.status.idle": "2024-06-09T08:28:59.943876Z",
     "shell.execute_reply": "2024-06-09T08:28:59.943037Z"
    },
    "papermill": {
     "duration": 7.16543,
     "end_time": "2024-06-09T08:28:59.946279",
     "exception": false,
     "start_time": "2024-06-09T08:28:52.780849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811c3660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:28:59.962492Z",
     "iopub.status.busy": "2024-06-09T08:28:59.962070Z",
     "iopub.status.idle": "2024-06-09T08:31:04.648912Z",
     "shell.execute_reply": "2024-06-09T08:31:04.647819Z"
    },
    "papermill": {
     "duration": 124.697199,
     "end_time": "2024-06-09T08:31:04.651045",
     "exception": false,
     "start_time": "2024-06-09T08:28:59.953846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 08:29:02.157943: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-09 08:29:02.158048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-09 08:29:02.328277: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea7d2f453f84f778b23b8bcf5fd8c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57727da0",
   "metadata": {
    "papermill": {
     "duration": 0.007542,
     "end_time": "2024-06-09T08:31:04.666707",
     "exception": false,
     "start_time": "2024-06-09T08:31:04.659165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test function\n",
    "\n",
    "Let's define the query model function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f57af7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:31:04.683262Z",
     "iopub.status.busy": "2024-06-09T08:31:04.682659Z",
     "iopub.status.idle": "2024-06-09T08:31:04.690943Z",
     "shell.execute_reply": "2024-06-09T08:31:04.690069Z"
    },
    "papermill": {
     "duration": 0.018515,
     "end_time": "2024-06-09T08:31:04.692937",
     "exception": false,
     "start_time": "2024-06-09T08:31:04.674422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_model(\n",
    "        system_message,\n",
    "        user_message,\n",
    "        temperature=0.7,\n",
    "        max_length=1024\n",
    "        ):\n",
    "    start_time = time()\n",
    "    user_message = \"Question: \" + user_message + \" Answer:\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "        ]\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "        )\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    sequences = pipeline(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=temperature,\n",
    "        #num_return_sequences=1,\n",
    "        eos_token_id=terminators,\n",
    "        max_new_tokens=max_length,\n",
    "        return_full_text=False,\n",
    "        pad_token_id=pipeline.model.config.eos_token_id\n",
    "    )\n",
    "    #answer = f\"{sequences[0]['generated_text'][len(prompt):]}\\n\"\n",
    "    answer = sequences[0]['generated_text']\n",
    "    end_time = time()\n",
    "    ttime = f\"Total time: {round(end_time-start_time, 2)} sec.\"\n",
    "\n",
    "    return user_message + \" \" + answer  + \" \" +  ttime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae26475",
   "metadata": {
    "papermill": {
     "duration": 0.007672,
     "end_time": "2024-06-09T08:31:04.708039",
     "exception": false,
     "start_time": "2024-06-09T08:31:04.700367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also define an utility function for displaying the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a0bd00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:31:04.725863Z",
     "iopub.status.busy": "2024-06-09T08:31:04.725549Z",
     "iopub.status.idle": "2024-06-09T08:31:04.730727Z",
     "shell.execute_reply": "2024-06-09T08:31:04.729822Z"
    },
    "papermill": {
     "duration": 0.016085,
     "end_time": "2024-06-09T08:31:04.732854",
     "exception": false,
     "start_time": "2024-06-09T08:31:04.716769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Reasoning\", \"Question\", \"Answer\", \"Total time\"], [\"blue\", \"red\", \"green\", \"magenta\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058a2ffe",
   "metadata": {
    "papermill": {
     "duration": 0.007081,
     "end_time": "2024-06-09T08:31:04.747610",
     "exception": false,
     "start_time": "2024-06-09T08:31:04.740529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Python code\n",
    "\n",
    "Let's start testing the model with some Python questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76328d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:31:04.764049Z",
     "iopub.status.busy": "2024-06-09T08:31:04.763788Z",
     "iopub.status.idle": "2024-06-09T08:31:09.287749Z",
     "shell.execute_reply": "2024-06-09T08:31:09.286730Z"
    },
    "papermill": {
     "duration": 4.53474,
     "end_time": "2024-06-09T08:31:09.289933",
     "exception": false,
     "start_time": "2024-06-09T08:31:04.755193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in Python to calculate the area of a rectangle with edges of L and l \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is the Python code for the function:\n",
       "\n",
       "```\n",
       "def rectangle_area(L, l):\n",
       "    return L * l\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 4.52 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple Python code.\n",
    "Please answer with the listing of the Python code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in Python to calculate the area of a rectangle with edges of L and l\",\n",
    "    temperature=0.1,\n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04342371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:31:09.306904Z",
     "iopub.status.busy": "2024-06-09T08:31:09.306366Z",
     "iopub.status.idle": "2024-06-09T08:31:11.007411Z",
     "shell.execute_reply": "2024-06-09T08:31:11.006102Z"
    },
    "papermill": {
     "duration": 1.712293,
     "end_time": "2024-06-09T08:31:11.009887",
     "exception": false,
     "start_time": "2024-06-09T08:31:09.297594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in Python to order a list \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a Python function that orders a list:\n",
       "\n",
       "```\n",
       "def order_list(lst):\n",
       "    return sorted(lst)\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 1.69 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in Python to order a list\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1e4871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:31:11.028009Z",
     "iopub.status.busy": "2024-06-09T08:31:11.027269Z",
     "iopub.status.idle": "2024-06-09T08:31:41.420365Z",
     "shell.execute_reply": "2024-06-09T08:31:41.419379Z"
    },
    "papermill": {
     "duration": 30.41234,
     "end_time": "2024-06-09T08:31:41.430786",
     "exception": false,
     "start_time": "2024-06-09T08:31:11.018446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a Python module for a phone agenda. \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple Python module for a phone agenda:\n",
       "\n",
       "```\n",
       "class PhoneAgenda:\n",
       "    def __init__(self):\n",
       "        self.contacts = {}\n",
       "\n",
       "    def add_contact(self, name, phone_number):\n",
       "        self.contacts[name] = phone_number\n",
       "\n",
       "    def delete_contact(self, name):\n",
       "        if name in self.contacts:\n",
       "            del self.contacts[name]\n",
       "        else:\n",
       "            print(\"Contact not found\")\n",
       "\n",
       "    def update_contact(self, name, phone_number):\n",
       "        if name in self.contacts:\n",
       "            self.contacts[name] = phone_number\n",
       "        else:\n",
       "            print(\"Contact not found\")\n",
       "\n",
       "    def search_contact(self, name):\n",
       "        if name in self.contacts:\n",
       "            return self.contacts[name]\n",
       "        else:\n",
       "            return \"Contact not found\"\n",
       "\n",
       "    def display_contacts(self):\n",
       "        for name, phone_number in self.contacts.items():\n",
       "            print(f\"Name: {name}, Phone Number: {phone_number}\")\n",
       "\n",
       "\n",
       "def main():\n",
       "    agenda = PhoneAgenda()\n",
       "\n",
       "    while True:\n",
       "        print(\"\\nPhone Agenda Menu:\")\n",
       "        print(\"1. Add Contact\")\n",
       "        print(\"2. Delete Contact\")\n",
       "        print(\"3. Update Contact\")\n",
       "        print(\"4. Search Contact\")\n",
       "        print(\"5. Display Contacts\")\n",
       "        print(\"6. Exit\")\n",
       "\n",
       "        choice = input(\"Enter your choice: \")\n",
       "\n",
       "        if choice == \"1\":\n",
       "            name = input(\"Enter contact name: \")\n",
       "            phone_number = input(\"Enter contact phone number: \")\n",
       "            agenda.add_contact(name, phone_number)\n",
       "        elif choice == \"2\":\n",
       "            name = input(\"Enter contact name: \")\n",
       "            agenda.delete_contact(name)\n",
       "        elif choice == \"3\":\n",
       "            name = input(\"Enter contact name: \")\n",
       "            phone_number = input(\"Enter new phone number: \")\n",
       "            agenda.update_contact(name, phone_number)\n",
       "        elif choice == \"4\":\n",
       "            name = input(\"Enter contact name: \")\n",
       "            print(agenda.search_contact(name))\n",
       "        elif choice == \"5\":\n",
       "            agenda.display_contacts()\n",
       "        elif choice == \"6\":\n",
       "            break\n",
       "        else:\n",
       "            print(\"Invalid choice. Please choose a valid option.\")\n",
       "\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    main()\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 30.39 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a Python module for a phone agenda.\", \n",
    "    temperature=0.1,\n",
    "    max_length=1024)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb246b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:31:41.449577Z",
     "iopub.status.busy": "2024-06-09T08:31:41.448795Z",
     "iopub.status.idle": "2024-06-09T08:31:58.878103Z",
     "shell.execute_reply": "2024-06-09T08:31:58.877089Z"
    },
    "papermill": {
     "duration": 17.441172,
     "end_time": "2024-06-09T08:31:58.880291",
     "exception": false,
     "start_time": "2024-06-09T08:31:41.439119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** \n",
       "                            Please write a Python service using Flask to expose a machine learning model. \n",
       "                            The service has one endpoint (POST) that receives three features:\n",
       "                            - area\n",
       "                            - number of rooms\n",
       "                            - number of bathrooms\n",
       "                            The model returns the price of the property. \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple Python service using Flask to expose a machine learning model:\n",
       "\n",
       "```\n",
       "from flask import Flask, request, jsonify\n",
       "import pandas as pd\n",
       "from sklearn.ensemble import RandomForestRegressor\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "\n",
       "app = Flask(__name__)\n",
       "\n",
       "# Load the dataset\n",
       "df = pd.read_csv('property_data.csv')\n",
       "\n",
       "# Split the data into features and target\n",
       "X = df.drop('price', axis=1)\n",
       "y = df['price']\n",
       "\n",
       "# Scale the features\n",
       "scaler = StandardScaler()\n",
       "X_scaled = scaler.fit_transform(X)\n",
       "\n",
       "# Train the model\n",
       "model = RandomForestRegressor()\n",
       "model.fit(X_scaled, y)\n",
       "\n",
       "@app.route('/predict', methods=['POST'])\n",
       "def predict():\n",
       "    data = request.get_json()\n",
       "    area = data['area']\n",
       "    num_rooms = data['num_rooms']\n",
       "    num_bathrooms = data['num_bathrooms']\n",
       "\n",
       "    # Scale the input data\n",
       "    input_data = [[area, num_rooms, num_bathrooms]]\n",
       "    input_data_scaled = scaler.transform(input_data)\n",
       "\n",
       "    # Make the prediction\n",
       "    prediction = model.predict(input_data_scaled)[0]\n",
       "\n",
       "    return jsonify({'price': prediction})\n",
       "\n",
       "if __name__ == '__main__':\n",
       "    app.run(debug=True)\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 17.42 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"\"\"\n",
    "                            Please write a Python service using Flask to expose a machine learning model. \n",
    "                            The service has one endpoint (POST) that receives three features:\n",
    "                            - area\n",
    "                            - number of rooms\n",
    "                            - number of bathrooms\n",
    "                            The model returns the price of the property.\"\"\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87dbd71",
   "metadata": {
    "papermill": {
     "duration": 0.008058,
     "end_time": "2024-06-09T08:31:58.896919",
     "exception": false,
     "start_time": "2024-06-09T08:31:58.888861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# C++ code\n",
    "\n",
    "Let's continue with few C++ questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e7b941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:31:58.914434Z",
     "iopub.status.busy": "2024-06-09T08:31:58.914104Z",
     "iopub.status.idle": "2024-06-09T08:32:06.355701Z",
     "shell.execute_reply": "2024-06-09T08:32:06.354670Z"
    },
    "papermill": {
     "duration": 7.452856,
     "end_time": "2024-06-09T08:32:06.358087",
     "exception": false,
     "start_time": "2024-06-09T08:31:58.905231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in C++ to calculate the area of a rectangle with edges of L and l \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is the C++ code for the function:\n",
       "\n",
       "```cpp\n",
       "#include<iostream>\n",
       "using namespace std;\n",
       "\n",
       "float area(float L, float l) {\n",
       "    return L * l;\n",
       "}\n",
       "\n",
       "int main() {\n",
       "    float L, l;\n",
       "    cout << \"Enter the length of the rectangle: \";\n",
       "    cin >> L;\n",
       "    cout << \"Enter the breadth of the rectangle: \";\n",
       "    cin >> l;\n",
       "    cout << \"The area of the rectangle is: \" << area(L, l);\n",
       "    return 0;\n",
       "}\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 7.43 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple C++ code.\n",
    "Please answer with the listing of the C++ code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in C++ to calculate the area of a rectangle with edges of L and l\",\n",
    "    temperature=0.1,\n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b4be21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:32:06.377846Z",
     "iopub.status.busy": "2024-06-09T08:32:06.377511Z",
     "iopub.status.idle": "2024-06-09T08:32:37.316807Z",
     "shell.execute_reply": "2024-06-09T08:32:37.315850Z"
    },
    "papermill": {
     "duration": 30.959466,
     "end_time": "2024-06-09T08:32:37.327023",
     "exception": false,
     "start_time": "2024-06-09T08:32:06.367557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in C++ to traverse a balanced tree \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple C++ function to traverse a balanced binary tree in-order, pre-order, and post-order:\n",
       "\n",
       "```cpp\n",
       "#include <iostream>\n",
       "using namespace std;\n",
       "\n",
       "// Define the structure for a node in the tree\n",
       "struct Node {\n",
       "    int data;\n",
       "    Node* left;\n",
       "    Node* right;\n",
       "};\n",
       "\n",
       "// Function to create a new node\n",
       "Node* createNode(int data) {\n",
       "    Node* newNode = new Node();\n",
       "    if (!newNode) {\n",
       "        cout << \"Memory error\\n\";\n",
       "        return NULL;\n",
       "    }\n",
       "    newNode->data = data;\n",
       "    newNode->left = newNode->right = NULL;\n",
       "    return newNode;\n",
       "}\n",
       "\n",
       "// Function to perform in-order traversal\n",
       "void inOrderTraversal(Node* root) {\n",
       "    if (root == NULL) return;\n",
       "    inOrderTraversal(root->left);\n",
       "    cout << root->data << \" \";\n",
       "    inOrderTraversal(root->right);\n",
       "}\n",
       "\n",
       "// Function to perform pre-order traversal\n",
       "void preOrderTraversal(Node* root) {\n",
       "    if (root == NULL) return;\n",
       "    cout << root->data << \" \";\n",
       "    preOrderTraversal(root->left);\n",
       "    preOrderTraversal(root->right);\n",
       "}\n",
       "\n",
       "// Function to perform post-order traversal\n",
       "void postOrderTraversal(Node* root) {\n",
       "    if (root == NULL) return;\n",
       "    postOrderTraversal(root->left);\n",
       "    postOrderTraversal(root->right);\n",
       "    cout << root->data << \" \";\n",
       "}\n",
       "\n",
       "int main() {\n",
       "    // Create a sample balanced binary tree\n",
       "    Node* root = createNode(1);\n",
       "    root->left = createNode(2);\n",
       "    root->right = createNode(3);\n",
       "    root->left->left = createNode(4);\n",
       "    root->left->right = createNode(5);\n",
       "\n",
       "    // Perform in-order traversal\n",
       "    cout << \"In-order traversal: \";\n",
       "    inOrderTraversal(root);\n",
       "    cout << endl;\n",
       "\n",
       "    // Perform pre-order traversal\n",
       "    cout << \"Pre-order traversal: \";\n",
       "    preOrderTraversal(root);\n",
       "    cout << endl;\n",
       "\n",
       "    // Perform post-order traversal\n",
       "    cout << \"Post-order traversal: \";\n",
       "    postOrderTraversal(root);\n",
       "    cout << endl;\n",
       "\n",
       "    return 0;\n",
       "}\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 30.93 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in C++ to traverse a balanced tree\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "906533f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:32:37.346092Z",
     "iopub.status.busy": "2024-06-09T08:32:37.345761Z",
     "iopub.status.idle": "2024-06-09T08:32:59.675462Z",
     "shell.execute_reply": "2024-06-09T08:32:59.674359Z"
    },
    "papermill": {
     "duration": 22.341733,
     "end_time": "2024-06-09T08:32:59.677698",
     "exception": false,
     "start_time": "2024-06-09T08:32:37.335965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a class in C++ for allocation of small objects \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple implementation of a class in C++ for allocation of small objects using a pool allocator:\n",
       "\n",
       "```cpp\n",
       "#include <iostream>\n",
       "#include <vector>\n",
       "#include <memory>\n",
       "\n",
       "class SmallObjectAllocator {\n",
       "private:\n",
       "    std::vector<std::unique_ptr<void>> pool;\n",
       "\n",
       "public:\n",
       "    SmallObjectAllocator(size_t size) {\n",
       "        pool.resize(size);\n",
       "    }\n",
       "\n",
       "    template <typename T>\n",
       "    T* allocate() {\n",
       "        for (auto& ptr : pool) {\n",
       "            if (!ptr) {\n",
       "                ptr.reset(new T());\n",
       "                return static_cast<T*>(ptr.get());\n",
       "            }\n",
       "        }\n",
       "        return nullptr;\n",
       "    }\n",
       "\n",
       "    void deallocate(T* ptr) {\n",
       "        for (auto& p : pool) {\n",
       "            if (p.get() == ptr) {\n",
       "                p.reset();\n",
       "                return;\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "int main() {\n",
       "    SmallObjectAllocator allocator(10);\n",
       "\n",
       "    for (int i = 0; i < 5; ++i) {\n",
       "        int* p = static_cast<int*>(allocator.allocate<int>());\n",
       "        *p = i;\n",
       "        std::cout << *p << std::endl;\n",
       "    }\n",
       "\n",
       "    allocator.deallocate(static_cast<int*>(allocator.allocate<int>()));\n",
       "\n",
       "    return 0;\n",
       "}\n",
       "```\n",
       "\n",
       "This code creates a pool of small objects and provides methods to allocate and deallocate objects from the pool. The `allocate` method returns a pointer to a newly allocated object if available in the pool, otherwise it returns `nullptr`. The `deallocate` method resets the pointer to the object in the pool, effectively freeing the memory. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 22.32 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a class in C++ for allocation of small objects\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56228bd",
   "metadata": {
    "papermill": {
     "duration": 0.009565,
     "end_time": "2024-06-09T08:32:59.697038",
     "exception": false,
     "start_time": "2024-06-09T08:32:59.687473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SQL code\n",
    "\n",
    "Let's continue by generating some transactional SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f58821a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:32:59.717973Z",
     "iopub.status.busy": "2024-06-09T08:32:59.716894Z",
     "iopub.status.idle": "2024-06-09T08:33:09.583043Z",
     "shell.execute_reply": "2024-06-09T08:33:09.581966Z"
    },
    "papermill": {
     "duration": 9.87909,
     "end_time": "2024-06-09T08:33:09.585396",
     "exception": false,
     "start_time": "2024-06-09T08:32:59.706306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a small stored procedure in SQL to debit one account and credit another account. \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a sample stored procedure in SQL to debit one account and credit another account:\n",
       "\n",
       "```\n",
       "CREATE PROCEDURE DebitAndCredit\n",
       "    @account_to_debit int,\n",
       "    @account_to_credit int,\n",
       "    @amount decimal(10,2)\n",
       "AS\n",
       "BEGIN\n",
       "    BEGIN TRANSACTION\n",
       "    BEGIN TRY\n",
       "        UPDATE Accounts\n",
       "        SET Balance = Balance - @amount\n",
       "        WHERE AccountID = @account_to_debit\n",
       "\n",
       "        UPDATE Accounts\n",
       "        SET Balance = Balance + @amount\n",
       "        WHERE AccountID = @account_to_credit\n",
       "\n",
       "        COMMIT TRANSACTION\n",
       "    END TRY\n",
       "    BEGIN CATCH\n",
       "        ROLLBACK TRANSACTION\n",
       "        THROW\n",
       "    END CATCH\n",
       "END\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 9.86 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple SQL code.\n",
    "Please answer with the listing of the SQL code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a small stored procedure in SQL to debit one account and credit another account.\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1923cb",
   "metadata": {
    "papermill": {
     "duration": 0.009446,
     "end_time": "2024-06-09T08:33:09.604977",
     "exception": false,
     "start_time": "2024-06-09T08:33:09.595531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Erlang code\n",
    "\n",
    "\n",
    "Let's continue by generating some Erlang code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be5fa186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:33:09.625495Z",
     "iopub.status.busy": "2024-06-09T08:33:09.625153Z",
     "iopub.status.idle": "2024-06-09T08:33:33.438942Z",
     "shell.execute_reply": "2024-06-09T08:33:33.437861Z"
    },
    "papermill": {
     "duration": 23.826602,
     "end_time": "2024-06-09T08:33:33.441234",
     "exception": false,
     "start_time": "2024-06-09T08:33:09.614632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a small module in Erlang for sending transactions between two parties. \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple Erlang module that simulates sending transactions between two parties:\n",
       "\n",
       "```erlang\n",
       "-module(transaction).\n",
       "-export([start/0, send/2, receive/1]).\n",
       "\n",
       "% Initialize the balance for both parties\n",
       "party1_balance = 1000.\n",
       "party2_balance = 1000.\n",
       "\n",
       "start() ->\n",
       "    io:format(\"Transaction system started.~n\").\n",
       "\n",
       "send(Party, Amount) ->\n",
       "    case Party of\n",
       "        party1 ->\n",
       "            if Amount =< party1_balance ->\n",
       "                party1_balance = party1_balance - Amount,\n",
       "                party2_balance = party2_balance + Amount,\n",
       "                io:format(\"Party 1 sent ~p to Party 2.~n\", [Amount]);\n",
       "               _ ->\n",
       "                io:format(\"Party 1 does not have enough balance.~n\")\n",
       "            end;\n",
       "        party2 ->\n",
       "            if Amount =< party2_balance ->\n",
       "                party1_balance = party1_balance + Amount,\n",
       "                party2_balance = party2_balance - Amount,\n",
       "                io:format(\"Party 2 sent ~p to Party 1.~n\", [Amount]);\n",
       "               _ ->\n",
       "                io:format(\"Party 2 does not have enough balance.~n\")\n",
       "            end;\n",
       "        _ ->\n",
       "            io:format(\"Invalid party.~n\")\n",
       "    end.\n",
       "\n",
       "receive(Party) ->\n",
       "    case Party of\n",
       "        party1 ->\n",
       "            io:format(\"Party 1 balance: ~p~n\", [party1_balance]);\n",
       "        party2 ->\n",
       "            io:format(\"Party 2 balance: ~p~n\", [party2_balance]);\n",
       "        _ ->\n",
       "            io:format(\"Invalid party.~n\")\n",
       "    end.\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 23.81 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple Erlang code.\n",
    "Please answer with the listing of the Erlang code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a small module in Erlang for sending transactions between two parties.\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092195b",
   "metadata": {
    "papermill": {
     "duration": 0.009044,
     "end_time": "2024-06-09T08:33:33.460527",
     "exception": false,
     "start_time": "2024-06-09T08:33:33.451483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ada code\n",
    "\n",
    "Let's write some Ada code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a78e359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:33:33.480692Z",
     "iopub.status.busy": "2024-06-09T08:33:33.479938Z",
     "iopub.status.idle": "2024-06-09T08:33:37.460057Z",
     "shell.execute_reply": "2024-06-09T08:33:37.459127Z"
    },
    "papermill": {
     "duration": 3.992571,
     "end_time": "2024-06-09T08:33:37.462327",
     "exception": false,
     "start_time": "2024-06-09T08:33:33.469756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in Ada to calculate the area of a rectangle with edges of L and l \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is the Ada code to calculate the area of a rectangle:\n",
       "\n",
       "```ada\n",
       "function Rectangle_Area (L, l : Float) return Float is\n",
       "   Area : Float;\n",
       "begin\n",
       "   Area := L * l;\n",
       "   return Area;\n",
       "end Rectangle_Area;\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 3.97 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple Ada code.\n",
    "Please answer with the listing of the Ada code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in Ada to calculate the area of a rectangle with edges of L and l\",\n",
    "    temperature=0.1,\n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad9110",
   "metadata": {
    "papermill": {
     "duration": 0.009272,
     "end_time": "2024-06-09T08:33:37.481365",
     "exception": false,
     "start_time": "2024-06-09T08:33:37.472093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FORTRAN code\n",
    "\n",
    "Let's write some FORTRAN code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4397b56a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:33:37.501344Z",
     "iopub.status.busy": "2024-06-09T08:33:37.501012Z",
     "iopub.status.idle": "2024-06-09T08:33:43.224145Z",
     "shell.execute_reply": "2024-06-09T08:33:43.223240Z"
    },
    "papermill": {
     "duration": 5.735685,
     "end_time": "2024-06-09T08:33:43.226360",
     "exception": false,
     "start_time": "2024-06-09T08:33:37.490675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24/8086320.py\", line 7, in <module>\n",
      "    response = query_model(\n",
      "  File \"/tmp/ipykernel_24/3852654054.py\", line 22, in query_model\n",
      "    sequences = pipeline(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\", line 240, in __call__\n",
      "    return super().__call__(text_inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n",
      "    logger.warning_once(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\n",
      "Arguments: (<class 'UserWarning'>,)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in FORTRAN to calculate the area of a rectangle with edges of L and l \n",
       "\n",
       "**<font color='green'>Answer:</font>** PROGRAM AREA_OF_RECTANGLE\n",
       "  IMPLICIT NONE\n",
       "  REAL :: L, l, area\n",
       "\n",
       "  PRINT *, \"Enter the length of the rectangle: \"\n",
       "  READ *, L\n",
       "  PRINT *, \"Enter the width of the rectangle: \"\n",
       "  READ *, l\n",
       "\n",
       "  area = L * l\n",
       "\n",
       "  PRINT *, \"The area of the rectangle is: \", area\n",
       "\n",
       "END PROGRAM AREA_OF_RECTANGLE \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 5.72 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple FORTRAN code.\n",
    "Please answer with the listing of the FORTRAN code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in FORTRAN to calculate the area of a rectangle with edges of L and l\",\n",
    "    temperature=0.1,\n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e2963",
   "metadata": {
    "papermill": {
     "duration": 0.010122,
     "end_time": "2024-06-09T08:33:43.246572",
     "exception": false,
     "start_time": "2024-06-09T08:33:43.236450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# COBOL code\n",
    "\n",
    "Let's try some COBOL code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77134f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:33:43.268154Z",
     "iopub.status.busy": "2024-06-09T08:33:43.267866Z",
     "iopub.status.idle": "2024-06-09T08:34:01.108915Z",
     "shell.execute_reply": "2024-06-09T08:34:01.108016Z"
    },
    "papermill": {
     "duration": 17.853977,
     "end_time": "2024-06-09T08:34:01.110979",
     "exception": false,
     "start_time": "2024-06-09T08:33:43.257002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in COBOL to calculate the average transaction amount during current month,\n",
       "    given the amounts of all the transactions and the dates of the transactions. \n",
       "\n",
       "**<font color='green'>Answer:</font>** IDENTIFICATION DIVISION.\n",
       "PROGRAM-ID. AVG-TRANSACTION-AMOUNT.\n",
       "\n",
       "DATA DIVISION.\n",
       "WORKING-STORAGE SECTION.\n",
       "01  TRANSACTION-AMOUNTS OCCURS 100 TIMES PIC 9(5).\n",
       "01  TRANSACTION-DATES OCCURS 100 TIMES PIC X(10).\n",
       "01  CURRENT-MONTH PIC 99.\n",
       "01  TOTAL-AMOUNT PIC 9(7) VALUE 0.\n",
       "01  TRANSACTION-COUNT PIC 9(2) VALUE 0.\n",
       "01  AVERAGE-AMOUNT PIC 9(5) VALUE 0.\n",
       "\n",
       "PROCEDURE DIVISION.\n",
       "    PERFORM GET-TRANSACTION-DATA\n",
       "    PERFORM CALCULATE-AVERAGE\n",
       "    DISPLAY AVERAGE-AMOUNT\n",
       "    STOP RUN.\n",
       "\n",
       "GET-TRANSACTION-DATA.\n",
       "    PERFORM VARYING I FROM 1 BY 1 UNTIL I > 100\n",
       "        ACCEPT \"Enter transaction amount \" I \": \" WITH NO ADVANCING\n",
       "        ACCEPT \"Enter transaction date \" I \": \" WITH NO ADVANCING\n",
       "        MOVE FUNCTION CURRENT-DATE TO TRANSACTION-DATES(I)\n",
       "        ADD TRANSACTION-AMOUNTS(I) TO TOTAL-AMOUNT\n",
       "        ADD 1 TO TRANSACTION-COUNT\n",
       "    END-PERFORM.\n",
       "\n",
       " \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 17.83 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple COBOL code.\n",
    "Please answer with the listing of the COBOL code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"\"\"Please write a function in COBOL to calculate the average transaction amount during current month,\n",
    "    given the amounts of all the transactions and the dates of the transactions.\"\"\",\n",
    "    temperature=0.1,\n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe6887",
   "metadata": {
    "papermill": {
     "duration": 0.010411,
     "end_time": "2024-06-09T08:34:01.132271",
     "exception": false,
     "start_time": "2024-06-09T08:34:01.121860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Llama3 proved to be proficient while writing code in a large number of languages, including objectual code, procedural, functional, and directive."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 314.608262,
   "end_time": "2024-06-09T08:34:04.134282",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-09T08:28:49.526020",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "096c09d179ea4a6f9454550109b1e504": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_929b3e44f6a44bc9aa3eae83b9976e24",
       "placeholder": "",
       "style": "IPY_MODEL_5c5bf6cf12574778b297b6b360c6ef10",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "437d2575ac8e4961864714eaa2ea3ba0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c5bf6cf12574778b297b6b360c6ef10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5e6f7d234ed240beb465fd74ebe91050": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b96b4a1e552c4a9787aa94a66356b9f1",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9df0bbca7c3848f7a92decda553ca4d9",
       "value": 4.0
      }
     },
     "64474073e3ff42d08491babe3f28365b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "81211a0b82be4469af0a785c304d6daf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8dc52a3d917a4f269629a97778abec7f",
       "placeholder": "",
       "style": "IPY_MODEL_64474073e3ff42d08491babe3f28365b",
       "value": " 4/4 [01:47&lt;00:00, 23.31s/it]"
      }
     },
     "8dc52a3d917a4f269629a97778abec7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "929b3e44f6a44bc9aa3eae83b9976e24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9df0bbca7c3848f7a92decda553ca4d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "aea7d2f453f84f778b23b8bcf5fd8c95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_096c09d179ea4a6f9454550109b1e504",
        "IPY_MODEL_5e6f7d234ed240beb465fd74ebe91050",
        "IPY_MODEL_81211a0b82be4469af0a785c304d6daf"
       ],
       "layout": "IPY_MODEL_437d2575ac8e4961864714eaa2ea3ba0"
      }
     },
     "b96b4a1e552c4a9787aa94a66356b9f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
