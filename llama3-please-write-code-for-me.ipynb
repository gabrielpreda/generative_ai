{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0214a5b2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.006559,
     "end_time": "2024-05-13T14:17:29.932862",
     "exception": false,
     "start_time": "2024-05-13T14:17:29.926303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "We are using LLama3 to write code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1237ebfb",
   "metadata": {
    "papermill": {
     "duration": 0.005353,
     "end_time": "2024-05-13T14:17:29.944143",
     "exception": false,
     "start_time": "2024-05-13T14:17:29.938790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebdd6f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:17:29.957248Z",
     "iopub.status.busy": "2024-05-13T14:17:29.956857Z",
     "iopub.status.idle": "2024-05-13T14:17:35.358832Z",
     "shell.execute_reply": "2024-05-13T14:17:35.357880Z"
    },
    "papermill": {
     "duration": 5.411388,
     "end_time": "2024-05-13T14:17:35.361128",
     "exception": false,
     "start_time": "2024-05-13T14:17:29.949740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "363bdc87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:17:35.375177Z",
     "iopub.status.busy": "2024-05-13T14:17:35.374536Z",
     "iopub.status.idle": "2024-05-13T14:19:24.475679Z",
     "shell.execute_reply": "2024-05-13T14:19:24.474830Z"
    },
    "papermill": {
     "duration": 109.110369,
     "end_time": "2024-05-13T14:19:24.477864",
     "exception": false,
     "start_time": "2024-05-13T14:17:35.367495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 14:17:37.051371: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-13 14:17:37.051523: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-13 14:17:37.165244: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef2db9647984f548d5887835b7d27f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da098b5",
   "metadata": {
    "papermill": {
     "duration": 0.005734,
     "end_time": "2024-05-13T14:19:24.489728",
     "exception": false,
     "start_time": "2024-05-13T14:19:24.483994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test function\n",
    "\n",
    "Let's define the query model function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4030edeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:19:24.503529Z",
     "iopub.status.busy": "2024-05-13T14:19:24.502529Z",
     "iopub.status.idle": "2024-05-13T14:19:24.510552Z",
     "shell.execute_reply": "2024-05-13T14:19:24.509705Z"
    },
    "papermill": {
     "duration": 0.016966,
     "end_time": "2024-05-13T14:19:24.512699",
     "exception": false,
     "start_time": "2024-05-13T14:19:24.495733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_model(\n",
    "        system_message,\n",
    "        user_message,\n",
    "        temperature=0.7,\n",
    "        max_length=1024\n",
    "        ):\n",
    "    start_time = time()\n",
    "    user_message = \"Question: \" + user_message + \" Answer:\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "        ]\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "        )\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    sequences = pipeline(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=temperature,\n",
    "        #num_return_sequences=1,\n",
    "        eos_token_id=terminators,\n",
    "        max_new_tokens=max_length,\n",
    "        return_full_text=False,\n",
    "        pad_token_id=pipeline.model.config.eos_token_id\n",
    "    )\n",
    "    #answer = f\"{sequences[0]['generated_text'][len(prompt):]}\\n\"\n",
    "    answer = sequences[0]['generated_text']\n",
    "    end_time = time()\n",
    "    ttime = f\"Total time: {round(end_time-start_time, 2)} sec.\"\n",
    "\n",
    "    return user_message + \" \" + answer  + \" \" +  ttime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a75e2c",
   "metadata": {
    "papermill": {
     "duration": 0.005682,
     "end_time": "2024-05-13T14:19:24.524461",
     "exception": false,
     "start_time": "2024-05-13T14:19:24.518779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also define an utility function for displaying the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9ad3c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:19:24.537424Z",
     "iopub.status.busy": "2024-05-13T14:19:24.537173Z",
     "iopub.status.idle": "2024-05-13T14:19:24.541902Z",
     "shell.execute_reply": "2024-05-13T14:19:24.541067Z"
    },
    "papermill": {
     "duration": 0.013607,
     "end_time": "2024-05-13T14:19:24.543859",
     "exception": false,
     "start_time": "2024-05-13T14:19:24.530252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Reasoning\", \"Question\", \"Answer\", \"Total time\"], [\"blue\", \"red\", \"green\", \"magenta\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335773d9",
   "metadata": {
    "papermill": {
     "duration": 0.00577,
     "end_time": "2024-05-13T14:19:24.556391",
     "exception": false,
     "start_time": "2024-05-13T14:19:24.550621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Python code\n",
    "\n",
    "Let's start testing the model with some Python questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f1f634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:19:24.569195Z",
     "iopub.status.busy": "2024-05-13T14:19:24.568951Z",
     "iopub.status.idle": "2024-05-13T14:19:28.814010Z",
     "shell.execute_reply": "2024-05-13T14:19:28.813033Z"
    },
    "papermill": {
     "duration": 4.254055,
     "end_time": "2024-05-13T14:19:28.816315",
     "exception": false,
     "start_time": "2024-05-13T14:19:24.562260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in Python to calculate the area of a rectangle with edges of L and l \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is the Python code for the function:\n",
       "\n",
       "```\n",
       "def rectangle_area(L, l):\n",
       "    return L * l\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 4.24 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple Python code.\n",
    "Please answer with the listing of the Python code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in Python to calculate the area of a rectangle with edges of L and l\",\n",
    "    temperature=0.1,\n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85dcf84f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:19:28.831749Z",
     "iopub.status.busy": "2024-05-13T14:19:28.830864Z",
     "iopub.status.idle": "2024-05-13T14:19:30.518080Z",
     "shell.execute_reply": "2024-05-13T14:19:30.517083Z"
    },
    "papermill": {
     "duration": 1.697265,
     "end_time": "2024-05-13T14:19:30.520393",
     "exception": false,
     "start_time": "2024-05-13T14:19:28.823128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in Python to order a list \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a Python function that orders a list:\n",
       "\n",
       "```\n",
       "def order_list(lst):\n",
       "    return sorted(lst)\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 1.68 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in Python to order a list\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8c52739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:19:30.535948Z",
     "iopub.status.busy": "2024-05-13T14:19:30.535376Z",
     "iopub.status.idle": "2024-05-13T14:20:00.764227Z",
     "shell.execute_reply": "2024-05-13T14:20:00.763309Z"
    },
    "papermill": {
     "duration": 30.244506,
     "end_time": "2024-05-13T14:20:00.772210",
     "exception": false,
     "start_time": "2024-05-13T14:19:30.527704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a Python module for a phone agenda. \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple Python module for a phone agenda:\n",
       "\n",
       "```\n",
       "class PhoneAgenda:\n",
       "    def __init__(self):\n",
       "        self.contacts = {}\n",
       "\n",
       "    def add_contact(self, name, phone_number):\n",
       "        self.contacts[name] = phone_number\n",
       "\n",
       "    def delete_contact(self, name):\n",
       "        if name in self.contacts:\n",
       "            del self.contacts[name]\n",
       "        else:\n",
       "            print(\"Contact not found\")\n",
       "\n",
       "    def update_contact(self, name, phone_number):\n",
       "        if name in self.contacts:\n",
       "            self.contacts[name] = phone_number\n",
       "        else:\n",
       "            print(\"Contact not found\")\n",
       "\n",
       "    def search_contact(self, name):\n",
       "        if name in self.contacts:\n",
       "            return self.contacts[name]\n",
       "        else:\n",
       "            return \"Contact not found\"\n",
       "\n",
       "    def display_contacts(self):\n",
       "        for name, phone_number in self.contacts.items():\n",
       "            print(f\"Name: {name}, Phone Number: {phone_number}\")\n",
       "\n",
       "\n",
       "def main():\n",
       "    agenda = PhoneAgenda()\n",
       "\n",
       "    while True:\n",
       "        print(\"\\nPhone Agenda Menu:\")\n",
       "        print(\"1. Add Contact\")\n",
       "        print(\"2. Delete Contact\")\n",
       "        print(\"3. Update Contact\")\n",
       "        print(\"4. Search Contact\")\n",
       "        print(\"5. Display Contacts\")\n",
       "        print(\"6. Exit\")\n",
       "\n",
       "        choice = input(\"Enter your choice: \")\n",
       "\n",
       "        if choice == \"1\":\n",
       "            name = input(\"Enter contact name: \")\n",
       "            phone_number = input(\"Enter contact phone number: \")\n",
       "            agenda.add_contact(name, phone_number)\n",
       "        elif choice == \"2\":\n",
       "            name = input(\"Enter contact name: \")\n",
       "            agenda.delete_contact(name)\n",
       "        elif choice == \"3\":\n",
       "            name = input(\"Enter contact name: \")\n",
       "            phone_number = input(\"Enter new contact phone number: \")\n",
       "            agenda.update_contact(name, phone_number)\n",
       "        elif choice == \"4\":\n",
       "            name = input(\"Enter contact name: \")\n",
       "            print(agenda.search_contact(name))\n",
       "        elif choice == \"5\":\n",
       "            agenda.display_contacts()\n",
       "        elif choice == \"6\":\n",
       "            break\n",
       "        else:\n",
       "            print(\"Invalid choice. Please choose a valid option.\")\n",
       "\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    main()\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 30.22 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a Python module for a phone agenda.\", \n",
    "    temperature=0.1,\n",
    "    max_length=1024)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fddf2f13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:20:00.786779Z",
     "iopub.status.busy": "2024-05-13T14:20:00.786410Z",
     "iopub.status.idle": "2024-05-13T14:20:23.165903Z",
     "shell.execute_reply": "2024-05-13T14:20:23.164952Z"
    },
    "papermill": {
     "duration": 22.389186,
     "end_time": "2024-05-13T14:20:23.167906",
     "exception": false,
     "start_time": "2024-05-13T14:20:00.778720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** \n",
       "                            Please write a Python service using Flask to expose a machine learning model. \n",
       "                            The service has one endpoint (POST) that receives three features:\n",
       "                            - area\n",
       "                            - number of rooms\n",
       "                            - number of bathrooms\n",
       "                            The model returns the price of the property. \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple Python service using Flask to expose a machine learning model:\n",
       "\n",
       "```\n",
       "from flask import Flask, request, jsonify\n",
       "import pandas as pd\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "from sklearn.linear_model import LinearRegression\n",
       "from sklearn.model_selection import train_test_split\n",
       "\n",
       "app = Flask(__name__)\n",
       "\n",
       "# Load the dataset\n",
       "df = pd.read_csv('property_data.csv')\n",
       "\n",
       "# Split the data into features and target\n",
       "X = df[['area', 'number of rooms', 'number of bathrooms']]\n",
       "y = df['price']\n",
       "\n",
       "# Split the data into training and testing sets\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
       "\n",
       "# Scale the features\n",
       "scaler = StandardScaler()\n",
       "X_train = scaler.fit_transform(X_train)\n",
       "X_test = scaler.transform(X_test)\n",
       "\n",
       "# Train the model\n",
       "model = LinearRegression()\n",
       "model.fit(X_train, y_train)\n",
       "\n",
       "# Define the endpoint\n",
       "@app.route('/predict', methods=['POST'])\n",
       "def predict():\n",
       "    data = request.get_json()\n",
       "    area = data['area']\n",
       "    number_of_rooms = data['number_of_rooms']\n",
       "    number_of_bathrooms = data['number_of_bathrooms']\n",
       "\n",
       "    # Scale the input data\n",
       "    scaler = StandardScaler()\n",
       "    input_data = scaler.transform([[area, number_of_rooms, number_of_bathrooms]])\n",
       "\n",
       "    # Make the prediction\n",
       "    prediction = model.predict(input_data)\n",
       "\n",
       "    return jsonify({'price': prediction[0]})\n",
       "\n",
       "if __name__ == '__main__':\n",
       "    app.run(debug=True)\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 22.37 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"\"\"\n",
    "                            Please write a Python service using Flask to expose a machine learning model. \n",
    "                            The service has one endpoint (POST) that receives three features:\n",
    "                            - area\n",
    "                            - number of rooms\n",
    "                            - number of bathrooms\n",
    "                            The model returns the price of the property.\"\"\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cdd41e",
   "metadata": {
    "papermill": {
     "duration": 0.006753,
     "end_time": "2024-05-13T14:20:23.182030",
     "exception": false,
     "start_time": "2024-05-13T14:20:23.175277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# C++ code\n",
    "\n",
    "Let's continue with few C++ questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f049b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:20:23.197613Z",
     "iopub.status.busy": "2024-05-13T14:20:23.197275Z",
     "iopub.status.idle": "2024-05-13T14:20:30.549599Z",
     "shell.execute_reply": "2024-05-13T14:20:30.548707Z"
    },
    "papermill": {
     "duration": 7.362731,
     "end_time": "2024-05-13T14:20:30.551768",
     "exception": false,
     "start_time": "2024-05-13T14:20:23.189037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in C++ to calculate the area of a rectangle with edges of L and l \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is the C++ code for the function:\n",
       "\n",
       "```cpp\n",
       "#include<iostream>\n",
       "using namespace std;\n",
       "\n",
       "float area(float L, float l) {\n",
       "    return L * l;\n",
       "}\n",
       "\n",
       "int main() {\n",
       "    float L, l;\n",
       "    cout << \"Enter the length of the rectangle: \";\n",
       "    cin >> L;\n",
       "    cout << \"Enter the breadth of the rectangle: \";\n",
       "    cin >> l;\n",
       "    cout << \"The area of the rectangle is: \" << area(L, l);\n",
       "    return 0;\n",
       "}\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 7.35 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple C++ code.\n",
    "Please answer with the listing of the C++ code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in C++ to calculate the area of a rectangle with edges of L and l\",\n",
    "    temperature=0.1,\n",
    "    max_length=256)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ae90e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:20:30.569343Z",
     "iopub.status.busy": "2024-05-13T14:20:30.568756Z",
     "iopub.status.idle": "2024-05-13T14:20:59.103930Z",
     "shell.execute_reply": "2024-05-13T14:20:59.102860Z"
    },
    "papermill": {
     "duration": 28.546982,
     "end_time": "2024-05-13T14:20:59.106443",
     "exception": false,
     "start_time": "2024-05-13T14:20:30.559461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in C++ to traverse a balanced tree \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple C++ function to traverse a balanced binary tree in-order, pre-order, and post-order:\n",
       "\n",
       "```cpp\n",
       "#include <iostream>\n",
       "using namespace std;\n",
       "\n",
       "// Define the structure for a node in the tree\n",
       "struct Node {\n",
       "    int data;\n",
       "    Node* left;\n",
       "    Node* right;\n",
       "};\n",
       "\n",
       "// Function to create a new node\n",
       "Node* createNode(int data) {\n",
       "    Node* newNode = new Node();\n",
       "    if (!newNode) {\n",
       "        cout << \"Memory error\\n\";\n",
       "        return NULL;\n",
       "    }\n",
       "    newNode->data = data;\n",
       "    newNode->left = newNode->right = NULL;\n",
       "    return newNode;\n",
       "}\n",
       "\n",
       "// Function to perform in-order traversal\n",
       "void inOrderTraversal(Node* root) {\n",
       "    if (root == NULL) return;\n",
       "    inOrderTraversal(root->left);\n",
       "    cout << root->data << \" \";\n",
       "    inOrderTraversal(root->right);\n",
       "}\n",
       "\n",
       "// Function to perform pre-order traversal\n",
       "void preOrderTraversal(Node* root) {\n",
       "    if (root == NULL) return;\n",
       "    cout << root->data << \" \";\n",
       "    preOrderTraversal(root->left);\n",
       "    preOrderTraversal(root->right);\n",
       "}\n",
       "\n",
       "// Function to perform post-order traversal\n",
       "void postOrderTraversal(Node* root) {\n",
       "    if (root == NULL) return;\n",
       "    postOrderTraversal(root->left);\n",
       "    postOrderTraversal(root->right);\n",
       "    cout << root->data << \" \";\n",
       "}\n",
       "\n",
       "int main() {\n",
       "    Node* root = createNode(1);\n",
       "    root->left = createNode(2);\n",
       "    root->right = createNode(3);\n",
       "    root->left->left = createNode(4);\n",
       "    root->left->right = createNode(5);\n",
       "\n",
       "    cout << \"In-order traversal: \";\n",
       "    inOrderTraversal(root);\n",
       "    cout << endl;\n",
       "\n",
       "    cout << \"Pre-order traversal: \";\n",
       "    preOrderTraversal(root);\n",
       "    cout << endl;\n",
       "\n",
       "    cout << \"Post-order traversal: \";\n",
       "    postOrderTraversal(root);\n",
       "    cout << endl;\n",
       "\n",
       "    return 0;\n",
       "}\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 28.53 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a function in C++ to traverse a balanced tree\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8339afc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:20:59.124280Z",
     "iopub.status.busy": "2024-05-13T14:20:59.123953Z",
     "iopub.status.idle": "2024-05-13T14:21:21.250396Z",
     "shell.execute_reply": "2024-05-13T14:21:21.249506Z"
    },
    "papermill": {
     "duration": 22.137562,
     "end_time": "2024-05-13T14:21:21.252497",
     "exception": false,
     "start_time": "2024-05-13T14:20:59.114935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a class in C++ for allocation of small objects \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple implementation of a class in C++ for allocation of small objects using a pool allocator:\n",
       "\n",
       "```cpp\n",
       "#include <iostream>\n",
       "#include <vector>\n",
       "#include <algorithm>\n",
       "\n",
       "class SmallObjectAllocator {\n",
       "private:\n",
       "    std::vector<char> pool;\n",
       "    size_t objectSize;\n",
       "\n",
       "public:\n",
       "    SmallObjectAllocator(size_t objectSize) : objectSize(objectSize) {\n",
       "        pool.resize(objectSize, 0);\n",
       "    }\n",
       "\n",
       "    void* allocate() {\n",
       "        for (char& byte : pool) {\n",
       "            if (byte == 0) {\n",
       "                byte = 1;\n",
       "                return &byte;\n",
       "            }\n",
       "        }\n",
       "        return nullptr;\n",
       "    }\n",
       "\n",
       "    void deallocate(void* ptr) {\n",
       "        if (ptr!= nullptr) {\n",
       "            char* charPtr = static_cast<char*>(ptr);\n",
       "            *charPtr = 0;\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "int main() {\n",
       "    SmallObjectAllocator allocator(16); // Allocate objects of size 16 bytes\n",
       "\n",
       "    void* obj1 = allocator.allocate();\n",
       "    void* obj2 = allocator.allocate();\n",
       "    void* obj3 = allocator.allocate();\n",
       "\n",
       "    // Use the allocated objects\n",
       "    //...\n",
       "\n",
       "    allocator.deallocate(obj1);\n",
       "    allocator.deallocate(obj2);\n",
       "    allocator.deallocate(obj3);\n",
       "\n",
       "    return 0;\n",
       "}\n",
       "```\n",
       "\n",
       "This code creates a pool of bytes of a specified size, and provides methods to allocate and deallocate objects of that size from the pool. The `allocate` method returns a pointer to the next available object in the pool, and the `deallocate` method marks an object as available again. \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 22.12 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a class in C++ for allocation of small objects\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0329459a",
   "metadata": {
    "papermill": {
     "duration": 0.007271,
     "end_time": "2024-05-13T14:21:21.267299",
     "exception": false,
     "start_time": "2024-05-13T14:21:21.260028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SQL code\n",
    "\n",
    "Let's continue by generating some transactional SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2c3488",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:21:21.283322Z",
     "iopub.status.busy": "2024-05-13T14:21:21.283031Z",
     "iopub.status.idle": "2024-05-13T14:21:31.029052Z",
     "shell.execute_reply": "2024-05-13T14:21:31.028136Z"
    },
    "papermill": {
     "duration": 9.756295,
     "end_time": "2024-05-13T14:21:31.031121",
     "exception": false,
     "start_time": "2024-05-13T14:21:21.274826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a small stored procedure in SQL to debit one account and credit another account. \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a sample stored procedure in SQL to debit one account and credit another account:\n",
       "\n",
       "```\n",
       "CREATE PROCEDURE DebitAndCredit\n",
       "    @account_to_debit int,\n",
       "    @account_to_credit int,\n",
       "    @amount decimal(10,2)\n",
       "AS\n",
       "BEGIN\n",
       "    BEGIN TRANSACTION\n",
       "    BEGIN TRY\n",
       "        UPDATE Accounts\n",
       "        SET Balance = Balance - @amount\n",
       "        WHERE AccountID = @account_to_debit\n",
       "\n",
       "        UPDATE Accounts\n",
       "        SET Balance = Balance + @amount\n",
       "        WHERE AccountID = @account_to_credit\n",
       "\n",
       "        COMMIT TRANSACTION\n",
       "    END TRY\n",
       "    BEGIN CATCH\n",
       "        ROLLBACK TRANSACTION\n",
       "        THROW\n",
       "    END CATCH\n",
       "END\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 9.74 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple SQL code.\n",
    "Please answer with the listing of the SQL code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a small stored procedure in SQL to debit one account and credit another account.\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcdf2be",
   "metadata": {
    "papermill": {
     "duration": 0.00785,
     "end_time": "2024-05-13T14:21:31.047646",
     "exception": false,
     "start_time": "2024-05-13T14:21:31.039796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Erlang code\n",
    "\n",
    "\n",
    "Let's continue by generating some Erlang code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "875de51f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T14:21:31.065553Z",
     "iopub.status.busy": "2024-05-13T14:21:31.064628Z",
     "iopub.status.idle": "2024-05-13T14:21:49.059144Z",
     "shell.execute_reply": "2024-05-13T14:21:49.058245Z"
    },
    "papermill": {
     "duration": 18.005469,
     "end_time": "2024-05-13T14:21:49.061293",
     "exception": false,
     "start_time": "2024-05-13T14:21:31.055824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a small module in Erlang for sending transactions between two parties. \n",
       "\n",
       "**<font color='green'>Answer:</font>** Here is a simple Erlang module that simulates sending transactions between two parties:\n",
       "\n",
       "```erlang\n",
       "-module(transaction).\n",
       "-export([start/0, send/2, receive/1]).\n",
       "\n",
       "% Initialize the balance for both parties\n",
       "party1_balance = 1000.\n",
       "party2_balance = 0.\n",
       "\n",
       "start() ->\n",
       "    io:format(\"Transaction system started.~n\").\n",
       "\n",
       "send(Party, Amount) ->\n",
       "    case Party of\n",
       "        party1 ->\n",
       "            if Amount =< party1_balance ->\n",
       "                party1_balance = party1_balance - Amount,\n",
       "                party2_balance = party2_balance + Amount,\n",
       "                io:format(\"Party 1 sent ~p to Party 2.~n\", [Amount]);\n",
       "               _ ->\n",
       "                io:format(\"Party 1 does not have enough balance.~n\")\n",
       "            end;\n",
       "        party2 ->\n",
       "            io:format(\"Party 2 cannot send transactions.~n\");\n",
       "        _ ->\n",
       "            io:format(\"Invalid party.~n\")\n",
       "    end.\n",
       "\n",
       "receive(Party) ->\n",
       "    case Party of\n",
       "        party2 ->\n",
       "            io:format(\"Party 2 received ~p from Party 1.~n\", [party2_balance]);\n",
       "        _ ->\n",
       "            io:format(\"Invalid party.~n\")\n",
       "    end.\n",
       "``` \n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 17.99 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant designed to write simple Erlang code.\n",
    "Please answer with the listing of the Erlang code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = query_model(\n",
    "    system_message,\n",
    "    user_message=\"Please write a small module in Erlang for sending transactions between two parties.\",\n",
    "    temperature=0.1,\n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b5dac",
   "metadata": {
    "papermill": {
     "duration": 0.007633,
     "end_time": "2024-05-13T14:21:49.076713",
     "exception": false,
     "start_time": "2024-05-13T14:21:49.069080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Llama3 proved to be proficient while writing code in a large number of languages, including objectual code, procedural, functional, and directive."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 265.201981,
   "end_time": "2024-05-13T14:21:52.445876",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-13T14:17:27.243895",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "10f8d8ccd4f8480fb94a5964a9cc44d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_472990a201d847608dc2adc1934d0048",
       "placeholder": "​",
       "style": "IPY_MODEL_3887b815b484413abcfbe9c0f4babfe1",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "174c9cb79e2b465491edf8d5127b617d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d09c8732bed42ebbcea203f7ee73067": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3887b815b484413abcfbe9c0f4babfe1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "472990a201d847608dc2adc1934d0048": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "483e142634e74c588feee1ca8c539069": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5a171f943c634e84a40f4f120da20760",
       "placeholder": "​",
       "style": "IPY_MODEL_604264466e3741fbbfcf8c4e29b102c2",
       "value": " 4/4 [01:35&lt;00:00, 20.31s/it]"
      }
     },
     "4ef2db9647984f548d5887835b7d27f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_10f8d8ccd4f8480fb94a5964a9cc44d7",
        "IPY_MODEL_54ef263682d54c2abda648f79450b4f4",
        "IPY_MODEL_483e142634e74c588feee1ca8c539069"
       ],
       "layout": "IPY_MODEL_f92c5d2cfe6e4d71a7775b6bfd343838"
      }
     },
     "54ef263682d54c2abda648f79450b4f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_174c9cb79e2b465491edf8d5127b617d",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1d09c8732bed42ebbcea203f7ee73067",
       "value": 4.0
      }
     },
     "5a171f943c634e84a40f4f120da20760": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "604264466e3741fbbfcf8c4e29b102c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f92c5d2cfe6e4d71a7775b6bfd343838": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
