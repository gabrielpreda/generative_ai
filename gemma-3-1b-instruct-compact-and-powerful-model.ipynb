{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e9e8f6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.011048,
     "end_time": "2025-04-14T19:13:40.000976",
     "exception": false,
     "start_time": "2025-04-14T19:13:39.989928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://www.geeky-gadgets.com/wp-content/uploads/2025/03/google-gemma-3-advanced-ai-models.webp\"></img></center>\n",
    "\n",
    "# Introduction\n",
    "This Notebook will explore how to prompt Gemma 3 1B instruct (fine-tuned), using KerasNLP. \n",
    "In a previous work, we explored the features of Gemma 3 1B (pre-trained): [Talk to Me Nice: Pro-Level Prompting for Gemma 3](https://www.kaggle.com/code/gpreda/talk-to-me-nice-pro-level-prompting-for-gemma-3)\n",
    "\n",
    "## What is Gemma?\n",
    "Gemma is a family of lightweight, state-of-the art open models built from the same research and technology used to create the Gemini models. At the 3rd generation now, Gemma 3 comes in 4 sizes, **1B**, **4B**, **12B** and **27B**, both pretrained and instruction finetuned versions.   \n",
    "\n",
    "Models **4B**, **12B**, **27B** brings an extended context window (up to **128K**) as well as **multi-modality** (text and image). \n",
    "\n",
    "The **1B** model, although incredibly compact, is not only very fast but is also quite powerful.\n",
    "\n",
    "As in the previous Notebook mentioned above, we will use the **1B intruct** model, on CPU only, without any accelerator.\n",
    "\n",
    "## How we will test the model?\n",
    "\n",
    "We will first initize the model and then we will test with simple common knowledge questions, followed by algebra and equations. Then we will test the model for writing code.\n",
    "\n",
    "\n",
    "# Prerequisites\n",
    "\n",
    "## Install packages\n",
    "\n",
    "We will install Keras and KerasNLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3418e24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:13:40.023431Z",
     "iopub.status.busy": "2025-04-14T19:13:40.023039Z",
     "iopub.status.idle": "2025-04-14T19:13:54.067076Z",
     "shell.execute_reply": "2025-04-14T19:13:54.065653Z"
    },
    "papermill": {
     "duration": 14.05762,
     "end_time": "2025-04-14T19:13:54.069873",
     "exception": false,
     "start_time": "2025-04-14T19:13:40.012253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.1/792.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0b1923",
   "metadata": {
    "papermill": {
     "duration": 0.010221,
     "end_time": "2025-04-14T19:13:54.094377",
     "exception": false,
     "start_time": "2025-04-14T19:13:54.084156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9058a411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:13:54.116308Z",
     "iopub.status.busy": "2025-04-14T19:13:54.115920Z",
     "iopub.status.idle": "2025-04-14T19:14:11.003969Z",
     "shell.execute_reply": "2025-04-14T19:14:11.003044Z"
    },
    "papermill": {
     "duration": 16.901266,
     "end_time": "2025-04-14T19:14:11.005934",
     "exception": false,
     "start_time": "2025-04-14T19:13:54.104668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "from keras_nlp.samplers import TopKSampler\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20945993",
   "metadata": {
    "papermill": {
     "duration": 0.009982,
     "end_time": "2025-04-14T19:14:11.026671",
     "exception": false,
     "start_time": "2025-04-14T19:14:11.016689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbcd68",
   "metadata": {
    "papermill": {
     "duration": 0.009763,
     "end_time": "2025-04-14T19:14:11.046965",
     "exception": false,
     "start_time": "2025-04-14T19:14:11.037202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Select the backend \n",
    "\n",
    "Keras is a high-level, multi-framework deep learning API designed for simplicity and ease of use.   \n",
    "Keras 3 lets you choose the backend: \n",
    "* TensorFlow\n",
    "* JAX\n",
    "* PyTorch\n",
    "\n",
    "\n",
    "For this Notebook, we will choose **JAX** as backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fcb839f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:14:11.068724Z",
     "iopub.status.busy": "2025-04-14T19:14:11.068037Z",
     "iopub.status.idle": "2025-04-14T19:14:11.072818Z",
     "shell.execute_reply": "2025-04-14T19:14:11.071919Z"
    },
    "papermill": {
     "duration": 0.017502,
     "end_time": "2025-04-14T19:14:11.074576",
     "exception": false,
     "start_time": "2025-04-14T19:14:11.057074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# run on CPU with max parallelism\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_cpu_multi_thread_eigen=true intra_op_parallelism_threads=8\"\n",
    "# if run on GPU, prevent JAX to take up to 100% memory from GPU, set max at 90% \n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa243279",
   "metadata": {
    "papermill": {
     "duration": 0.010591,
     "end_time": "2025-04-14T19:14:11.095691",
     "exception": false,
     "start_time": "2025-04-14T19:14:11.085100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We set `XLA_FLAGS` so that we allow parallelism and set maximum number of parallel threads to 8 - this is the maximum allowed on this platform CPU.\n",
    "\n",
    "Note: if you want to run this code on GPU, comment this line and uncomment the next line. This setting will prevent `JAX` from accessing 100% of GPU at starting, limiting to 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c481142",
   "metadata": {
    "papermill": {
     "duration": 0.009678,
     "end_time": "2025-04-14T19:14:11.115489",
     "exception": false,
     "start_time": "2025-04-14T19:14:11.105811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669ee47d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:14:11.136915Z",
     "iopub.status.busy": "2025-04-14T19:14:11.136530Z",
     "iopub.status.idle": "2025-04-14T19:14:42.002681Z",
     "shell.execute_reply": "2025-04-14T19:14:42.001664Z"
    },
    "papermill": {
     "duration": 30.879041,
     "end_time": "2025-04-14T19:14:42.004573",
     "exception": false,
     "start_time": "2025-04-14T19:14:11.125532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma_lm = keras_nlp.models.Gemma3CausalLM.from_preset(\"/kaggle/input/gemma3/keras/gemma3_instruct_1b/3\")\n",
    "tokenizer = keras_nlp.models.Gemma3Tokenizer.from_preset(\"/kaggle/input/gemma3/keras/gemma3_instruct_1b/3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afeac89",
   "metadata": {
    "papermill": {
     "duration": 0.00984,
     "end_time": "2025-04-14T19:14:42.024999",
     "exception": false,
     "start_time": "2025-04-14T19:14:42.015159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Verify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d53aa8a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:14:42.046637Z",
     "iopub.status.busy": "2025-04-14T19:14:42.046289Z",
     "iopub.status.idle": "2025-04-14T19:14:42.081069Z",
     "shell.execute_reply": "2025-04-14T19:14:42.080090Z"
    },
    "papermill": {
     "duration": 0.04758,
     "end_time": "2025-04-14T19:14:42.082827",
     "exception": false,
     "start_time": "2025-04-14T19:14:42.035247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma3_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma3_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma3_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Gemma3Tokenizer</span>)                            │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma3_tokenizer (\u001b[38;5;33mGemma3Tokenizer\u001b[0m)                            │                      Vocab size: \u001b[38;5;34m262,144\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma3_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma3_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma3_backbone               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">999,885,952</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Gemma3Backbone</span>)              │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">301,989,888</span> │ gemma3_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma3_backbone               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)        │     \u001b[38;5;34m999,885,952\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemma3Backbone\u001b[0m)              │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)      │     \u001b[38;5;34m301,989,888\u001b[0m │ gemma3_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">999,885,952</span> (3.72 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m999,885,952\u001b[0m (3.72 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">999,885,952</span> (3.72 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m999,885,952\u001b[0m (3.72 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc94c9b8",
   "metadata": {
    "papermill": {
     "duration": 0.010972,
     "end_time": "2025-04-14T19:14:42.105327",
     "exception": false,
     "start_time": "2025-04-14T19:14:42.094355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prompt the model\n",
    "\n",
    "We define a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f073ce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:14:42.128469Z",
     "iopub.status.busy": "2025-04-14T19:14:42.128127Z",
     "iopub.status.idle": "2025-04-14T19:15:03.757564Z",
     "shell.execute_reply": "2025-04-14T19:15:03.756523Z"
    },
    "papermill": {
     "duration": 21.642911,
     "end_time": "2025-04-14T19:15:03.759292",
     "exception": false,
     "start_time": "2025-04-14T19:14:42.116381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = \"You are an AI that answers in short, complete sentences only.\\n\"\n",
    "prompt = (\n",
    "    f\"{instructions}\"\n",
    "    \"Question: {question}\\n\"\n",
    "    \"Answer:\"\n",
    ")\n",
    "\n",
    "output = gemma_lm.generate(\n",
    "    prompt.format(question=\"What is the temperature of the Moon?\"),\n",
    "    max_length=40, \n",
    "    stop_token_ids=[tokenizer.token_to_id(\"\\n\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce3bfad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:03.783450Z",
     "iopub.status.busy": "2025-04-14T19:15:03.783021Z",
     "iopub.status.idle": "2025-04-14T19:15:03.788408Z",
     "shell.execute_reply": "2025-04-14T19:15:03.787232Z"
    },
    "papermill": {
     "duration": 0.019549,
     "end_time": "2025-04-14T19:15:03.790295",
     "exception": false,
     "start_time": "2025-04-14T19:15:03.770746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the temperature of the Moon?\n",
      "Answer: 0°C\n"
     ]
    }
   ],
   "source": [
    "answer = output.replace(instructions, \"\").strip()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7179ab8c",
   "metadata": {
    "papermill": {
     "duration": 0.010932,
     "end_time": "2025-04-14T19:15:03.812678",
     "exception": false,
     "start_time": "2025-04-14T19:15:03.801746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Well, the answer doesn't look correct. Let's try more questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6f825a",
   "metadata": {
    "papermill": {
     "duration": 0.01076,
     "end_time": "2025-04-14T19:15:03.834588",
     "exception": false,
     "start_time": "2025-04-14T19:15:03.823828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Functions to generate and format the output\n",
    "\n",
    "We define a function to generate the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc3c6fa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:03.858266Z",
     "iopub.status.busy": "2025-04-14T19:15:03.857858Z",
     "iopub.status.idle": "2025-04-14T19:15:03.862949Z",
     "shell.execute_reply": "2025-04-14T19:15:03.861993Z"
    },
    "papermill": {
     "duration": 0.018961,
     "end_time": "2025-04-14T19:15:03.864763",
     "exception": false,
     "start_time": "2025-04-14T19:15:03.845802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_answer(question, \n",
    "                    instructions=\"You are an AI that answers in short, complete sentences only.\\n\", \n",
    "                    max_length=40):\n",
    "    prompt = (\n",
    "        f\"{instructions}\"\n",
    "        \"Question: {question}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    output = gemma_lm.generate(\n",
    "        prompt.format(question=question),\n",
    "        max_length=max_length, \n",
    "        stop_token_ids=[tokenizer.token_to_id(\"\\n\")]\n",
    "    )    \n",
    "    answer = output.replace(instructions, \"\").strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68553ad0",
   "metadata": {
    "papermill": {
     "duration": 0.010799,
     "end_time": "2025-04-14T19:15:03.886938",
     "exception": false,
     "start_time": "2025-04-14T19:15:03.876139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we define a function to format the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91947f4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:03.910892Z",
     "iopub.status.busy": "2025-04-14T19:15:03.910501Z",
     "iopub.status.idle": "2025-04-14T19:15:03.915668Z",
     "shell.execute_reply": "2025-04-14T19:15:03.914660Z"
    },
    "papermill": {
     "duration": 0.019178,
     "end_time": "2025-04-14T19:15:03.917530",
     "exception": false,
     "start_time": "2025-04-14T19:15:03.898352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Reasoning\", \"Question\", \"Answer\", \"Explanation\", \"Total time\"], [\"blue\", \"red\", \"green\", \"darkblue\",  \"magenta\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42a1cc",
   "metadata": {
    "papermill": {
     "duration": 0.011403,
     "end_time": "2025-04-14T19:15:03.940428",
     "exception": false,
     "start_time": "2025-04-14T19:15:03.929025",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following function combine both functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "196d5b85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:03.964914Z",
     "iopub.status.busy": "2025-04-14T19:15:03.964571Z",
     "iopub.status.idle": "2025-04-14T19:15:03.969338Z",
     "shell.execute_reply": "2025-04-14T19:15:03.968308Z"
    },
    "papermill": {
     "duration": 0.018825,
     "end_time": "2025-04-14T19:15:03.970900",
     "exception": false,
     "start_time": "2025-04-14T19:15:03.952075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_format_answer(question, \n",
    "                    instructions=\"You are an AI that answers in short, complete sentences only.\\n\", \n",
    "                    max_length=40):\n",
    "    t = time()\n",
    "    answer = generate_answer(question, instructions, max_length)\n",
    "    display(Markdown(colorize_text(f\"{answer}\\n\\nTotal time: {round(time()-t, 2)} sec.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac5ac8",
   "metadata": {
    "papermill": {
     "duration": 0.011008,
     "end_time": "2025-04-14T19:15:03.993500",
     "exception": false,
     "start_time": "2025-04-14T19:15:03.982492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test the model with simple common knowledge questions\n",
    "\n",
    "Will ask questions from history, arts, general culture and politics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d97aafc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:04.019253Z",
     "iopub.status.busy": "2025-04-14T19:15:04.018859Z",
     "iopub.status.idle": "2025-04-14T19:15:07.629170Z",
     "shell.execute_reply": "2025-04-14T19:15:07.628123Z"
    },
    "papermill": {
     "duration": 3.625529,
     "end_time": "2025-04-14T19:15:07.630840",
     "exception": false,
     "start_time": "2025-04-14T19:15:04.005311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** When lived Alexander the Great?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** He lived in the 4th century BC.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 3.6 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = generate_format_answer(\"When lived Alexander the Great?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82f6c2ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:07.655088Z",
     "iopub.status.busy": "2025-04-14T19:15:07.654711Z",
     "iopub.status.idle": "2025-04-14T19:15:11.214360Z",
     "shell.execute_reply": "2025-04-14T19:15:11.213086Z"
    },
    "papermill": {
     "duration": 3.573869,
     "end_time": "2025-04-14T19:15:11.216202",
     "exception": false,
     "start_time": "2025-04-14T19:15:07.642333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** When lived Julius Caesar?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** He lived in the 1st century BC.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 3.55 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = generate_format_answer(\"When lived Julius Caesar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db6eddd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:11.241230Z",
     "iopub.status.busy": "2025-04-14T19:15:11.240797Z",
     "iopub.status.idle": "2025-04-14T19:15:13.838684Z",
     "shell.execute_reply": "2025-04-14T19:15:13.837602Z"
    },
    "papermill": {
     "duration": 2.612231,
     "end_time": "2025-04-14T19:15:13.840456",
     "exception": false,
     "start_time": "2025-04-14T19:15:11.228225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** When was the 1st Crusade?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** 11th century.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 2.59 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = generate_format_answer(\"When was the 1st Crusade?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90387911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:13.865273Z",
     "iopub.status.busy": "2025-04-14T19:15:13.864847Z",
     "iopub.status.idle": "2025-04-14T19:15:16.402361Z",
     "shell.execute_reply": "2025-04-14T19:15:16.401194Z"
    },
    "papermill": {
     "duration": 2.551853,
     "end_time": "2025-04-14T19:15:16.404156",
     "exception": false,
     "start_time": "2025-04-14T19:15:13.852303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** When Henric VIII lived?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** 15th century.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 2.53 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = generate_format_answer(\"When Henric VIII lived?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f884c",
   "metadata": {
    "papermill": {
     "duration": 0.011286,
     "end_time": "2025-04-14T19:15:16.427597",
     "exception": false,
     "start_time": "2025-04-14T19:15:16.416311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The answer is partially correct, he actually was born in 15th century, but lived most of his life in 16th century."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c026c4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:16.451675Z",
     "iopub.status.busy": "2025-04-14T19:15:16.451305Z",
     "iopub.status.idle": "2025-04-14T19:15:19.253005Z",
     "shell.execute_reply": "2025-04-14T19:15:19.251762Z"
    },
    "papermill": {
     "duration": 2.816092,
     "end_time": "2025-04-14T19:15:19.255124",
     "exception": false,
     "start_time": "2025-04-14T19:15:16.439032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** When started the rule of King Charles III?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** 2022\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 2.8 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = generate_format_answer(\"When started the rule of King Charles III?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2b4c149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:19.280542Z",
     "iopub.status.busy": "2025-04-14T19:15:19.280170Z",
     "iopub.status.idle": "2025-04-14T19:15:20.561700Z",
     "shell.execute_reply": "2025-04-14T19:15:20.560600Z"
    },
    "papermill": {
     "duration": 1.296173,
     "end_time": "2025-04-14T19:15:20.563552",
     "exception": false,
     "start_time": "2025-04-14T19:15:19.267379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** In what continent is Albania?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** Europe\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 1.28 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = generate_format_answer(\"In what continent is Albania?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c3bbac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:20.589069Z",
     "iopub.status.busy": "2025-04-14T19:15:20.588662Z",
     "iopub.status.idle": "2025-04-14T19:15:22.151859Z",
     "shell.execute_reply": "2025-04-14T19:15:22.150851Z"
    },
    "papermill": {
     "duration": 1.578052,
     "end_time": "2025-04-14T19:15:22.153674",
     "exception": false,
     "start_time": "2025-04-14T19:15:20.575622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** With which country in Asia has Europe border?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** Russia.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 1.56 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = generate_format_answer(\"With which country in Asia has Europe border?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a56755da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:22.179777Z",
     "iopub.status.busy": "2025-04-14T19:15:22.179400Z",
     "iopub.status.idle": "2025-04-14T19:15:25.241329Z",
     "shell.execute_reply": "2025-04-14T19:15:25.240188Z"
    },
    "papermill": {
     "duration": 3.076721,
     "end_time": "2025-04-14T19:15:25.242993",
     "exception": false,
     "start_time": "2025-04-14T19:15:22.166272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** On what continents is Turkye?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** Turkey is located on Europe and Asia.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 3.06 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = generate_format_answer(\"On what continents is Turkye?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8179c540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:25.269691Z",
     "iopub.status.busy": "2025-04-14T19:15:25.269341Z",
     "iopub.status.idle": "2025-04-14T19:15:27.301935Z",
     "shell.execute_reply": "2025-04-14T19:15:27.300820Z"
    },
    "papermill": {
     "duration": 2.047701,
     "end_time": "2025-04-14T19:15:27.303635",
     "exception": false,
     "start_time": "2025-04-14T19:15:25.255934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** What compound powers nuclear reactors?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** Uranium\n",
       "\n",
       "<end_of_turn><end_of_turn>\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 2.03 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = generate_format_answer(\"What compound powers nuclear reactors?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b92683b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:27.331580Z",
     "iopub.status.busy": "2025-04-14T19:15:27.331225Z",
     "iopub.status.idle": "2025-04-14T19:15:29.438821Z",
     "shell.execute_reply": "2025-04-14T19:15:29.437742Z"
    },
    "papermill": {
     "duration": 2.123897,
     "end_time": "2025-04-14T19:15:29.440814",
     "exception": false,
     "start_time": "2025-04-14T19:15:27.316917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Who build the 1st atomic bomb?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** The United States.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 2.1 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = generate_format_answer(\"Who build the 1st atomic bomb?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f7f2bb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:29.484998Z",
     "iopub.status.busy": "2025-04-14T19:15:29.484495Z",
     "iopub.status.idle": "2025-04-14T19:15:32.649374Z",
     "shell.execute_reply": "2025-04-14T19:15:32.648398Z"
    },
    "papermill": {
     "duration": 3.187655,
     "end_time": "2025-04-14T19:15:32.651040",
     "exception": false,
     "start_time": "2025-04-14T19:15:29.463385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Who was the 46th president of United States?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** Joe Biden\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** What is the\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 3.16 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = generate_format_answer(\"Who was the 46th president of United States?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eea268",
   "metadata": {
    "papermill": {
     "duration": 0.07312,
     "end_time": "2025-04-14T19:15:32.737000",
     "exception": false,
     "start_time": "2025-04-14T19:15:32.663880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There is an issue here, it looks like the model is initiating a conversation or just dumps sequences of Q & A.\n",
    "\n",
    "Let's test the model for a bit more complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d334c0f",
   "metadata": {
    "papermill": {
     "duration": 0.011943,
     "end_time": "2025-04-14T19:15:32.761419",
     "exception": false,
     "start_time": "2025-04-14T19:15:32.749476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test the model with simple arithmetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80b4be8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:32.787248Z",
     "iopub.status.busy": "2025-04-14T19:15:32.786879Z",
     "iopub.status.idle": "2025-04-14T19:15:35.334933Z",
     "shell.execute_reply": "2025-04-14T19:15:35.333878Z"
    },
    "papermill": {
     "duration": 2.562966,
     "end_time": "2025-04-14T19:15:35.336620",
     "exception": false,
     "start_time": "2025-04-14T19:15:32.773654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** What is 144 + 25?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** 169\n",
       "\n",
       "<end_of_turn>\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 2.54 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_format_answer(\"What is 144 + 25?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94bb7cdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:35.363535Z",
     "iopub.status.busy": "2025-04-14T19:15:35.363188Z",
     "iopub.status.idle": "2025-04-14T19:15:37.144235Z",
     "shell.execute_reply": "2025-04-14T19:15:37.143160Z"
    },
    "papermill": {
     "duration": 1.796379,
     "end_time": "2025-04-14T19:15:37.145890",
     "exception": false,
     "start_time": "2025-04-14T19:15:35.349511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** What is the square root of 169?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** 13\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 1.78 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_format_answer(\"What is the square root of 169?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cc46a97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:37.173855Z",
     "iopub.status.busy": "2025-04-14T19:15:37.173437Z",
     "iopub.status.idle": "2025-04-14T19:15:40.758538Z",
     "shell.execute_reply": "2025-04-14T19:15:40.757498Z"
    },
    "papermill": {
     "duration": 3.601335,
     "end_time": "2025-04-14T19:15:40.760245",
     "exception": false,
     "start_time": "2025-04-14T19:15:37.158910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** What is the square of 14?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** 196\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** What is the sum\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 3.58 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_format_answer(\"What is the square of 14?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f83e2",
   "metadata": {
    "papermill": {
     "duration": 0.012147,
     "end_time": "2025-04-14T19:15:40.785432",
     "exception": false,
     "start_time": "2025-04-14T19:15:40.773285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Again, the model starts to dump Q & A sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fdeb71",
   "metadata": {
    "papermill": {
     "duration": 0.01237,
     "end_time": "2025-04-14T19:15:40.810363",
     "exception": false,
     "start_time": "2025-04-14T19:15:40.797993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test with more advanced math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6b418ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:40.836734Z",
     "iopub.status.busy": "2025-04-14T19:15:40.836361Z",
     "iopub.status.idle": "2025-04-14T19:15:40.840450Z",
     "shell.execute_reply": "2025-04-14T19:15:40.839533Z"
    },
    "papermill": {
     "duration": 0.019073,
     "end_time": "2025-04-14T19:15:40.842038",
     "exception": false,
     "start_time": "2025-04-14T19:15:40.822965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an AI assistant designed to solve math problems.\n",
    "Answer to the problem. Only when needed, include reasoning.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d45b1ab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:15:40.869074Z",
     "iopub.status.busy": "2025-04-14T19:15:40.868712Z",
     "iopub.status.idle": "2025-04-14T19:17:11.907784Z",
     "shell.execute_reply": "2025-04-14T19:17:11.906659Z"
    },
    "papermill": {
     "duration": 91.067279,
     "end_time": "2025-04-14T19:17:11.922356",
     "exception": false,
     "start_time": "2025-04-14T19:15:40.855077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "You are an AI assistant designed to solve math problems.\n",
       "Answer to the problem. Only when needed, include reasoning.\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Eduard and John are brothers. \n",
       "    They split 10 apples.\n",
       "    Eduard has 2 more apples than John. \n",
       "    How many apples have each?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "Let's solve this problem step by step.\n",
       "Let $E$ be the number of apples Eduard has and $J$ be the number of apples John has.\n",
       "We are given that they split 10 apples, so $E + J = 10$.\n",
       "We are also given that Eduard has 2 more apples than John, so $E = J + 2$.\n",
       "Now we can substitute the second equation into the first equation:\n",
       "$(J + 2) + J = 10$\n",
       "$2J + 2 = 10$\n",
       "$2J = 8$\n",
       "$J = 4$\n",
       "Now we can find the number of apples Eduard has:\n",
       "$E = J + 2 = 4 + 2 = 6$\n",
       "So Eduard has 6 apples and John has 4 apples.\n",
       "We can check our answer:\n",
       "$E + J = 6 + 4 = 10$\n",
       "$E = J + 2 \\Rightarrow 6 = 4 + 2$, which is true.\n",
       "Final \n",
       "\n",
       "**<font color='green'>Answer:</font>** The final answer is $\\boxed{6, 4}$<end_of_turn>\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 91.03 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = time()\n",
    "response = gemma_lm.generate(prompt.format(\n",
    "    question=\"\"\"Eduard and John are brothers. \n",
    "    They split 10 apples.\n",
    "    Eduard has 2 more apples than John. \n",
    "    How many apples have each?\"\"\"), \n",
    "    max_length=400)\n",
    "display(Markdown(colorize_text(f\"{response}\\n\\nTotal time: {round(time()-t, 2)} sec.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc3e01b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:17:11.950344Z",
     "iopub.status.busy": "2025-04-14T19:17:11.949899Z",
     "iopub.status.idle": "2025-04-14T19:18:39.992351Z",
     "shell.execute_reply": "2025-04-14T19:18:39.991105Z"
    },
    "papermill": {
     "duration": 88.071596,
     "end_time": "2025-04-14T19:18:40.007292",
     "exception": false,
     "start_time": "2025-04-14T19:17:11.935696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "You are an AI assistant designed to solve math problems.\n",
       "Answer to the problem. Only when needed, include reasoning.\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** 2x + 5y = 12\n",
       "                2y - x = 3\n",
       "                Solve the equation for x and y. \n",
       "                Hint: simplify first x.\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "x = 3\n",
       "y = 2\n",
       "\n",
       "\n",
       "**<font color='darkblue'>Explanation:</font>**\n",
       "The given equations are:\n",
       "2x + 5y = 12\n",
       "2y - x = 3\n",
       "We can solve this system of equations by substitution.\n",
       "From the second equation, we can solve for x:\n",
       "2y - x = 3\n",
       "x = 2y - 3\n",
       "Substitute this expression for x into the first equation:\n",
       "2(2y - 3) + 5y = 12\n",
       "4y - 6 + 5y = 12\n",
       "9y - 6 = 12\n",
       "9y = 18\n",
       "y = 2\n",
       "Now, substitute y = 2 into the equation x = 2y - 3:\n",
       "x = 2(2) - 3\n",
       "x = 4 - 3\n",
       "x = 1\n",
       "Therefore, x = 1 and y = 2.\n",
       "The solution is x = 1, y = 2.\n",
       "Final \n",
       "\n",
       "**<font color='green'>Answer:</font>** The final answer is 1, 2.\n",
       "<end_of_turn>\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 88.04 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = time()\n",
    "response = gemma_lm.generate(prompt.format(\n",
    "    question=\"\"\"2x + 5y = 12\n",
    "                2y - x = 3\n",
    "                Solve the equation for x and y. \n",
    "                Hint: simplify first x.\"\"\"), \n",
    "    max_length=512)\n",
    "display(Markdown(colorize_text(f\"{response}\\n\\nTotal time: {round(time()-t, 2)} sec.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16fd68b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:18:40.034987Z",
     "iopub.status.busy": "2025-04-14T19:18:40.034628Z",
     "iopub.status.idle": "2025-04-14T19:20:00.427100Z",
     "shell.execute_reply": "2025-04-14T19:20:00.425769Z"
    },
    "papermill": {
     "duration": 80.420712,
     "end_time": "2025-04-14T19:20:00.441026",
     "exception": false,
     "start_time": "2025-04-14T19:18:40.020314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "You are an AI assistant designed to solve math problems.\n",
       "Answer to the problem. Only when needed, include reasoning.\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** x^2 -5x + 6 = 0\n",
       "                Solve the equation for x. \n",
       "                \n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "The equation is a quadratic equation in the form ax^2 + bx + c = 0.\n",
       "In this case, a = 1, b = -5, and c = 6.\n",
       "We can use the quadratic formula to solve for x:\n",
       "x = (-b ± √(b^2 - 4ac)) / 2a\n",
       "Plugging in the values, we get:\n",
       "x = (-(-5) ± √((-5)^2 - 4 * 1 * 6)) / (2 * 1)\n",
       "x = (5 ± √(25 - 24)) / 2\n",
       "x = (5 ± √1) / 2\n",
       "x = (5 ± 1) / 2\n",
       "x1 = (5 + 1) / 2 = 6 / 2 = 3\n",
       "x2 = (5 - 1) / 2 = 4 / 2 = 2\n",
       "Therefore, the solutions are x = 3 and x = 2.\n",
       "The solutions are x =\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 80.39 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = time()\n",
    "response = gemma_lm.generate(prompt.format(\n",
    "    question=\"\"\"x^2 -5x + 6 = 0\n",
    "                Solve the equation for x. \n",
    "                \"\"\"), \n",
    "    max_length=275)\n",
    "display(Markdown(colorize_text(f\"{response}\\n\\nTotal time: {round(time()-t, 2)} sec.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e27ca",
   "metadata": {
    "papermill": {
     "duration": 0.013643,
     "end_time": "2025-04-14T19:20:00.467846",
     "exception": false,
     "start_time": "2025-04-14T19:20:00.454203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Write code\n",
    "\n",
    "Let's test the model for writing code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55be8695",
   "metadata": {
    "papermill": {
     "duration": 0.012929,
     "end_time": "2025-04-14T19:20:00.493868",
     "exception": false,
     "start_time": "2025-04-14T19:20:00.480939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed1f0595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:20:00.521382Z",
     "iopub.status.busy": "2025-04-14T19:20:00.520955Z",
     "iopub.status.idle": "2025-04-14T19:20:00.525403Z",
     "shell.execute_reply": "2025-04-14T19:20:00.524290Z"
    },
    "papermill": {
     "duration": 0.020063,
     "end_time": "2025-04-14T19:20:00.527026",
     "exception": false,
     "start_time": "2025-04-14T19:20:00.506963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an AI assistant designed to write simple Python code.\n",
    "Please answer with the listing of the Python code.\n",
    "Make sure to format the output using correct Markdown for code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6dc996a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:20:00.555221Z",
     "iopub.status.busy": "2025-04-14T19:20:00.554822Z",
     "iopub.status.idle": "2025-04-14T19:20:41.817966Z",
     "shell.execute_reply": "2025-04-14T19:20:41.816781Z"
    },
    "papermill": {
     "duration": 41.292338,
     "end_time": "2025-04-14T19:20:41.832966",
     "exception": false,
     "start_time": "2025-04-14T19:20:00.540628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "You are an AI assistant designed to write simple Python code.\n",
       "Please answer with the listing of the Python code.\n",
       "Make sure to format the output using correct Markdown for code.\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please write a function in Python to calculate the area of a square with edge 'a'\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "```python\n",
       "def calculate_square_area(a):\n",
       "    \"\"\"\n",
       "    Calculate the area of a square with edge 'a'.\n",
       "\n",
       "    Args:\n",
       "        a: The length of the side of the square.\n",
       "\n",
       "    Returns:\n",
       "        The area of the square.\n",
       "    \"\"\"\n",
       "    area = a * a\n",
       "    return area\n",
       "```\n",
       "<end_of_turn>\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 41.26 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = time()\n",
    "response = gemma_lm.generate(prompt.format(question=\"Please write a function in Python to calculate the area of a square with edge 'a'\"), \n",
    "                             max_length=256)\n",
    "display(Markdown(colorize_text(f\"{response}\\n\\nTotal time: {round(time()-t, 2)} sec.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e334a540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:20:41.861292Z",
     "iopub.status.busy": "2025-04-14T19:20:41.860911Z",
     "iopub.status.idle": "2025-04-14T19:21:04.858854Z",
     "shell.execute_reply": "2025-04-14T19:21:04.857824Z"
    },
    "papermill": {
     "duration": 23.014489,
     "end_time": "2025-04-14T19:21:04.860915",
     "exception": false,
     "start_time": "2025-04-14T19:20:41.846426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "You are an AI assistant designed to write simple Python code.\n",
       "Please answer with the listing of the Python code.\n",
       "Make sure to format the output using correct Markdown for code.\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Write a function in Python to calculate the area of a circle of radius r\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "```python\n",
       "import math\n",
       "\n",
       "def calculate_circle_area(r):\n",
       "  \"\"\"\n",
       "  Calculate the area of a circle.\n",
       "\n",
       "  Args:\n",
       "    r: The radius of the circle.\n",
       "\n",
       "  Returns:\n",
       "    The area of the circle.\n",
       "  \"\"\"\n",
       "  area = math.pi * r**2\n",
       "  return area\n",
       "```\n",
       "<end_of_turn>\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 22.99 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = time()\n",
    "response = gemma_lm.generate(prompt.format(question=\"Write a function in Python to calculate the area of a circle of radius r\"), \n",
    "                             max_length=256)\n",
    "display(Markdown(colorize_text(f\"{response}\\n\\nTotal time: {round(time()-t, 2)} sec.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0db07122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:21:04.889483Z",
     "iopub.status.busy": "2025-04-14T19:21:04.889129Z",
     "iopub.status.idle": "2025-04-14T19:21:54.636670Z",
     "shell.execute_reply": "2025-04-14T19:21:54.635538Z"
    },
    "papermill": {
     "duration": 49.776847,
     "end_time": "2025-04-14T19:21:54.651588",
     "exception": false,
     "start_time": "2025-04-14T19:21:04.874741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "You are an AI assistant designed to write simple Python code.\n",
       "Please answer with the listing of the Python code.\n",
       "Make sure to format the output using correct Markdown for code.\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Write a function in Python to calculate cosine similarity of two vectors.\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "```python\n",
       "import numpy as np\n",
       "\n",
       "def cosine_similarity(vec1, vec2):\n",
       "    \"\"\"\n",
       "    Calculate the cosine similarity of two vectors.\n",
       "\n",
       "    Args:\n",
       "        vec1 (numpy.ndarray): The first vector.\n",
       "        vec2 (numpy.ndarray): The second vector.\n",
       "\n",
       "    Returns:\n",
       "        float: The cosine similarity of the two vectors.\n",
       "    \"\"\"\n",
       "    dot_product = np.dot(vec1, vec2)\n",
       "    magnitude_vec1 = np.linalg.norm(vec1)\n",
       "    magnitude_vec2 = np.linalg.norm(vec2)\n",
       "    if magnitude_vec1 == 0 or magnitude_vec2 == 0:\n",
       "        return 0.0\n",
       "    return dot_product / (magnitude_vec1 * magnitude_vec2)\n",
       "```\n",
       "<end_of_turn>\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 49.74 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = time()\n",
    "response = gemma_lm.generate(prompt.format(question=\"Write a function in Python to calculate cosine similarity of two vectors.\"), \n",
    "                             max_length=256)\n",
    "display(Markdown(colorize_text(f\"{response}\\n\\nTotal time: {round(time()-t, 2)} sec.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a16617",
   "metadata": {
    "papermill": {
     "duration": 0.01332,
     "end_time": "2025-04-14T19:21:54.678391",
     "exception": false,
     "start_time": "2025-04-14T19:21:54.665071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code is correct, carefully documented and clean for all the examples above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64966cb",
   "metadata": {
    "papermill": {
     "duration": 0.013017,
     "end_time": "2025-04-14T19:21:54.704890",
     "exception": false,
     "start_time": "2025-04-14T19:21:54.691873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### C++ code\n",
    "\n",
    "Let's test now the model with writing C++ code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79709fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:21:54.733315Z",
     "iopub.status.busy": "2025-04-14T19:21:54.732884Z",
     "iopub.status.idle": "2025-04-14T19:21:54.737314Z",
     "shell.execute_reply": "2025-04-14T19:21:54.736181Z"
    },
    "papermill": {
     "duration": 0.020735,
     "end_time": "2025-04-14T19:21:54.738909",
     "exception": false,
     "start_time": "2025-04-14T19:21:54.718174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an AI assistant designed to write simple C++ code.\n",
    "Please answer with the listing of the C++ code.\n",
    "Make sure to format the output using correct Markdown for code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1adbe706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:21:54.768022Z",
     "iopub.status.busy": "2025-04-14T19:21:54.767679Z",
     "iopub.status.idle": "2025-04-14T19:23:02.377191Z",
     "shell.execute_reply": "2025-04-14T19:23:02.376126Z"
    },
    "papermill": {
     "duration": 67.638705,
     "end_time": "2025-04-14T19:23:02.391505",
     "exception": false,
     "start_time": "2025-04-14T19:21:54.752800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "You are an AI assistant designed to write simple C++ code.\n",
       "Please answer with the listing of the C++ code.\n",
       "Make sure to format the output using correct Markdown for code.\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Write a C++ function to calculate linear product of two vectors.\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "```cpp\n",
       "#include <iostream>\n",
       "#include <vector>\n",
       "\n",
       "using namespace std;\n",
       "\n",
       "// Function to calculate the product of two vectors\n",
       "vector<int> productOfVectors(const vector<int>& vec1, const vector<int>& vec2) {\n",
       "  vector<int> result;\n",
       "  for (int i = 0; i < vec1.size(); ++i) {\n",
       "    result.push_back(vec1[i] * vec2[i]);\n",
       "  }\n",
       "  return result;\n",
       "}\n",
       "\n",
       "int main() {\n",
       "  vector<int> v1 = {1, 2, 3};\n",
       "  vector<int> v2 = {4, 5, 6};\n",
       "  vector<int> product = productOfVectors(v1, v2);\n",
       "  cout << \"Product: \";\n",
       "  for (int i = 0; i < product.size(); ++i) {\n",
       "    cout << product[i] << \" \";\n",
       "  }\n",
       "  cout << endl;\n",
       "  return 0;\n",
       "}\n",
       "```\n",
       "<end_of_turn>\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 67.6 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = time()\n",
    "response = gemma_lm.generate(prompt.format(question=\"Write a C++ function to calculate linear product of two vectors.\"), \n",
    "                             max_length=400)\n",
    "display(Markdown(colorize_text(f\"{response}\\n\\nTotal time: {round(time()-t, 2)} sec.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409bcd2",
   "metadata": {
    "papermill": {
     "duration": 0.014148,
     "end_time": "2025-04-14T19:23:02.419295",
     "exception": false,
     "start_time": "2025-04-14T19:23:02.405147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Java code\n",
    "\n",
    "Let's test now the model with writing Java code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "062033ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:23:02.448569Z",
     "iopub.status.busy": "2025-04-14T19:23:02.448161Z",
     "iopub.status.idle": "2025-04-14T19:23:02.452478Z",
     "shell.execute_reply": "2025-04-14T19:23:02.451320Z"
    },
    "papermill": {
     "duration": 0.021005,
     "end_time": "2025-04-14T19:23:02.454226",
     "exception": false,
     "start_time": "2025-04-14T19:23:02.433221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an AI assistant designed to write simple Java code.\n",
    "Please answer with the listing of the Java code.\n",
    "Make sure to format the output using correct Markdown for code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f74fb171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:23:02.483571Z",
     "iopub.status.busy": "2025-04-14T19:23:02.483230Z",
     "iopub.status.idle": "2025-04-14T19:23:53.722420Z",
     "shell.execute_reply": "2025-04-14T19:23:53.721156Z"
    },
    "papermill": {
     "duration": 51.26942,
     "end_time": "2025-04-14T19:23:53.737521",
     "exception": false,
     "start_time": "2025-04-14T19:23:02.468101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "You are an AI assistant designed to write simple Java code.\n",
       "Please answer with the listing of the Java code.\n",
       "Make sure to format the output using correct Markdown for code.\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Write a Java function to calculate the largest number in an array.\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "```java\n",
       "import java.util.Arrays;\n",
       "\n",
       "class Solution {\n",
       "    /**\n",
       "     * Calculates the largest number in an array.\n",
       "     *\n",
       "     * @param arr The array of numbers.\n",
       "     * @return The largest number in the array.\n",
       "     */\n",
       "    public int findLargestNumber(int[] arr) {\n",
       "        if (arr == null || arr.length == 0) {\n",
       "            throw new IllegalArgumentException(\"Array cannot be null or empty.\");\n",
       "        }\n",
       "        int largest = arr[0];\n",
       "        for (int i = 1; i < arr.length; i++) {\n",
       "            if (arr[i] > largest) {\n",
       "                largest = arr[i];\n",
       "            }\n",
       "        }\n",
       "        return largest;\n",
       "    }\n",
       "}\n",
       "```\n",
       "<end_of_turn>\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 51.23 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = time()\n",
    "response = gemma_lm.generate(prompt.format(question=\"Write a Java function to calculate the largest number in an array.\"), \n",
    "                             max_length=400)\n",
    "display(Markdown(colorize_text(f\"{response}\\n\\nTotal time: {round(time()-t, 2)} sec.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a7a2b6",
   "metadata": {
    "papermill": {
     "duration": 0.015105,
     "end_time": "2025-04-14T19:23:53.766640",
     "exception": false,
     "start_time": "2025-04-14T19:23:53.751535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Fortran code\n",
    "\n",
    "\n",
    "Let's test the model for writing Fortran code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "807963b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:23:53.796291Z",
     "iopub.status.busy": "2025-04-14T19:23:53.795881Z",
     "iopub.status.idle": "2025-04-14T19:23:53.800155Z",
     "shell.execute_reply": "2025-04-14T19:23:53.799036Z"
    },
    "papermill": {
     "duration": 0.021298,
     "end_time": "2025-04-14T19:23:53.801984",
     "exception": false,
     "start_time": "2025-04-14T19:23:53.780686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an AI assistant designed to write simple Fortran code.\n",
    "Please answer with the listing of the Fortran code.\n",
    "Make sure to format the output using correct Markdown for code.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a2884c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:23:53.831702Z",
     "iopub.status.busy": "2025-04-14T19:23:53.831335Z",
     "iopub.status.idle": "2025-04-14T19:24:26.531212Z",
     "shell.execute_reply": "2025-04-14T19:24:26.530118Z"
    },
    "papermill": {
     "duration": 32.730077,
     "end_time": "2025-04-14T19:24:26.546387",
     "exception": false,
     "start_time": "2025-04-14T19:23:53.816310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "You are an AI assistant designed to write simple Fortran code.\n",
       "Please answer with the listing of the Fortran code.\n",
       "Make sure to format the output using correct Markdown for code.\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Write an Fortran function to calculate the area of a circle.\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "```fortran\n",
       "PROGRAM CircleArea\n",
       "\n",
       "INTEGER radius, angle\n",
       "\n",
       "DO i = 1, 10\n",
       "  radius = radius * 2.0\n",
       "  angle = angle * 3.141592653589793\n",
       "  area = pi * radius * radius\n",
       "  PRINT *, \"Radius: \", radius, \" Angle: \", angle, \" Area: \", area\n",
       "END DO\n",
       "\n",
       "END\n",
       "```\n",
       "<end_of_turn>\n",
       "\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 32.69 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = time()\n",
    "response = gemma_lm.generate(prompt.format(question=\"Write an Fortran function to calculate the area of a circle.\"), \n",
    "                             max_length=512)\n",
    "display(Markdown(colorize_text(f\"{response}\\n\\nTotal time: {round(time()-t, 2)} sec.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8126ec6d",
   "metadata": {
    "papermill": {
     "duration": 0.01373,
     "end_time": "2025-04-14T19:24:26.574397",
     "exception": false,
     "start_time": "2025-04-14T19:24:26.560667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "\n",
    "We tested the Gemma 3 instruct 1B model from Google DeepMind on CPU-only machine.  \n",
    "This is a very powerful model that proved to be quite proficient with simple history, geography and general knowledge questions.  \n",
    "We tested then with arithmetics and answered correctly.  \n",
    "When prompted to solve simple math equations, it also went well.  \n",
    "It performed quite well with code writing, we tested it for Python, C++, and Java.  \n",
    "We also tested it for writing Fortran code but the result doesn't seems correct.\n",
    "\n",
    "# Suggestions to continue the work\n",
    "\n",
    "You can continue this work. Here are few suggestions:\n",
    "* Run the same code on GPU. You will see a major improvement of speed.\n",
    "* Quantize the model. From 1GB, you will be able to reduce the model size and run it (with acceptable performance degradation on a mobile platform or even on edge).\n",
    "* Find other user cases.\n",
    "* Include the model in a Retrieval Augmented Generation system.\n",
    "* Fine-tune the model for a specific task.\n",
    "* Combine fine-tuning with quantization to obtain a compact, adapted model for your own task.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "modelId": 279036,
     "modelInstanceId": 257759,
     "sourceId": 316994,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 653.883367,
   "end_time": "2025-04-14T19:24:30.453680",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-14T19:13:36.570313",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
